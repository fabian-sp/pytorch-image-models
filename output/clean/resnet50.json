[
    {
        "config": {
            "batch_size": 256,
            "dataset": "imagenet1k",
            "gradient_accumulation": 1,
            "max_epoch": 100,
            "model": "resnet50",
            "opt": {
                "lr": 0.4,
                "lr_schedule": "wsd",
                "momentum": 0.9,
                "name": "momentum",
                "weight_decay": 0.0001
            },
            "run_id": 0
        },
        "history": [
            {
                "epoch": 0,
                "learning_rate": 0.080008,
                "model_norm": 229.78472900390625,
                "train_grad_norm": 0.9571082226805231,
                "train_loss": 6.447919845581055,
                "val_loss": 5.730025307617187,
                "val_top1": 4.661999994812012,
                "val_top5": 13.391999995117187
            },
            {
                "epoch": 1,
                "learning_rate": 0.160006,
                "model_norm": 207.91778564453125,
                "train_grad_norm": 1.0454513685751143,
                "train_loss": 5.661999702453613,
                "val_loss": 4.743436141662598,
                "val_top1": 11.852000000610351,
                "val_top5": 28.71200003173828
            },
            {
                "epoch": 2,
                "learning_rate": 0.240004,
                "model_norm": 184.59910583496094,
                "train_grad_norm": 1.0366517718923425,
                "train_loss": 4.847457408905029,
                "val_loss": 4.237614579086304,
                "val_top1": 18.265999964599608,
                "val_top5": 39.05600001586914
            },
            {
                "epoch": 3,
                "learning_rate": 0.320002,
                "model_norm": 169.51486206054688,
                "train_grad_norm": 0.9679629818461869,
                "train_loss": 4.241257667541504,
                "val_loss": 3.628931259765625,
                "val_top1": 26.13000006225586,
                "val_top5": 50.56400002929688
            },
            {
                "epoch": 4,
                "learning_rate": 0.4,
                "model_norm": 165.77389526367188,
                "train_grad_norm": 0.918191514663645,
                "train_loss": 3.872633457183838,
                "val_loss": 3.0187298596191408,
                "val_top1": 36.366000053710934,
                "val_top5": 62.83399998779297
            },
            {
                "epoch": 5,
                "learning_rate": 0.4,
                "model_norm": 168.36880493164062,
                "train_grad_norm": 0.8929851340325523,
                "train_loss": 3.6193103790283203,
                "val_loss": 2.858974967956543,
                "val_top1": 39.305999997558594,
                "val_top5": 66.36000011230469
            },
            {
                "epoch": 6,
                "learning_rate": 0.4,
                "model_norm": 172.71453857421875,
                "train_grad_norm": 0.9022579511499998,
                "train_loss": 3.4418249130249023,
                "val_loss": 2.659292435913086,
                "val_top1": 42.52000000244141,
                "val_top5": 68.83799991699219
            },
            {
                "epoch": 7,
                "learning_rate": 0.4,
                "model_norm": 177.268310546875,
                "train_grad_norm": 0.9088291202448958,
                "train_loss": 3.3285019397735596,
                "val_loss": 2.6785198564147947,
                "val_top1": 42.75800003295898,
                "val_top5": 69.75600001464844
            },
            {
                "epoch": 8,
                "learning_rate": 0.4,
                "model_norm": 181.68104553222656,
                "train_grad_norm": 0.9162602141482382,
                "train_loss": 3.2476794719696045,
                "val_loss": 2.7636483846282958,
                "val_top1": 41.97400005004883,
                "val_top5": 68.09200001953126
            },
            {
                "epoch": 9,
                "learning_rate": 0.4,
                "model_norm": 185.79994201660156,
                "train_grad_norm": 0.9235808369424267,
                "train_loss": 3.1879191398620605,
                "val_loss": 2.4597888118362428,
                "val_top1": 46.202000017089844,
                "val_top5": 72.26999990966797
            },
            {
                "epoch": 10,
                "learning_rate": 0.4,
                "model_norm": 189.68650817871094,
                "train_grad_norm": 0.9287970786934577,
                "train_loss": 3.1391570568084717,
                "val_loss": 2.442347403411865,
                "val_top1": 45.87000001831055,
                "val_top5": 72.88999997314453
            },
            {
                "epoch": 11,
                "learning_rate": 0.4,
                "model_norm": 193.31227111816406,
                "train_grad_norm": 0.9339142359711408,
                "train_loss": 3.1003901958465576,
                "val_loss": 2.664441858139038,
                "val_top1": 43.07200001342773,
                "val_top5": 69.41200010253907
            },
            {
                "epoch": 12,
                "learning_rate": 0.4,
                "model_norm": 196.73739624023438,
                "train_grad_norm": 0.937799990693779,
                "train_loss": 3.0695900917053223,
                "val_loss": 2.3288032550048827,
                "val_top1": 49.62200004516602,
                "val_top5": 75.22400001953125
            },
            {
                "epoch": 13,
                "learning_rate": 0.4,
                "model_norm": 199.99530029296875,
                "train_grad_norm": 0.9412975493004749,
                "train_loss": 3.0443851947784424,
                "val_loss": 2.2692258366775513,
                "val_top1": 50.64200014648438,
                "val_top5": 75.974000078125
            },
            {
                "epoch": 14,
                "learning_rate": 0.4,
                "model_norm": 203.12669372558594,
                "train_grad_norm": 0.9449287320083872,
                "train_loss": 3.0205929279327393,
                "val_loss": 2.381392548980713,
                "val_top1": 48.010000017089844,
                "val_top5": 73.85200005859375
            },
            {
                "epoch": 15,
                "learning_rate": 0.4,
                "model_norm": 206.16505432128906,
                "train_grad_norm": 0.948193618690659,
                "train_loss": 3.001215934753418,
                "val_loss": 2.145868313598633,
                "val_top1": 53.4319999609375,
                "val_top5": 78.62399997802734
            },
            {
                "epoch": 16,
                "learning_rate": 0.4,
                "model_norm": 209.10206604003906,
                "train_grad_norm": 0.9502826095827998,
                "train_loss": 2.9854819774627686,
                "val_loss": 2.163861873435974,
                "val_top1": 52.1200000390625,
                "val_top5": 77.40599999023438
            },
            {
                "epoch": 17,
                "learning_rate": 0.4,
                "model_norm": 211.94546508789062,
                "train_grad_norm": 0.9533337228111711,
                "train_loss": 2.9691243171691895,
                "val_loss": 2.272862912902832,
                "val_top1": 49.5260000390625,
                "val_top5": 75.06799997558593
            },
            {
                "epoch": 18,
                "learning_rate": 0.4,
                "model_norm": 214.72230529785156,
                "train_grad_norm": 0.9553506062878121,
                "train_loss": 2.956183910369873,
                "val_loss": 2.125240773887634,
                "val_top1": 52.70600005859375,
                "val_top5": 77.9179999975586
            },
            {
                "epoch": 19,
                "learning_rate": 0.4,
                "model_norm": 217.35804748535156,
                "train_grad_norm": 0.9567313117956058,
                "train_loss": 2.943600654602051,
                "val_loss": 2.046815586242676,
                "val_top1": 53.59000001220703,
                "val_top5": 79.04799999023437
            },
            {
                "epoch": 20,
                "learning_rate": 0.4,
                "model_norm": 220.0094757080078,
                "train_grad_norm": 0.9595547879429849,
                "train_loss": 2.9350461959838867,
                "val_loss": 2.1818274645614624,
                "val_top1": 52.398000009765624,
                "val_top5": 78.19600001953125
            },
            {
                "epoch": 21,
                "learning_rate": 0.4,
                "model_norm": 222.5454864501953,
                "train_grad_norm": 0.9611428261876596,
                "train_loss": 2.9239611625671387,
                "val_loss": 2.239154165496826,
                "val_top1": 50.771999946289064,
                "val_top5": 76.029999921875
            },
            {
                "epoch": 22,
                "learning_rate": 0.4,
                "model_norm": 225.01759338378906,
                "train_grad_norm": 0.9618807417148313,
                "train_loss": 2.917198896408081,
                "val_loss": 2.1331974703598022,
                "val_top1": 52.95599997558594,
                "val_top5": 78.22800002929688
            },
            {
                "epoch": 23,
                "learning_rate": 0.4,
                "model_norm": 227.436279296875,
                "train_grad_norm": 0.9626142134862778,
                "train_loss": 2.908466339111328,
                "val_loss": 2.273724267196655,
                "val_top1": 51.31000008666992,
                "val_top5": 76.12000006591796
            },
            {
                "epoch": 24,
                "learning_rate": 0.4,
                "model_norm": 229.7989044189453,
                "train_grad_norm": 0.9637627573034664,
                "train_loss": 2.901036024093628,
                "val_loss": 2.5683204862213134,
                "val_top1": 45.92799996337891,
                "val_top5": 71.39000006347656
            },
            {
                "epoch": 25,
                "learning_rate": 0.4,
                "model_norm": 232.15826416015625,
                "train_grad_norm": 0.9652804490868896,
                "train_loss": 2.8947947025299072,
                "val_loss": 2.292823437652588,
                "val_top1": 49.68800002929687,
                "val_top5": 75.12199997558594
            },
            {
                "epoch": 26,
                "learning_rate": 0.4,
                "model_norm": 234.3701934814453,
                "train_grad_norm": 0.9642320270971128,
                "train_loss": 2.8876399993896484,
                "val_loss": 2.359271624221802,
                "val_top1": 48.65199994140625,
                "val_top5": 73.66999998291016
            },
            {
                "epoch": 27,
                "learning_rate": 0.4,
                "model_norm": 236.57347106933594,
                "train_grad_norm": 0.9654477217059406,
                "train_loss": 2.8808839321136475,
                "val_loss": 2.0908999966812134,
                "val_top1": 54.185999985351565,
                "val_top5": 78.80799997802734
            },
            {
                "epoch": 28,
                "learning_rate": 0.4,
                "model_norm": 238.74520874023438,
                "train_grad_norm": 0.965464002440393,
                "train_loss": 2.878621816635132,
                "val_loss": 2.0980401485824585,
                "val_top1": 54.350000083007814,
                "val_top5": 79.13799990478516
            },
            {
                "epoch": 29,
                "learning_rate": 0.4,
                "model_norm": 240.95974731445312,
                "train_grad_norm": 0.9673344318226877,
                "train_loss": 2.870448112487793,
                "val_loss": 2.0557776248168946,
                "val_top1": 54.28800001953125,
                "val_top5": 79.34
            },
            {
                "epoch": 30,
                "learning_rate": 0.4,
                "model_norm": 243.04852294921875,
                "train_grad_norm": 0.9665798471565782,
                "train_loss": 2.8685708045959473,
                "val_loss": 2.144233003768921,
                "val_top1": 53.56600000488281,
                "val_top5": 78.45200005859375
            },
            {
                "epoch": 31,
                "learning_rate": 0.4,
                "model_norm": 245.19398498535156,
                "train_grad_norm": 0.9679248691643346,
                "train_loss": 2.8628811836242676,
                "val_loss": 1.9495906688690186,
                "val_top1": 56.170000061035154,
                "val_top5": 80.4679999975586
            },
            {
                "epoch": 32,
                "learning_rate": 0.4,
                "model_norm": 247.18946838378906,
                "train_grad_norm": 0.9670862043521902,
                "train_loss": 2.855740547180176,
                "val_loss": 2.1602656625747683,
                "val_top1": 52.66999995849609,
                "val_top5": 77.9360000805664
            },
            {
                "epoch": 33,
                "learning_rate": 0.4,
                "model_norm": 249.2989959716797,
                "train_grad_norm": 0.9688613894097747,
                "train_loss": 2.8530325889587402,
                "val_loss": 2.0411784716796877,
                "val_top1": 53.70199999023438,
                "val_top5": 78.98799997314453
            },
            {
                "epoch": 34,
                "learning_rate": 0.4,
                "model_norm": 251.31993103027344,
                "train_grad_norm": 0.9686203447996447,
                "train_loss": 2.8496813774108887,
                "val_loss": 2.1426426000213623,
                "val_top1": 52.19199997558594,
                "val_top5": 77.99400006347656
            },
            {
                "epoch": 35,
                "learning_rate": 0.4,
                "model_norm": 253.33187866210938,
                "train_grad_norm": 0.9695865702132335,
                "train_loss": 2.846004009246826,
                "val_loss": 1.9884772358322143,
                "val_top1": 54.83399994628906,
                "val_top5": 79.70599989746094
            },
            {
                "epoch": 36,
                "learning_rate": 0.4,
                "model_norm": 255.2864990234375,
                "train_grad_norm": 0.9698345601656121,
                "train_loss": 2.845346212387085,
                "val_loss": 2.475345940628052,
                "val_top1": 47.72999996337891,
                "val_top5": 72.58600000732422
            },
            {
                "epoch": 37,
                "learning_rate": 0.4,
                "model_norm": 257.21600341796875,
                "train_grad_norm": 0.9699328555752651,
                "train_loss": 2.841653347015381,
                "val_loss": 2.0026269302368163,
                "val_top1": 55.12200009277344,
                "val_top5": 80.06400002197266
            },
            {
                "epoch": 38,
                "learning_rate": 0.4,
                "model_norm": 259.2279968261719,
                "train_grad_norm": 0.9722727972575147,
                "train_loss": 2.837676525115967,
                "val_loss": 2.1866624814224243,
                "val_top1": 52.29199995605469,
                "val_top5": 77.286000078125
            },
            {
                "epoch": 39,
                "learning_rate": 0.4,
                "model_norm": 261.0235290527344,
                "train_grad_norm": 0.9696063848932581,
                "train_loss": 2.8347887992858887,
                "val_loss": 2.1328400854492187,
                "val_top1": 53.28800002441406,
                "val_top5": 78.53200012939453
            },
            {
                "epoch": 40,
                "learning_rate": 0.4,
                "model_norm": 262.8606872558594,
                "train_grad_norm": 0.9698697501784544,
                "train_loss": 2.8305788040161133,
                "val_loss": 2.071056840438843,
                "val_top1": 54.262,
                "val_top5": 79.12599997314453
            },
            {
                "epoch": 41,
                "learning_rate": 0.4,
                "model_norm": 264.6859130859375,
                "train_grad_norm": 0.9708513415027136,
                "train_loss": 2.8273935317993164,
                "val_loss": 2.1535148817443845,
                "val_top1": 52.51600002441406,
                "val_top5": 77.92400009277344
            },
            {
                "epoch": 42,
                "learning_rate": 0.4,
                "model_norm": 266.569091796875,
                "train_grad_norm": 0.9718111414714344,
                "train_loss": 2.82534122467041,
                "val_loss": 2.4624870989227294,
                "val_top1": 47.04799996826172,
                "val_top5": 72.46400008789062
            },
            {
                "epoch": 43,
                "learning_rate": 0.4,
                "model_norm": 268.3955078125,
                "train_grad_norm": 0.9720954088612722,
                "train_loss": 2.8237180709838867,
                "val_loss": 2.0715167589187624,
                "val_top1": 54.40200005126953,
                "val_top5": 79.33
            },
            {
                "epoch": 44,
                "learning_rate": 0.4,
                "model_norm": 270.1556091308594,
                "train_grad_norm": 0.9709881915496331,
                "train_loss": 2.821575164794922,
                "val_loss": 1.8890052780532838,
                "val_top1": 57.10800006347656,
                "val_top5": 81.33799996582032
            },
            {
                "epoch": 45,
                "learning_rate": 0.4,
                "model_norm": 271.9014587402344,
                "train_grad_norm": 0.9715808350766734,
                "train_loss": 2.8185811042785645,
                "val_loss": 2.056696659698486,
                "val_top1": 55.19800002929688,
                "val_top5": 79.74599995117188
            },
            {
                "epoch": 46,
                "learning_rate": 0.4,
                "model_norm": 273.63665771484375,
                "train_grad_norm": 0.9707809908128299,
                "train_loss": 2.8154478073120117,
                "val_loss": 2.187453620529175,
                "val_top1": 51.407999967041015,
                "val_top5": 77.49400004150391
            },
            {
                "epoch": 47,
                "learning_rate": 0.4,
                "model_norm": 275.40521240234375,
                "train_grad_norm": 0.9725625655825353,
                "train_loss": 2.8142809867858887,
                "val_loss": 1.998365263748169,
                "val_top1": 55.352000068359374,
                "val_top5": 79.90200005126952
            },
            {
                "epoch": 48,
                "learning_rate": 0.4,
                "model_norm": 277.117431640625,
                "train_grad_norm": 0.9721367931160536,
                "train_loss": 2.8157081604003906,
                "val_loss": 2.0364844560241697,
                "val_top1": 54.38000001464844,
                "val_top5": 79.15600006835938
            },
            {
                "epoch": 49,
                "learning_rate": 0.4,
                "model_norm": 278.7344970703125,
                "train_grad_norm": 0.9706064459113615,
                "train_loss": 2.8104491233825684,
                "val_loss": 2.029074183921814,
                "val_top1": 54.31400007324219,
                "val_top5": 79.61599994873046
            },
            {
                "epoch": 50,
                "learning_rate": 0.4,
                "model_norm": 280.38421630859375,
                "train_grad_norm": 0.9713740900820929,
                "train_loss": 2.8097598552703857,
                "val_loss": 2.027357148323059,
                "val_top1": 54.55200002685547,
                "val_top5": 79.63800010253907
            },
            {
                "epoch": 51,
                "learning_rate": 0.4,
                "model_norm": 282.0740661621094,
                "train_grad_norm": 0.9724921728488429,
                "train_loss": 2.805417537689209,
                "val_loss": 2.2696728705978395,
                "val_top1": 50.57400003417969,
                "val_top5": 75.59599987548827
            },
            {
                "epoch": 52,
                "learning_rate": 0.4,
                "model_norm": 283.7242431640625,
                "train_grad_norm": 0.9723011579783937,
                "train_loss": 2.8055310249328613,
                "val_loss": 2.062717682609558,
                "val_top1": 54.58999990966797,
                "val_top5": 79.590000078125
            },
            {
                "epoch": 53,
                "learning_rate": 0.4,
                "model_norm": 285.3294982910156,
                "train_grad_norm": 0.9714900718700125,
                "train_loss": 2.8045473098754883,
                "val_loss": 2.2284411032867433,
                "val_top1": 50.768000034179686,
                "val_top5": 76.15200000488281
            },
            {
                "epoch": 54,
                "learning_rate": 0.4,
                "model_norm": 286.9717712402344,
                "train_grad_norm": 0.9730769126225213,
                "train_loss": 2.8022067546844482,
                "val_loss": 2.5187382506561278,
                "val_top1": 46.07399999511719,
                "val_top5": 71.8120000390625
            },
            {
                "epoch": 55,
                "learning_rate": 0.4,
                "model_norm": 288.5377197265625,
                "train_grad_norm": 0.9717876017311065,
                "train_loss": 2.798346757888794,
                "val_loss": 2.5989951293182374,
                "val_top1": 45.38000007446289,
                "val_top5": 70.24600006591797
            },
            {
                "epoch": 56,
                "learning_rate": 0.4,
                "model_norm": 290.18560791015625,
                "train_grad_norm": 0.9729292109494808,
                "train_loss": 2.8003084659576416,
                "val_loss": 2.01509551651001,
                "val_top1": 55.020000151367185,
                "val_top5": 79.91400010009765
            },
            {
                "epoch": 57,
                "learning_rate": 0.4,
                "model_norm": 291.7604064941406,
                "train_grad_norm": 0.9720401134444265,
                "train_loss": 2.799147367477417,
                "val_loss": 2.0919281951141357,
                "val_top1": 54.3940000390625,
                "val_top5": 78.92200001953125
            },
            {
                "epoch": 58,
                "learning_rate": 0.4,
                "model_norm": 293.2875061035156,
                "train_grad_norm": 0.9717689159804287,
                "train_loss": 2.796347141265869,
                "val_loss": 2.2209968066787718,
                "val_top1": 51.23600001098633,
                "val_top5": 76.24399999267578
            },
            {
                "epoch": 59,
                "learning_rate": 0.4,
                "model_norm": 294.7563171386719,
                "train_grad_norm": 0.9713181225073926,
                "train_loss": 2.7941508293151855,
                "val_loss": 1.905708598098755,
                "val_top1": 56.87000001708984,
                "val_top5": 81.16200002441406
            },
            {
                "epoch": 60,
                "learning_rate": 0.4,
                "model_norm": 296.29315185546875,
                "train_grad_norm": 0.9725805307867346,
                "train_loss": 2.792876720428467,
                "val_loss": 1.9852815836334228,
                "val_top1": 55.414000073242185,
                "val_top5": 80.04400006347656
            },
            {
                "epoch": 61,
                "learning_rate": 0.4,
                "model_norm": 297.8203125,
                "train_grad_norm": 0.9722142115299536,
                "train_loss": 2.7931439876556396,
                "val_loss": 1.9995060255432129,
                "val_top1": 55.576000034179685,
                "val_top5": 79.90600000732422
            },
            {
                "epoch": 62,
                "learning_rate": 0.4,
                "model_norm": 299.3487243652344,
                "train_grad_norm": 0.9730702301506915,
                "train_loss": 2.7906408309936523,
                "val_loss": 2.2338244446945192,
                "val_top1": 51.49999997802735,
                "val_top5": 76.56000004882813
            },
            {
                "epoch": 63,
                "learning_rate": 0.4,
                "model_norm": 300.7936096191406,
                "train_grad_norm": 0.9715619709372241,
                "train_loss": 2.7901148796081543,
                "val_loss": 1.909769455871582,
                "val_top1": 56.66600001953125,
                "val_top5": 81.49000013183594
            },
            {
                "epoch": 64,
                "learning_rate": 0.4,
                "model_norm": 302.2392883300781,
                "train_grad_norm": 0.9720191591209439,
                "train_loss": 2.788944959640503,
                "val_loss": 2.0433919984054567,
                "val_top1": 54.80799991699219,
                "val_top5": 79.71400009765625
            },
            {
                "epoch": 65,
                "learning_rate": 0.4,
                "model_norm": 303.6778564453125,
                "train_grad_norm": 0.9715767849286427,
                "train_loss": 2.7882962226867676,
                "val_loss": 2.0875618745803832,
                "val_top1": 53.289999921875,
                "val_top5": 78.33200001708984
            },
            {
                "epoch": 66,
                "learning_rate": 0.4,
                "model_norm": 305.15673828125,
                "train_grad_norm": 0.9727622570151839,
                "train_loss": 2.7872414588928223,
                "val_loss": 2.356427206726074,
                "val_top1": 48.22600005371094,
                "val_top5": 74.08800005615234
            },
            {
                "epoch": 67,
                "learning_rate": 0.4,
                "model_norm": 306.5767822265625,
                "train_grad_norm": 0.9720996333132489,
                "train_loss": 2.784829616546631,
                "val_loss": 1.9986272064208985,
                "val_top1": 54.218000029296874,
                "val_top5": 79.51400005371094
            },
            {
                "epoch": 68,
                "learning_rate": 0.4,
                "model_norm": 308.08709716796875,
                "train_grad_norm": 0.9739842481238811,
                "train_loss": 2.783698797225952,
                "val_loss": 2.0896512159729004,
                "val_top1": 54.16200000244141,
                "val_top5": 78.84799997802735
            },
            {
                "epoch": 69,
                "learning_rate": 0.4,
                "model_norm": 309.5274353027344,
                "train_grad_norm": 0.9734454672223224,
                "train_loss": 2.782858371734619,
                "val_loss": 2.111876448059082,
                "val_top1": 53.94999996337891,
                "val_top5": 78.86399998046875
            },
            {
                "epoch": 70,
                "learning_rate": 0.4,
                "model_norm": 310.9107971191406,
                "train_grad_norm": 0.9731540736791714,
                "train_loss": 2.782562732696533,
                "val_loss": 2.2328572468566894,
                "val_top1": 51.21199997314453,
                "val_top5": 76.19600002197265
            },
            {
                "epoch": 71,
                "learning_rate": 0.4,
                "model_norm": 312.3354187011719,
                "train_grad_norm": 0.9744246597011907,
                "train_loss": 2.7821741104125977,
                "val_loss": 1.9846917171096803,
                "val_top1": 56.372000053710934,
                "val_top5": 80.69000008300782
            },
            {
                "epoch": 72,
                "learning_rate": 0.4,
                "model_norm": 313.686767578125,
                "train_grad_norm": 0.9728493787454127,
                "train_loss": 2.778852939605713,
                "val_loss": 2.013607481918335,
                "val_top1": 54.736000078125,
                "val_top5": 79.70399997314453
            },
            {
                "epoch": 73,
                "learning_rate": 0.4,
                "model_norm": 315.04833984375,
                "train_grad_norm": 0.9725413612731681,
                "train_loss": 2.7791748046875,
                "val_loss": 2.000278983001709,
                "val_top1": 55.30400005859375,
                "val_top5": 79.615999921875
            },
            {
                "epoch": 74,
                "learning_rate": 0.4,
                "model_norm": 316.42535400390625,
                "train_grad_norm": 0.9730070312969777,
                "train_loss": 2.778364896774292,
                "val_loss": 2.0229466144561767,
                "val_top1": 54.95600014648438,
                "val_top5": 79.96799991699218
            },
            {
                "epoch": 75,
                "learning_rate": 0.4,
                "model_norm": 317.796875,
                "train_grad_norm": 0.9732965942795415,
                "train_loss": 2.7796597480773926,
                "val_loss": 1.9781597204971313,
                "val_top1": 55.8460000390625,
                "val_top5": 80.54399997070313
            },
            {
                "epoch": 76,
                "learning_rate": 0.4,
                "model_norm": 319.1359558105469,
                "train_grad_norm": 0.9729137849655297,
                "train_loss": 2.7766432762145996,
                "val_loss": 2.1786781173706053,
                "val_top1": 52.092000078125,
                "val_top5": 77.58999997802735
            },
            {
                "epoch": 77,
                "learning_rate": 0.4,
                "model_norm": 320.4538879394531,
                "train_grad_norm": 0.9725123150008829,
                "train_loss": 2.7745001316070557,
                "val_loss": 2.1589239154815676,
                "val_top1": 52.75599992675781,
                "val_top5": 77.98199997558594
            },
            {
                "epoch": 78,
                "learning_rate": 0.4,
                "model_norm": 321.8318176269531,
                "train_grad_norm": 0.9737971432097524,
                "train_loss": 2.7746126651763916,
                "val_loss": 2.2675754916381834,
                "val_top1": 49.930000078125,
                "val_top5": 75.70400002685547
            },
            {
                "epoch": 79,
                "learning_rate": 0.38095238095238093,
                "model_norm": 322.7025451660156,
                "train_grad_norm": 0.9746520388747486,
                "train_loss": 2.764699935913086,
                "val_loss": 1.9086867432403565,
                "val_top1": 58.05600007324219,
                "val_top5": 81.67600002685546
            },
            {
                "epoch": 80,
                "learning_rate": 0.36190476190476195,
                "model_norm": 323.4132080078125,
                "train_grad_norm": 0.9860126352500943,
                "train_loss": 2.7459208965301514,
                "val_loss": 1.9760648631286621,
                "val_top1": 55.666000009765625,
                "val_top5": 80.18800006347657
            },
            {
                "epoch": 81,
                "learning_rate": 0.3428571428571429,
                "model_norm": 323.9961853027344,
                "train_grad_norm": 0.9989716880043211,
                "train_loss": 2.722038984298706,
                "val_loss": 2.159971365356445,
                "val_top1": 52.61000006347656,
                "val_top5": 77.4660001171875
            },
            {
                "epoch": 82,
                "learning_rate": 0.3238095238095238,
                "model_norm": 324.4521484375,
                "train_grad_norm": 1.0135126026534078,
                "train_loss": 2.701380729675293,
                "val_loss": 1.92412708026886,
                "val_top1": 57.83600013671875,
                "val_top5": 81.42000004638672
            },
            {
                "epoch": 83,
                "learning_rate": 0.3047619047619048,
                "model_norm": 324.8420715332031,
                "train_grad_norm": 1.0287905647704783,
                "train_loss": 2.678675889968872,
                "val_loss": 1.8660372263336182,
                "val_top1": 58.34000003417969,
                "val_top5": 82.34799991210937
            },
            {
                "epoch": 84,
                "learning_rate": 0.28571428571428575,
                "model_norm": 325.1612854003906,
                "train_grad_norm": 1.0466240105814477,
                "train_loss": 2.656568765640259,
                "val_loss": 2.0842406508636473,
                "val_top1": 54.8399999609375,
                "val_top5": 79.48000005859375
            },
            {
                "epoch": 85,
                "learning_rate": 0.2666666666666667,
                "model_norm": 325.3660583496094,
                "train_grad_norm": 1.0639898079454824,
                "train_loss": 2.6298038959503174,
                "val_loss": 1.7467756451797485,
                "val_top1": 60.34200005859375,
                "val_top5": 83.72999993164062
            },
            {
                "epoch": 86,
                "learning_rate": 0.24761904761904763,
                "model_norm": 325.5453186035156,
                "train_grad_norm": 1.0858438898666058,
                "train_loss": 2.602879524230957,
                "val_loss": 1.7919459711456298,
                "val_top1": 60.386000092773436,
                "val_top5": 83.72599999755859
            },
            {
                "epoch": 87,
                "learning_rate": 0.22857142857142856,
                "model_norm": 325.613037109375,
                "train_grad_norm": 1.1068268683567806,
                "train_loss": 2.5759992599487305,
                "val_loss": 1.7776702530670165,
                "val_top1": 60.36600008056641,
                "val_top5": 83.44400004150391
            },
            {
                "epoch": 88,
                "learning_rate": 0.20952380952380956,
                "model_norm": 325.5784912109375,
                "train_grad_norm": 1.1294859141791893,
                "train_loss": 2.545241117477417,
                "val_loss": 1.7761689227294921,
                "val_top1": 59.971999973144534,
                "val_top5": 83.50000010498047
            },
            {
                "epoch": 89,
                "learning_rate": 0.19047619047619047,
                "model_norm": 325.4537658691406,
                "train_grad_norm": 1.155918589164099,
                "train_loss": 2.514430522918701,
                "val_loss": 1.7293310461807252,
                "val_top1": 60.74199997314453,
                "val_top5": 84.0500000366211
            },
            {
                "epoch": 90,
                "learning_rate": 0.17142857142857146,
                "model_norm": 325.2460021972656,
                "train_grad_norm": 1.1835609977354637,
                "train_loss": 2.482426643371582,
                "val_loss": 1.5520873066711425,
                "val_top1": 64.238,
                "val_top5": 86.39000000976563
            },
            {
                "epoch": 91,
                "learning_rate": 0.1523809523809524,
                "model_norm": 324.9453430175781,
                "train_grad_norm": 1.2142021165321122,
                "train_loss": 2.4456419944763184,
                "val_loss": 1.5712954787826539,
                "val_top1": 64.1180000390625,
                "val_top5": 86.13600003173828
            },
            {
                "epoch": 92,
                "learning_rate": 0.13333333333333336,
                "model_norm": 324.5622863769531,
                "train_grad_norm": 1.2480219935251462,
                "train_loss": 2.4084599018096924,
                "val_loss": 1.4253814968490601,
                "val_top1": 67.01399993164063,
                "val_top5": 88.29000012695313
            },
            {
                "epoch": 93,
                "learning_rate": 0.11428571428571428,
                "model_norm": 324.0908508300781,
                "train_grad_norm": 1.2858106731994918,
                "train_loss": 2.3668227195739746,
                "val_loss": 1.4231149000167846,
                "val_top1": 67.55400006591798,
                "val_top5": 88.17999997314453
            },
            {
                "epoch": 94,
                "learning_rate": 0.09523809523809526,
                "model_norm": 323.5373229980469,
                "train_grad_norm": 1.3257709243978233,
                "train_loss": 2.317612648010254,
                "val_loss": 1.3945927935791016,
                "val_top1": 68.34400006835938,
                "val_top5": 88.59600007324218
            },
            {
                "epoch": 95,
                "learning_rate": 0.0761904761904762,
                "model_norm": 322.9096984863281,
                "train_grad_norm": 1.3692255935949804,
                "train_loss": 2.2653751373291016,
                "val_loss": 1.3210851564407349,
                "val_top1": 69.09200006347656,
                "val_top5": 89.20399997558594
            },
            {
                "epoch": 96,
                "learning_rate": 0.05714285714285716,
                "model_norm": 322.2525939941406,
                "train_grad_norm": 1.4177325446145306,
                "train_loss": 2.2045040130615234,
                "val_loss": 1.262376431312561,
                "val_top1": 70.78399997802734,
                "val_top5": 90.02799997558594
            },
            {
                "epoch": 97,
                "learning_rate": 0.0380952380952381,
                "model_norm": 321.6009826660156,
                "train_grad_norm": 1.4604983885428995,
                "train_loss": 2.1359751224517822,
                "val_loss": 1.1680419285011292,
                "val_top1": 72.77800004638672,
                "val_top5": 91.41799991699219
            },
            {
                "epoch": 98,
                "learning_rate": 0.01904761904761907,
                "model_norm": 321.06744384765625,
                "train_grad_norm": 1.495150858753491,
                "train_loss": 2.0630199909210205,
                "val_loss": 1.0621363062477112,
                "val_top1": 75.12000001220703,
                "val_top5": 92.44800009277344
            },
            {
                "epoch": 99,
                "learning_rate": 0.0,
                "model_norm": 320.83331298828125,
                "train_grad_norm": 1.5051529698375152,
                "train_loss": 1.9867218732833862,
                "val_loss": 1.015911143169403,
                "val_top1": 76.20600006347657,
                "val_top5": 93.13400006835937
            }
        ],
        "summary": {
            "len_train_loader": 1251,
            "start_time": "2025-03-27 05:52:23.561633"
        }
    },
    {
        "config": {
            "batch_size": 256,
            "dataset": "imagenet1k",
            "gradient_accumulation": 1,
            "max_epoch": 100,
            "model": "resnet50",
            "opt": {
                "lr": 0.2,
                "lr_schedule": "cosine",
                "momentum": 0.9,
                "name": "momentum",
                "weight_decay": 0.0001
            },
            "run_id": 0
        },
        "history": [
            {
                "epoch": 0,
                "learning_rate": 0.04000800000000001,
                "model_norm": 234.07186889648438,
                "train_loss": 6.552799701690674,
                "val_loss": 6.037252909545899,
                "val_top1": 3.1820000021362307,
                "val_top5": 9.778000007324218
            },
            {
                "epoch": 1,
                "learning_rate": 0.08000600000000001,
                "model_norm": 221.85133361816406,
                "train_loss": 5.943948745727539,
                "val_loss": 5.304778470458984,
                "val_top1": 7.667999985961914,
                "val_top5": 19.87600000366211
            },
            {
                "epoch": 2,
                "learning_rate": 0.12000400000000001,
                "model_norm": 205.14031982421875,
                "train_loss": 5.318328857421875,
                "val_loss": 4.836578750991821,
                "val_top1": 11.964000008544922,
                "val_top5": 28.774000050048826
            },
            {
                "epoch": 3,
                "learning_rate": 0.16000200000000003,
                "model_norm": 188.3626251220703,
                "train_loss": 4.690803527832031,
                "val_loss": 3.908398317642212,
                "val_top1": 21.920000024414062,
                "val_top5": 44.83400002685547
            },
            {
                "epoch": 4,
                "learning_rate": 0.1987688340595138,
                "model_norm": 175.00296020507812,
                "train_loss": 4.215302467346191,
                "val_loss": 3.627287672729492,
                "val_top1": 26.300000006103517,
                "val_top5": 51.204000024414064
            },
            {
                "epoch": 5,
                "learning_rate": 0.1982287250728689,
                "model_norm": 166.84011840820312,
                "train_loss": 3.850215435028076,
                "val_loss": 3.0203130815124513,
                "val_top1": 35.595999990234375,
                "val_top5": 62.0899999609375
            },
            {
                "epoch": 6,
                "learning_rate": 0.19759167619387474,
                "model_norm": 162.9285430908203,
                "train_loss": 3.5918540954589844,
                "val_loss": 2.780903256530762,
                "val_top1": 40.38999998046875,
                "val_top5": 67.03200009521484
            },
            {
                "epoch": 7,
                "learning_rate": 0.1968583161128631,
                "model_norm": 161.7611083984375,
                "train_loss": 3.417708158493042,
                "val_loss": 2.5501452170562744,
                "val_top1": 44.025999986572266,
                "val_top5": 70.4079999609375
            },
            {
                "epoch": 8,
                "learning_rate": 0.19602936856769432,
                "model_norm": 162.18898010253906,
                "train_loss": 3.2869820594787598,
                "val_loss": 2.4274717673873902,
                "val_top1": 46.7919999597168,
                "val_top5": 73.08400001464844
            },
            {
                "epoch": 9,
                "learning_rate": 0.19510565162951538,
                "model_norm": 163.41970825195312,
                "train_loss": 3.1882948875427246,
                "val_loss": 2.3007335512161253,
                "val_top1": 48.61999998046875,
                "val_top5": 74.89399991699219
            },
            {
                "epoch": 10,
                "learning_rate": 0.19408807689542257,
                "model_norm": 165.0523223876953,
                "train_loss": 3.110159158706665,
                "val_loss": 2.099063591995239,
                "val_top1": 52.02200010498047,
                "val_top5": 77.514
            },
            {
                "epoch": 11,
                "learning_rate": 0.19297764858882516,
                "model_norm": 166.8182373046875,
                "train_loss": 3.0475010871887207,
                "val_loss": 2.2187391185760497,
                "val_top1": 51.12800008300781,
                "val_top5": 76.67799997070313
            },
            {
                "epoch": 12,
                "learning_rate": 0.19177546256839811,
                "model_norm": 168.61012268066406,
                "train_loss": 2.996967315673828,
                "val_loss": 2.2368530543518066,
                "val_top1": 51.31999995605469,
                "val_top5": 76.58599990478515
            },
            {
                "epoch": 13,
                "learning_rate": 0.19048270524660196,
                "model_norm": 170.38937377929688,
                "train_loss": 2.95440936088562,
                "val_loss": 2.1642927393341065,
                "val_top1": 53.39999995361328,
                "val_top5": 77.97600000976563
            },
            {
                "epoch": 14,
                "learning_rate": 0.18910065241883678,
                "model_norm": 172.03709411621094,
                "train_loss": 2.9165101051330566,
                "val_loss": 2.1606717335128782,
                "val_top1": 52.18999998046875,
                "val_top5": 77.30999999023437
            },
            {
                "epoch": 15,
                "learning_rate": 0.18763066800438635,
                "model_norm": 173.6806182861328,
                "train_loss": 2.8849921226501465,
                "val_loss": 2.1920520124053957,
                "val_top1": 52.81199999511719,
                "val_top5": 78.25600008300782
            },
            {
                "epoch": 16,
                "learning_rate": 0.18607420270039438,
                "model_norm": 175.25587463378906,
                "train_loss": 2.8568201065063477,
                "val_loss": 2.2318254180145263,
                "val_top1": 52.26400005615234,
                "val_top5": 77.35800003417968
            },
            {
                "epoch": 17,
                "learning_rate": 0.1844327925502015,
                "model_norm": 176.7479705810547,
                "train_loss": 2.8307301998138428,
                "val_loss": 1.9760099210357667,
                "val_top1": 55.191999921875,
                "val_top5": 80.03400004882812
            },
            {
                "epoch": 18,
                "learning_rate": 0.1827080574274562,
                "model_norm": 178.18177795410156,
                "train_loss": 2.8083908557891846,
                "val_loss": 1.9535912377166749,
                "val_top1": 56.819999982910154,
                "val_top5": 80.95800002197265
            },
            {
                "epoch": 19,
                "learning_rate": 0.18090169943749476,
                "model_norm": 179.49977111816406,
                "train_loss": 2.786313533782959,
                "val_loss": 1.8932534648513795,
                "val_top1": 57.902000034179686,
                "val_top5": 81.89199996337891
            },
            {
                "epoch": 20,
                "learning_rate": 0.17901550123756904,
                "model_norm": 180.8182830810547,
                "train_loss": 2.7681281566619873,
                "val_loss": 2.0280736030578614,
                "val_top1": 55.52600001953125,
                "val_top5": 80.15199991943359
            },
            {
                "epoch": 21,
                "learning_rate": 0.17705132427757894,
                "model_norm": 182.08518981933594,
                "train_loss": 2.750185012817383,
                "val_loss": 1.9398287322616576,
                "val_top1": 56.19200000732422,
                "val_top5": 80.69200013671875
            },
            {
                "epoch": 22,
                "learning_rate": 0.17501110696304598,
                "model_norm": 183.27760314941406,
                "train_loss": 2.7330336570739746,
                "val_loss": 1.8405730133056641,
                "val_top1": 58.52800001220703,
                "val_top5": 82.66599991210937
            },
            {
                "epoch": 23,
                "learning_rate": 0.17289686274214117,
                "model_norm": 184.46449279785156,
                "train_loss": 2.717191696166992,
                "val_loss": 1.8357243202590943,
                "val_top1": 58.860000078125,
                "val_top5": 82.52200000732422
            },
            {
                "epoch": 24,
                "learning_rate": 0.17071067811865476,
                "model_norm": 185.57313537597656,
                "train_loss": 2.701540946960449,
                "val_loss": 2.0013623527145388,
                "val_top1": 55.79600002441406,
                "val_top5": 80.22599998046876
            },
            {
                "epoch": 25,
                "learning_rate": 0.16845471059286887,
                "model_norm": 186.60658264160156,
                "train_loss": 2.6867308616638184,
                "val_loss": 1.8356908488082886,
                "val_top1": 57.97000000732422,
                "val_top5": 82.27799993652344
            },
            {
                "epoch": 26,
                "learning_rate": 0.1661311865323652,
                "model_norm": 187.66778564453125,
                "train_loss": 2.6722183227539062,
                "val_loss": 1.7664478963851928,
                "val_top1": 59.474000102539065,
                "val_top5": 83.29000001708984
            },
            {
                "epoch": 27,
                "learning_rate": 0.16374239897486897,
                "model_norm": 188.61337280273438,
                "train_loss": 2.65901517868042,
                "val_loss": 1.7030466966629028,
                "val_top1": 60.80000005859375,
                "val_top5": 84.22400006835937
            },
            {
                "epoch": 28,
                "learning_rate": 0.16129070536529766,
                "model_norm": 189.533203125,
                "train_loss": 2.6473031044006348,
                "val_loss": 1.7456463047027588,
                "val_top1": 60.600000002441405,
                "val_top5": 83.74600004882812
            },
            {
                "epoch": 29,
                "learning_rate": 0.15877852522924732,
                "model_norm": 190.4375762939453,
                "train_loss": 2.633235454559326,
                "val_loss": 1.766419591331482,
                "val_top1": 59.92199999511719,
                "val_top5": 83.69400001464844
            },
            {
                "epoch": 30,
                "learning_rate": 0.1562083377852131,
                "model_norm": 191.30096435546875,
                "train_loss": 2.6266047954559326,
                "val_loss": 1.815327038269043,
                "val_top1": 59.74200001953125,
                "val_top5": 83.14400016601563
            },
            {
                "epoch": 31,
                "learning_rate": 0.15358267949789967,
                "model_norm": 192.1345672607422,
                "train_loss": 2.6110308170318604,
                "val_loss": 1.7307233588409423,
                "val_top1": 60.72000001953125,
                "val_top5": 84.20000010986328
            },
            {
                "epoch": 32,
                "learning_rate": 0.15090414157503715,
                "model_norm": 192.91574096679688,
                "train_loss": 2.5980448722839355,
                "val_loss": 1.650607216796875,
                "val_top1": 61.834000021972656,
                "val_top5": 84.87199992919922
            },
            {
                "epoch": 33,
                "learning_rate": 0.14817536741017154,
                "model_norm": 193.68255615234375,
                "train_loss": 2.5879952907562256,
                "val_loss": 1.8100331186676026,
                "val_top1": 58.85999995117187,
                "val_top5": 82.88600016601562
            },
            {
                "epoch": 34,
                "learning_rate": 0.14539904997395467,
                "model_norm": 194.38035583496094,
                "train_loss": 2.576272487640381,
                "val_loss": 1.6418911153030395,
                "val_top1": 62.875999997558594,
                "val_top5": 85.68000013671875
            },
            {
                "epoch": 35,
                "learning_rate": 0.14257792915650727,
                "model_norm": 195.07159423828125,
                "train_loss": 2.565577268600464,
                "val_loss": 1.842898504524231,
                "val_top1": 58.39599993652344,
                "val_top5": 82.06400007324218
            },
            {
                "epoch": 36,
                "learning_rate": 0.1397147890634781,
                "model_norm": 195.7198944091797,
                "train_loss": 2.5576796531677246,
                "val_loss": 1.6962744719314575,
                "val_top1": 62.17599995605469,
                "val_top5": 84.80999993896485
            },
            {
                "epoch": 37,
                "learning_rate": 0.1368124552684678,
                "model_norm": 196.32879638671875,
                "train_loss": 2.545713424682617,
                "val_loss": 1.7707645338439941,
                "val_top1": 60.42399997070312,
                "val_top5": 83.84999990722656
            },
            {
                "epoch": 38,
                "learning_rate": 0.13387379202452918,
                "model_norm": 196.91659545898438,
                "train_loss": 2.5345096588134766,
                "val_loss": 1.6754915758132936,
                "val_top1": 62.33999994140625,
                "val_top5": 84.93199995361329
            },
            {
                "epoch": 39,
                "learning_rate": 0.13090169943749475,
                "model_norm": 197.4620361328125,
                "train_loss": 2.5242979526519775,
                "val_loss": 1.6340573940277099,
                "val_top1": 62.59399994873047,
                "val_top5": 85.25000000732422
            },
            {
                "epoch": 40,
                "learning_rate": 0.12789911060392295,
                "model_norm": 198.0003204345703,
                "train_loss": 2.5112338066101074,
                "val_loss": 1.629468864402771,
                "val_top1": 62.938000083007815,
                "val_top5": 85.5140000366211
            },
            {
                "epoch": 41,
                "learning_rate": 0.12486898871648551,
                "model_norm": 198.48171997070312,
                "train_loss": 2.5012245178222656,
                "val_loss": 1.5963788497924805,
                "val_top1": 63.009999916992186,
                "val_top5": 85.47800019042968
            },
            {
                "epoch": 42,
                "learning_rate": 0.12181432413965426,
                "model_norm": 198.92063903808594,
                "train_loss": 2.4886608123779297,
                "val_loss": 1.720824899635315,
                "val_top1": 61.61600010498047,
                "val_top5": 84.1059998828125
            },
            {
                "epoch": 43,
                "learning_rate": 0.11873813145857248,
                "model_norm": 199.37452697753906,
                "train_loss": 2.479307174682617,
                "val_loss": 1.5576885600852965,
                "val_top1": 64.60800003417968,
                "val_top5": 86.796000078125
            },
            {
                "epoch": 44,
                "learning_rate": 0.1156434465040231,
                "model_norm": 199.77735900878906,
                "train_loss": 2.468705415725708,
                "val_loss": 1.5477862567520142,
                "val_top1": 65.02800006347657,
                "val_top5": 86.72800005615234
            },
            {
                "epoch": 45,
                "learning_rate": 0.11253332335643043,
                "model_norm": 200.15151977539062,
                "train_loss": 2.4578371047973633,
                "val_loss": 1.7208437479782104,
                "val_top1": 62.01999997558594,
                "val_top5": 84.56999991210938
            },
            {
                "epoch": 46,
                "learning_rate": 0.10941083133185144,
                "model_norm": 200.47982788085938,
                "train_loss": 2.4450693130493164,
                "val_loss": 1.7215855045318604,
                "val_top1": 60.85400002929688,
                "val_top5": 84.12199998779298
            },
            {
                "epoch": 47,
                "learning_rate": 0.10627905195293136,
                "model_norm": 200.7976837158203,
                "train_loss": 2.436235189437866,
                "val_loss": 1.5274497087860108,
                "val_top1": 64.40600004638672,
                "val_top5": 86.27600005615234
            },
            {
                "epoch": 48,
                "learning_rate": 0.10314107590781281,
                "model_norm": 201.08082580566406,
                "train_loss": 2.42468523979187,
                "val_loss": 1.498955059337616,
                "val_top1": 65.1460000830078,
                "val_top5": 86.87200013183593
            },
            {
                "epoch": 49,
                "learning_rate": 0.1,
                "model_norm": 201.35635375976562,
                "train_loss": 2.4146406650543213,
                "val_loss": 1.7186675778579712,
                "val_top1": 61.880000021972656,
                "val_top5": 84.49400001220702
            },
            {
                "epoch": 50,
                "learning_rate": 0.0968589240921872,
                "model_norm": 201.60382080078125,
                "train_loss": 2.403407335281372,
                "val_loss": 1.5475595442581176,
                "val_top1": 64.91599999511719,
                "val_top5": 86.56000008789063
            },
            {
                "epoch": 51,
                "learning_rate": 0.09372094804706867,
                "model_norm": 201.81150817871094,
                "train_loss": 2.3897793292999268,
                "val_loss": 1.4756032515335082,
                "val_top1": 65.86800009277344,
                "val_top5": 87.204
            },
            {
                "epoch": 52,
                "learning_rate": 0.09058916866814859,
                "model_norm": 201.9969482421875,
                "train_loss": 2.3786206245422363,
                "val_loss": 1.5286368049621581,
                "val_top1": 65.44800010253907,
                "val_top5": 86.81400008789062
            },
            {
                "epoch": 53,
                "learning_rate": 0.0874666766435696,
                "model_norm": 202.1833038330078,
                "train_loss": 2.3663151264190674,
                "val_loss": 1.4600220356369018,
                "val_top1": 66.29399995849609,
                "val_top5": 87.520000078125
            },
            {
                "epoch": 54,
                "learning_rate": 0.08435655349597693,
                "model_norm": 202.3235626220703,
                "train_loss": 2.3540358543395996,
                "val_loss": 1.5982201221466064,
                "val_top1": 63.98600005615234,
                "val_top5": 85.98199993408203
            },
            {
                "epoch": 55,
                "learning_rate": 0.08126186854142754,
                "model_norm": 202.43124389648438,
                "train_loss": 2.3413138389587402,
                "val_loss": 1.4466150081634521,
                "val_top1": 66.60600008300781,
                "val_top5": 87.99000005126953
            },
            {
                "epoch": 56,
                "learning_rate": 0.07818567586034575,
                "model_norm": 202.5395965576172,
                "train_loss": 2.3313229084014893,
                "val_loss": 1.456577632484436,
                "val_top1": 66.46199993408203,
                "val_top5": 87.83199986816406
            },
            {
                "epoch": 57,
                "learning_rate": 0.07513101128351454,
                "model_norm": 202.62640380859375,
                "train_loss": 2.3177404403686523,
                "val_loss": 1.5279756172180177,
                "val_top1": 65.60200001464844,
                "val_top5": 86.80600002929687
            },
            {
                "epoch": 58,
                "learning_rate": 0.07210088939607709,
                "model_norm": 202.67776489257812,
                "train_loss": 2.3060922622680664,
                "val_loss": 1.4251228840446473,
                "val_top1": 67.36399990722656,
                "val_top5": 88.386000078125
            },
            {
                "epoch": 59,
                "learning_rate": 0.06909830056250527,
                "model_norm": 202.68919372558594,
                "train_loss": 2.290738582611084,
                "val_loss": 1.411850155353546,
                "val_top1": 67.45200003173828,
                "val_top5": 88.28000012695313
            },
            {
                "epoch": 60,
                "learning_rate": 0.06612620797547086,
                "model_norm": 202.7079315185547,
                "train_loss": 2.278888702392578,
                "val_loss": 1.317465803050995,
                "val_top1": 69.36599997314453,
                "val_top5": 89.32799994628907
            },
            {
                "epoch": 61,
                "learning_rate": 0.06318754473153224,
                "model_norm": 202.7077178955078,
                "train_loss": 2.266653060913086,
                "val_loss": 1.4771591008377076,
                "val_top1": 66.49400009521484,
                "val_top5": 87.6680000805664
            },
            {
                "epoch": 62,
                "learning_rate": 0.06028521093652193,
                "model_norm": 202.6925048828125,
                "train_loss": 2.250857353210449,
                "val_loss": 1.4446872788238525,
                "val_top1": 67.5079999609375,
                "val_top5": 88.08399997558594
            },
            {
                "epoch": 63,
                "learning_rate": 0.05742207084349274,
                "model_norm": 202.6537628173828,
                "train_loss": 2.2383551597595215,
                "val_loss": 1.3598510372543335,
                "val_top1": 68.72800000488282,
                "val_top5": 89.28000007324219
            },
            {
                "epoch": 64,
                "learning_rate": 0.05460095002604533,
                "model_norm": 202.597900390625,
                "train_loss": 2.2245962619781494,
                "val_loss": 1.3616288628387452,
                "val_top1": 68.2239999584961,
                "val_top5": 88.84599989257812
            },
            {
                "epoch": 65,
                "learning_rate": 0.05182463258982846,
                "model_norm": 202.5243682861328,
                "train_loss": 2.2101690769195557,
                "val_loss": 1.4437418194580078,
                "val_top1": 67.18800002197266,
                "val_top5": 87.91000008300782
            },
            {
                "epoch": 66,
                "learning_rate": 0.04909585842496287,
                "model_norm": 202.4429473876953,
                "train_loss": 2.195721387863159,
                "val_loss": 1.2970645051765441,
                "val_top1": 70.21799992919922,
                "val_top5": 89.740000078125
            },
            {
                "epoch": 67,
                "learning_rate": 0.04641732050210036,
                "model_norm": 202.33128356933594,
                "train_loss": 2.1794424057006836,
                "val_loss": 1.2381298389053346,
                "val_top1": 70.75999998046875,
                "val_top5": 90.34399981445313
            },
            {
                "epoch": 68,
                "learning_rate": 0.04379166221478697,
                "model_norm": 202.21237182617188,
                "train_loss": 2.1636993885040283,
                "val_loss": 1.2459068105316162,
                "val_top1": 71.04200000732422,
                "val_top5": 90.3180000805664
            },
            {
                "epoch": 69,
                "learning_rate": 0.0412214747707527,
                "model_norm": 202.08389282226562,
                "train_loss": 2.150202751159668,
                "val_loss": 1.274345359954834,
                "val_top1": 70.7139998779297,
                "val_top5": 90.13400012939454
            },
            {
                "epoch": 70,
                "learning_rate": 0.038709294634702344,
                "model_norm": 201.9381561279297,
                "train_loss": 2.1349830627441406,
                "val_loss": 1.182050849494934,
                "val_top1": 72.13599991699219,
                "val_top5": 90.94800009765625
            },
            {
                "epoch": 71,
                "learning_rate": 0.03625760102513103,
                "model_norm": 201.7880859375,
                "train_loss": 2.1189889907836914,
                "val_loss": 1.2406307245826722,
                "val_top1": 71.344,
                "val_top5": 90.63399984375
            },
            {
                "epoch": 72,
                "learning_rate": 0.03386881346763483,
                "model_norm": 201.61886596679688,
                "train_loss": 2.102705955505371,
                "val_loss": 1.2243262644004822,
                "val_top1": 71.77399997314453,
                "val_top5": 90.59199999267578
            },
            {
                "epoch": 73,
                "learning_rate": 0.03154528940713116,
                "model_norm": 201.4479217529297,
                "train_loss": 2.0856451988220215,
                "val_loss": 1.1679092558670043,
                "val_top1": 72.58000004638671,
                "val_top5": 91.0700000415039
            },
            {
                "epoch": 74,
                "learning_rate": 0.029289321881345223,
                "model_norm": 201.2671356201172,
                "train_loss": 2.0699002742767334,
                "val_loss": 1.1839427572250367,
                "val_top1": 72.55200002441406,
                "val_top5": 91.03799997070313
            },
            {
                "epoch": 75,
                "learning_rate": 0.027103137257858834,
                "model_norm": 201.0830535888672,
                "train_loss": 2.0551936626434326,
                "val_loss": 1.1609854674720763,
                "val_top1": 73.19200005126953,
                "val_top5": 91.58000002197265
            },
            {
                "epoch": 76,
                "learning_rate": 0.024988893036954042,
                "model_norm": 200.8873748779297,
                "train_loss": 2.0357704162597656,
                "val_loss": 1.1702742915916442,
                "val_top1": 72.87199996582031,
                "val_top5": 91.29800001708985
            },
            {
                "epoch": 77,
                "learning_rate": 0.022948675722421086,
                "model_norm": 200.69192504882812,
                "train_loss": 2.018796682357788,
                "val_loss": 1.117676941242218,
                "val_top1": 73.8680000415039,
                "val_top5": 91.79799993652344
            },
            {
                "epoch": 78,
                "learning_rate": 0.020984498762430984,
                "model_norm": 200.49301147460938,
                "train_loss": 2.00258731842041,
                "val_loss": 1.1337406645202637,
                "val_top1": 73.5360001220703,
                "val_top5": 91.84399999267578
            },
            {
                "epoch": 79,
                "learning_rate": 0.019098300562505267,
                "model_norm": 200.28915405273438,
                "train_loss": 1.9853944778442383,
                "val_loss": 1.1060229873466492,
                "val_top1": 74.47800002197266,
                "val_top5": 92.09600014648437
            },
            {
                "epoch": 80,
                "learning_rate": 0.017291942572543805,
                "model_norm": 200.08953857421875,
                "train_loss": 1.9685965776443481,
                "val_loss": 1.1069604231071473,
                "val_top1": 74.45200004394532,
                "val_top5": 91.95400001464844
            },
            {
                "epoch": 81,
                "learning_rate": 0.015567207449798493,
                "model_norm": 199.89207458496094,
                "train_loss": 1.9482814073562622,
                "val_loss": 1.0898883640670776,
                "val_top1": 74.5999999609375,
                "val_top5": 92.24199993896484
            },
            {
                "epoch": 82,
                "learning_rate": 0.013925797299605648,
                "model_norm": 199.69725036621094,
                "train_loss": 1.9317536354064941,
                "val_loss": 1.0937901725006103,
                "val_top1": 74.5499999609375,
                "val_top5": 92.29399996337891
            },
            {
                "epoch": 83,
                "learning_rate": 0.012369331995613665,
                "model_norm": 199.5100555419922,
                "train_loss": 1.9159135818481445,
                "val_loss": 1.0692575130462647,
                "val_top1": 75.06800001464843,
                "val_top5": 92.47600009277343
            },
            {
                "epoch": 84,
                "learning_rate": 0.010899347581163222,
                "model_norm": 199.32962036132812,
                "train_loss": 1.8978886604309082,
                "val_loss": 1.091595656452179,
                "val_top1": 74.61600007324219,
                "val_top5": 92.27400001708985
            },
            {
                "epoch": 85,
                "learning_rate": 0.009517294753398043,
                "model_norm": 199.15603637695312,
                "train_loss": 1.881469964981079,
                "val_loss": 1.0610847935295105,
                "val_top1": 75.6459999609375,
                "val_top5": 92.69400001464844
            },
            {
                "epoch": 86,
                "learning_rate": 0.008224537431601887,
                "model_norm": 198.99545288085938,
                "train_loss": 1.862800121307373,
                "val_loss": 1.0412272360038757,
                "val_top1": 75.98200001708985,
                "val_top5": 92.97999991210938
            },
            {
                "epoch": 87,
                "learning_rate": 0.0070223514111748655,
                "model_norm": 198.84671020507812,
                "train_loss": 1.8483242988586426,
                "val_loss": 1.0411246835517882,
                "val_top1": 75.8200000366211,
                "val_top5": 92.83200001464844
            },
            {
                "epoch": 88,
                "learning_rate": 0.005911923104577455,
                "model_norm": 198.71200561523438,
                "train_loss": 1.8319331407546997,
                "val_loss": 1.030106625289917,
                "val_top1": 76.27000006591797,
                "val_top5": 92.97399998779296
            },
            {
                "epoch": 89,
                "learning_rate": 0.004894348370484647,
                "model_norm": 198.5930633544922,
                "train_loss": 1.8167288303375244,
                "val_loss": 1.02427750125885,
                "val_top1": 76.49800001220703,
                "val_top5": 93.12799996337891
            },
            {
                "epoch": 90,
                "learning_rate": 0.003970631432305705,
                "model_norm": 198.48956298828125,
                "train_loss": 1.8050960302352905,
                "val_loss": 1.0140593359375,
                "val_top1": 76.68999993896485,
                "val_top5": 93.20000001464844
            },
            {
                "epoch": 91,
                "learning_rate": 0.0031416838871368927,
                "model_norm": 198.40219116210938,
                "train_loss": 1.7909435033798218,
                "val_loss": 1.0060294381332398,
                "val_top1": 76.83800006591797,
                "val_top5": 93.27399998779296
            },
            {
                "epoch": 92,
                "learning_rate": 0.0024083238061252676,
                "model_norm": 198.3303985595703,
                "train_loss": 1.780777096748352,
                "val_loss": 1.0153950563812255,
                "val_top1": 76.64000006347656,
                "val_top5": 93.19000009033203
            },
            {
                "epoch": 93,
                "learning_rate": 0.001771274927131128,
                "model_norm": 198.2743682861328,
                "train_loss": 1.7731120586395264,
                "val_loss": 1.007699072856903,
                "val_top1": 76.83999998779296,
                "val_top5": 93.36799998779297
            },
            {
                "epoch": 94,
                "learning_rate": 0.0012311659404862342,
                "model_norm": 198.23257446289062,
                "train_loss": 1.7628815174102783,
                "val_loss": 0.9984651715660096,
                "val_top1": 77.0239999609375,
                "val_top5": 93.43600006591797
            },
            {
                "epoch": 95,
                "learning_rate": 0.0007885298685522236,
                "model_norm": 198.2036590576172,
                "train_loss": 1.7562099695205688,
                "val_loss": 0.999527120513916,
                "val_top1": 77.11400006591796,
                "val_top5": 93.46399990966796
            },
            {
                "epoch": 96,
                "learning_rate": 0.0004438035396920004,
                "model_norm": 198.1857147216797,
                "train_loss": 1.7499369382858276,
                "val_loss": 1.0001586378479004,
                "val_top1": 77.09399993652343,
                "val_top5": 93.43199998779296
            },
            {
                "epoch": 97,
                "learning_rate": 0.00019732715717284412,
                "model_norm": 198.1763153076172,
                "train_loss": 1.746922492980957,
                "val_loss": 0.9957417548370361,
                "val_top1": 77.11999999023438,
                "val_top5": 93.46199998779296
            },
            {
                "epoch": 98,
                "learning_rate": 4.934396342684e-05,
                "model_norm": 198.17282104492188,
                "train_loss": 1.7460905313491821,
                "val_loss": 1.0047309856414794,
                "val_top1": 77.13200001464844,
                "val_top5": 93.49399998779298
            },
            {
                "epoch": 99,
                "learning_rate": 0.0,
                "model_norm": 198.17225646972656,
                "train_loss": 1.744036316871643,
                "val_loss": 0.9928645990753174,
                "val_top1": 77.1920000390625,
                "val_top5": 93.47000001464843
            }
        ],
        "summary": {
            "len_train_loader": 1251,
            "start_time": "2025-03-26 15:18:18.894028"
        }
    },
    {
        "config": {
            "batch_size": 256,
            "dataset": "imagenet1k",
            "gradient_accumulation": 1,
            "max_epoch": 100,
            "model": "resnet50",
            "opt": {
                "lr": 0.1,
                "lr_schedule": "cosine",
                "momentum": 0.9,
                "name": "momentum",
                "weight_decay": 0.0001
            },
            "run_id": 0
        },
        "history": [
            {
                "epoch": 0,
                "learning_rate": 0.020008,
                "model_norm": 236.2527313232422,
                "train_loss": 6.645748615264893,
                "val_loss": 6.204254975891113,
                "val_top1": 2.616000009765625,
                "val_top5": 7.994
            },
            {
                "epoch": 1,
                "learning_rate": 0.04000600000000001,
                "model_norm": 229.8668670654297,
                "train_loss": 6.154252529144287,
                "val_loss": 5.57846278793335,
                "val_top1": 5.949999993896484,
                "val_top5": 16.09800004638672
            },
            {
                "epoch": 2,
                "learning_rate": 0.06000400000000001,
                "model_norm": 220.07595825195312,
                "train_loss": 5.7262468338012695,
                "val_loss": 5.043336514282227,
                "val_top1": 9.165999993286134,
                "val_top5": 23.45000001220703
            },
            {
                "epoch": 3,
                "learning_rate": 0.080002,
                "model_norm": 208.26539611816406,
                "train_loss": 5.241634368896484,
                "val_loss": 4.521384533233642,
                "val_top1": 14.967999998779296,
                "val_top5": 34.096000009765625
            },
            {
                "epoch": 4,
                "learning_rate": 0.0993844170297569,
                "model_norm": 196.02322387695312,
                "train_loss": 4.7323503494262695,
                "val_loss": 4.0051609675598145,
                "val_top1": 20.46400002319336,
                "val_top5": 43.19600001464844
            },
            {
                "epoch": 5,
                "learning_rate": 0.09911436253643445,
                "model_norm": 185.48776245117188,
                "train_loss": 4.301990032196045,
                "val_loss": 3.5986610808563233,
                "val_top1": 26.3760000390625,
                "val_top5": 50.96199996337891
            },
            {
                "epoch": 6,
                "learning_rate": 0.09879583809693737,
                "model_norm": 177.41209411621094,
                "train_loss": 3.9728190898895264,
                "val_loss": 3.080609608306885,
                "val_top1": 34.768000004882815,
                "val_top5": 61.0979999633789
            },
            {
                "epoch": 7,
                "learning_rate": 0.09842915805643156,
                "model_norm": 171.27395629882812,
                "train_loss": 3.7327375411987305,
                "val_loss": 2.899163557434082,
                "val_top1": 38.593999985351566,
                "val_top5": 65.17200010742188
            },
            {
                "epoch": 8,
                "learning_rate": 0.09801468428384716,
                "model_norm": 166.6516571044922,
                "train_loss": 3.5562186241149902,
                "val_loss": 2.7525148433685303,
                "val_top1": 40.81200004638672,
                "val_top5": 67.24200006591796
            },
            {
                "epoch": 9,
                "learning_rate": 0.09755282581475769,
                "model_norm": 163.2438201904297,
                "train_loss": 3.4196856021881104,
                "val_loss": 2.4405103079986574,
                "val_top1": 46.61399994628906,
                "val_top5": 72.92600000732422
            },
            {
                "epoch": 10,
                "learning_rate": 0.09704403844771128,
                "model_norm": 160.80482482910156,
                "train_loss": 3.3084778785705566,
                "val_loss": 2.3763051138687135,
                "val_top1": 47.46199999511719,
                "val_top5": 73.28600002929687
            },
            {
                "epoch": 11,
                "learning_rate": 0.09648882429441258,
                "model_norm": 159.161865234375,
                "train_loss": 3.219424247741699,
                "val_loss": 2.3683858885574343,
                "val_top1": 47.46400000244141,
                "val_top5": 73.66600013671875
            },
            {
                "epoch": 12,
                "learning_rate": 0.09588773128419906,
                "model_norm": 158.1321563720703,
                "train_loss": 3.1447064876556396,
                "val_loss": 2.2895260250854492,
                "val_top1": 51.32999999023438,
                "val_top5": 76.45800011230469
            },
            {
                "epoch": 13,
                "learning_rate": 0.09524135262330098,
                "model_norm": 157.60824584960938,
                "train_loss": 3.0774898529052734,
                "val_loss": 2.183965936393738,
                "val_top1": 53.220000126953124,
                "val_top5": 77.98799997558594
            },
            {
                "epoch": 14,
                "learning_rate": 0.09455032620941839,
                "model_norm": 157.453369140625,
                "train_loss": 3.0149402618408203,
                "val_loss": 2.113124783859253,
                "val_top1": 52.52800001220703,
                "val_top5": 77.74800014160157
            },
            {
                "epoch": 15,
                "learning_rate": 0.09381533400219318,
                "model_norm": 157.57627868652344,
                "train_loss": 2.961460590362549,
                "val_loss": 2.079807848968506,
                "val_top1": 54.18199996337891,
                "val_top5": 79.33800007324218
            },
            {
                "epoch": 16,
                "learning_rate": 0.09303710135019719,
                "model_norm": 157.86947631835938,
                "train_loss": 2.915780544281006,
                "val_loss": 2.0253041299057006,
                "val_top1": 56.86800003417969,
                "val_top5": 80.66799988769532
            },
            {
                "epoch": 17,
                "learning_rate": 0.09221639627510075,
                "model_norm": 158.2805633544922,
                "train_loss": 2.872133493423462,
                "val_loss": 1.927347085838318,
                "val_top1": 56.67200005859375,
                "val_top5": 80.7379998828125
            },
            {
                "epoch": 18,
                "learning_rate": 0.0913540287137281,
                "model_norm": 158.7718505859375,
                "train_loss": 2.8373053073883057,
                "val_loss": 2.096160633659363,
                "val_top1": 54.305999990234376,
                "val_top5": 78.90400003417969
            },
            {
                "epoch": 19,
                "learning_rate": 0.09045084971874738,
                "model_norm": 159.28726196289062,
                "train_loss": 2.8021152019500732,
                "val_loss": 1.8581995980072021,
                "val_top1": 58.694000061035155,
                "val_top5": 82.72600001708985
            },
            {
                "epoch": 20,
                "learning_rate": 0.08950775061878452,
                "model_norm": 159.8647918701172,
                "train_loss": 2.7743263244628906,
                "val_loss": 1.8745535711669923,
                "val_top1": 58.160000102539065,
                "val_top5": 82.04999998046875
            },
            {
                "epoch": 21,
                "learning_rate": 0.08852566213878947,
                "model_norm": 160.43917846679688,
                "train_loss": 2.746621608734131,
                "val_loss": 1.8732611952209473,
                "val_top1": 58.23799998046875,
                "val_top5": 82.08599998291015
            },
            {
                "epoch": 22,
                "learning_rate": 0.08750555348152299,
                "model_norm": 161.02207946777344,
                "train_loss": 2.7220029830932617,
                "val_loss": 1.8076003289413451,
                "val_top1": 60.278000056152344,
                "val_top5": 83.66800006835938
            },
            {
                "epoch": 23,
                "learning_rate": 0.08644843137107058,
                "model_norm": 161.60726928710938,
                "train_loss": 2.6998636722564697,
                "val_loss": 1.8182523027420043,
                "val_top1": 60.12999997314453,
                "val_top5": 83.42600006835937
            },
            {
                "epoch": 24,
                "learning_rate": 0.08535533905932738,
                "model_norm": 162.17901611328125,
                "train_loss": 2.6770248413085938,
                "val_loss": 1.789492282447815,
                "val_top1": 60.264,
                "val_top5": 83.55599998535156
            },
            {
                "epoch": 25,
                "learning_rate": 0.08422735529643444,
                "model_norm": 162.73297119140625,
                "train_loss": 2.6577579975128174,
                "val_loss": 1.7179939141845704,
                "val_top1": 60.52399994140625,
                "val_top5": 83.8999999584961
            },
            {
                "epoch": 26,
                "learning_rate": 0.0830655932661826,
                "model_norm": 163.2707977294922,
                "train_loss": 2.6385726928710938,
                "val_loss": 1.744727508430481,
                "val_top1": 60.56000001708984,
                "val_top5": 83.8880000366211
            },
            {
                "epoch": 27,
                "learning_rate": 0.08187119948743449,
                "model_norm": 163.77850341796875,
                "train_loss": 2.619675874710083,
                "val_loss": 1.6334226589965821,
                "val_top1": 61.92200003173828,
                "val_top5": 84.72200001464844
            },
            {
                "epoch": 28,
                "learning_rate": 0.08064535268264883,
                "model_norm": 164.27622985839844,
                "train_loss": 2.604264736175537,
                "val_loss": 1.7305091715621947,
                "val_top1": 61.02600000732422,
                "val_top5": 84.07400001220704
            },
            {
                "epoch": 29,
                "learning_rate": 0.07938926261462366,
                "model_norm": 164.7656707763672,
                "train_loss": 2.5859122276306152,
                "val_loss": 1.670649055519104,
                "val_top1": 61.476000046386716,
                "val_top5": 84.52400001464844
            },
            {
                "epoch": 30,
                "learning_rate": 0.07810416889260655,
                "model_norm": 165.2299346923828,
                "train_loss": 2.5737202167510986,
                "val_loss": 1.6443558975601196,
                "val_top1": 62.91400006835938,
                "val_top5": 85.37200011230469
            },
            {
                "epoch": 31,
                "learning_rate": 0.07679133974894983,
                "model_norm": 165.6703643798828,
                "train_loss": 2.5559887886047363,
                "val_loss": 1.568593190727234,
                "val_top1": 64.08000001464843,
                "val_top5": 85.99800011230468
            },
            {
                "epoch": 32,
                "learning_rate": 0.07545207078751857,
                "model_norm": 166.08026123046875,
                "train_loss": 2.5397305488586426,
                "val_loss": 1.6456949687957763,
                "val_top1": 62.56200001464844,
                "val_top5": 85.19199998291016
            },
            {
                "epoch": 33,
                "learning_rate": 0.07408768370508577,
                "model_norm": 166.4936065673828,
                "train_loss": 2.5261776447296143,
                "val_loss": 1.7234310612106323,
                "val_top1": 60.893999924316404,
                "val_top5": 84.14999998535156
            },
            {
                "epoch": 34,
                "learning_rate": 0.07269952498697733,
                "model_norm": 166.87803649902344,
                "train_loss": 2.512852668762207,
                "val_loss": 1.5991305916976928,
                "val_top1": 63.742000009765626,
                "val_top5": 86.14000005126952
            },
            {
                "epoch": 35,
                "learning_rate": 0.07128896457825364,
                "model_norm": 167.2355194091797,
                "train_loss": 2.4982805252075195,
                "val_loss": 1.5725013973617554,
                "val_top1": 64.13800009277344,
                "val_top5": 86.01400005859375
            },
            {
                "epoch": 36,
                "learning_rate": 0.06985739453173904,
                "model_norm": 167.58511352539062,
                "train_loss": 2.488795042037964,
                "val_loss": 1.5580751748657227,
                "val_top1": 65.00999999023438,
                "val_top5": 86.67400010742188
            },
            {
                "epoch": 37,
                "learning_rate": 0.0684062276342339,
                "model_norm": 167.92062377929688,
                "train_loss": 2.475412368774414,
                "val_loss": 1.5202206256103517,
                "val_top1": 65.50200000488282,
                "val_top5": 87.20200004882813
            },
            {
                "epoch": 38,
                "learning_rate": 0.06693689601226459,
                "model_norm": 168.21664428710938,
                "train_loss": 2.4617180824279785,
                "val_loss": 1.5657405508613587,
                "val_top1": 64.89000006591797,
                "val_top5": 86.44400015625
            },
            {
                "epoch": 39,
                "learning_rate": 0.06545084971874737,
                "model_norm": 168.50608825683594,
                "train_loss": 2.450563907623291,
                "val_loss": 1.4984197017288208,
                "val_top1": 66.07599993652343,
                "val_top5": 87.40600013183594
            },
            {
                "epoch": 40,
                "learning_rate": 0.06394955530196147,
                "model_norm": 168.76654052734375,
                "train_loss": 2.434687376022339,
                "val_loss": 1.5044055230712892,
                "val_top1": 66.00000004150391,
                "val_top5": 87.57199995361329
            },
            {
                "epoch": 41,
                "learning_rate": 0.062434494358242755,
                "model_norm": 169.01376342773438,
                "train_loss": 2.4243366718292236,
                "val_loss": 1.5186939282226561,
                "val_top1": 64.78799997070313,
                "val_top5": 86.47199995605469
            },
            {
                "epoch": 42,
                "learning_rate": 0.06090716206982713,
                "model_norm": 169.24122619628906,
                "train_loss": 2.4107232093811035,
                "val_loss": 1.4763604963302612,
                "val_top1": 65.88199998046875,
                "val_top5": 87.18400005371093
            },
            {
                "epoch": 43,
                "learning_rate": 0.05936906572928624,
                "model_norm": 169.4546356201172,
                "train_loss": 2.3986411094665527,
                "val_loss": 1.4811248152542114,
                "val_top1": 66.22000004150391,
                "val_top5": 87.59600005126953
            },
            {
                "epoch": 44,
                "learning_rate": 0.05782172325201155,
                "model_norm": 169.6531219482422,
                "train_loss": 2.387983798980713,
                "val_loss": 1.4910060482406615,
                "val_top1": 65.77800008300781,
                "val_top5": 86.80400008300781
            },
            {
                "epoch": 45,
                "learning_rate": 0.056266661678215216,
                "model_norm": 169.83486938476562,
                "train_loss": 2.37613582611084,
                "val_loss": 1.4948467172622681,
                "val_top1": 66.94800011230468,
                "val_top5": 87.80800000488281
            },
            {
                "epoch": 46,
                "learning_rate": 0.05470541566592572,
                "model_norm": 169.99679565429688,
                "train_loss": 2.3639535903930664,
                "val_loss": 1.5219021686172485,
                "val_top1": 65.13800005371094,
                "val_top5": 86.67999993408203
            },
            {
                "epoch": 47,
                "learning_rate": 0.05313952597646568,
                "model_norm": 170.1382598876953,
                "train_loss": 2.352487087249756,
                "val_loss": 1.4254862819480896,
                "val_top1": 66.72999998291016,
                "val_top5": 87.84199992431641
            },
            {
                "epoch": 48,
                "learning_rate": 0.051570537953906405,
                "model_norm": 170.27395629882812,
                "train_loss": 2.3428568840026855,
                "val_loss": 1.4503326021003724,
                "val_top1": 66.64600008789063,
                "val_top5": 87.77400005126952
            },
            {
                "epoch": 49,
                "learning_rate": 0.05,
                "model_norm": 170.37887573242188,
                "train_loss": 2.33092999458313,
                "val_loss": 1.5235432428359985,
                "val_top1": 65.66999998291016,
                "val_top5": 86.78800005126953
            },
            {
                "epoch": 50,
                "learning_rate": 0.0484294620460936,
                "model_norm": 170.4730224609375,
                "train_loss": 2.318793773651123,
                "val_loss": 1.459237751159668,
                "val_top1": 67.46599995605469,
                "val_top5": 88.30400000732422
            },
            {
                "epoch": 51,
                "learning_rate": 0.04686047402353433,
                "model_norm": 170.5481719970703,
                "train_loss": 2.3064217567443848,
                "val_loss": 1.3392596765708924,
                "val_top1": 68.74400005859376,
                "val_top5": 88.92800002441406
            },
            {
                "epoch": 52,
                "learning_rate": 0.045294584334074295,
                "model_norm": 170.61529541015625,
                "train_loss": 2.2942707538604736,
                "val_loss": 1.4134872190856933,
                "val_top1": 67.9720000390625,
                "val_top5": 88.277999921875
            },
            {
                "epoch": 53,
                "learning_rate": 0.0437333383217848,
                "model_norm": 170.66412353515625,
                "train_loss": 2.28194260597229,
                "val_loss": 1.4739752744293213,
                "val_top1": 66.43000008789062,
                "val_top5": 87.64000010742187
            },
            {
                "epoch": 54,
                "learning_rate": 0.042178276747988463,
                "model_norm": 170.70188903808594,
                "train_loss": 2.270803928375244,
                "val_loss": 1.3405671702003479,
                "val_top1": 69.15599995117188,
                "val_top5": 89.19999994628907
            },
            {
                "epoch": 55,
                "learning_rate": 0.04063093427071377,
                "model_norm": 170.72474670410156,
                "train_loss": 2.257936477661133,
                "val_loss": 1.335730012588501,
                "val_top1": 68.964,
                "val_top5": 89.05200009765625
            },
            {
                "epoch": 56,
                "learning_rate": 0.039092837930172875,
                "model_norm": 170.739013671875,
                "train_loss": 2.2473108768463135,
                "val_loss": 1.366075869026184,
                "val_top1": 68.87000002441407,
                "val_top5": 89.19400001953125
            },
            {
                "epoch": 57,
                "learning_rate": 0.03756550564175727,
                "model_norm": 170.74476623535156,
                "train_loss": 2.2343318462371826,
                "val_loss": 1.3373474246025085,
                "val_top1": 69.22800000488282,
                "val_top5": 89.13000005126953
            },
            {
                "epoch": 58,
                "learning_rate": 0.036050444698038545,
                "model_norm": 170.73648071289062,
                "train_loss": 2.2229983806610107,
                "val_loss": 1.3054394064903259,
                "val_top1": 69.85000000488282,
                "val_top5": 89.64200012695312
            },
            {
                "epoch": 59,
                "learning_rate": 0.03454915028125263,
                "model_norm": 170.7008056640625,
                "train_loss": 2.2103843688964844,
                "val_loss": 1.312818378238678,
                "val_top1": 69.81800005371093,
                "val_top5": 89.4860001513672
            },
            {
                "epoch": 60,
                "learning_rate": 0.03306310398773543,
                "model_norm": 170.66062927246094,
                "train_loss": 2.1969056129455566,
                "val_loss": 1.2839758387374878,
                "val_top1": 70.32999997802735,
                "val_top5": 89.738000078125
            },
            {
                "epoch": 61,
                "learning_rate": 0.03159377236576612,
                "model_norm": 170.6140899658203,
                "train_loss": 2.1855735778808594,
                "val_loss": 1.2910564125442505,
                "val_top1": 70.228,
                "val_top5": 89.92200004638671
            },
            {
                "epoch": 62,
                "learning_rate": 0.030142605468260964,
                "model_norm": 170.5540313720703,
                "train_loss": 2.1707592010498047,
                "val_loss": 1.3241446904945373,
                "val_top1": 69.26600005615235,
                "val_top5": 89.32400002441406
            },
            {
                "epoch": 63,
                "learning_rate": 0.02871103542174637,
                "model_norm": 170.48387145996094,
                "train_loss": 2.160094738006592,
                "val_loss": 1.3281765531349181,
                "val_top1": 70.07599996826171,
                "val_top5": 89.77000007324219
            },
            {
                "epoch": 64,
                "learning_rate": 0.027300475013022664,
                "model_norm": 170.40359497070312,
                "train_loss": 2.1455960273742676,
                "val_loss": 1.2542860330963135,
                "val_top1": 70.86600005371093,
                "val_top5": 90.07400002441406
            },
            {
                "epoch": 65,
                "learning_rate": 0.02591231629491423,
                "model_norm": 170.3115234375,
                "train_loss": 2.1328396797180176,
                "val_loss": 1.2374950374031066,
                "val_top1": 71.21200005371094,
                "val_top5": 90.53199999511719
            },
            {
                "epoch": 66,
                "learning_rate": 0.024547929212481435,
                "model_norm": 170.21519470214844,
                "train_loss": 2.119157314300537,
                "val_loss": 1.2448480358695984,
                "val_top1": 71.60599997314453,
                "val_top5": 90.44399997070313
            },
            {
                "epoch": 67,
                "learning_rate": 0.02320866025105018,
                "model_norm": 170.10606384277344,
                "train_loss": 2.1049394607543945,
                "val_loss": 1.1858794367218017,
                "val_top1": 72.32199996826172,
                "val_top5": 90.95000004638672
            },
            {
                "epoch": 68,
                "learning_rate": 0.021895831107393484,
                "model_norm": 169.99000549316406,
                "train_loss": 2.090313196182251,
                "val_loss": 1.2401723775863647,
                "val_top1": 71.57400000244141,
                "val_top5": 90.60800004882813
            },
            {
                "epoch": 69,
                "learning_rate": 0.02061073738537635,
                "model_norm": 169.8682861328125,
                "train_loss": 2.0763909816741943,
                "val_loss": 1.3019348267364501,
                "val_top1": 70.70400002685547,
                "val_top5": 90.01400009521484
            },
            {
                "epoch": 70,
                "learning_rate": 0.019354647317351172,
                "model_norm": 169.7420196533203,
                "train_loss": 2.0639474391937256,
                "val_loss": 1.2031591672706603,
                "val_top1": 72.19799999511719,
                "val_top5": 90.79800010009765
            },
            {
                "epoch": 71,
                "learning_rate": 0.018128800512565515,
                "model_norm": 169.6103057861328,
                "train_loss": 2.049745559692383,
                "val_loss": 1.2018958144760132,
                "val_top1": 72.59200005371093,
                "val_top5": 91.15000002197266
            },
            {
                "epoch": 72,
                "learning_rate": 0.016934406733817416,
                "model_norm": 169.4698944091797,
                "train_loss": 2.034513473510742,
                "val_loss": 1.2081966429519653,
                "val_top1": 72.27999994140625,
                "val_top5": 91.04600004638672
            },
            {
                "epoch": 73,
                "learning_rate": 0.01577264470356558,
                "model_norm": 169.3324432373047,
                "train_loss": 2.0210981369018555,
                "val_loss": 1.15286728307724,
                "val_top1": 73.00399994628906,
                "val_top5": 91.20000002197266
            },
            {
                "epoch": 74,
                "learning_rate": 0.014644660940672611,
                "model_norm": 169.18801879882812,
                "train_loss": 2.0063350200653076,
                "val_loss": 1.1456665900039673,
                "val_top1": 73.54000009765625,
                "val_top5": 91.53600007080078
            },
            {
                "epoch": 75,
                "learning_rate": 0.013551568628929417,
                "model_norm": 169.0442657470703,
                "train_loss": 1.9927549362182617,
                "val_loss": 1.1751402752685547,
                "val_top1": 72.96799994140625,
                "val_top5": 91.30400007080078
            },
            {
                "epoch": 76,
                "learning_rate": 0.012494446518477021,
                "model_norm": 168.8982696533203,
                "train_loss": 1.9771944284439087,
                "val_loss": 1.1686648106765747,
                "val_top1": 73.16800001708984,
                "val_top5": 91.30200001464844
            },
            {
                "epoch": 77,
                "learning_rate": 0.011474337861210543,
                "model_norm": 168.75234985351562,
                "train_loss": 1.9620344638824463,
                "val_loss": 1.1535101632118225,
                "val_top1": 73.36400004394531,
                "val_top5": 91.42399999023438
            },
            {
                "epoch": 78,
                "learning_rate": 0.010492249381215492,
                "model_norm": 168.6083221435547,
                "train_loss": 1.949090838432312,
                "val_loss": 1.1352228517341614,
                "val_top1": 73.69400004394531,
                "val_top5": 91.58200009521484
            },
            {
                "epoch": 79,
                "learning_rate": 0.009549150281252633,
                "model_norm": 168.46412658691406,
                "train_loss": 1.9347772598266602,
                "val_loss": 1.1045699541091918,
                "val_top1": 74.25799989013672,
                "val_top5": 92.08000001464843
            },
            {
                "epoch": 80,
                "learning_rate": 0.008645971286271903,
                "model_norm": 168.32586669921875,
                "train_loss": 1.9198393821716309,
                "val_loss": 1.1007753425598144,
                "val_top1": 74.31000004394531,
                "val_top5": 91.96200001464844
            },
            {
                "epoch": 81,
                "learning_rate": 0.007783603724899247,
                "model_norm": 168.19068908691406,
                "train_loss": 1.9030200242996216,
                "val_loss": 1.1019386211585998,
                "val_top1": 74.51200009033204,
                "val_top5": 92.11799993652343
            },
            {
                "epoch": 82,
                "learning_rate": 0.006962898649802824,
                "model_norm": 168.05943298339844,
                "train_loss": 1.891116976737976,
                "val_loss": 1.100666168899536,
                "val_top1": 74.81799993652344,
                "val_top5": 92.28200006835938
            },
            {
                "epoch": 83,
                "learning_rate": 0.006184665997806833,
                "model_norm": 167.9352264404297,
                "train_loss": 1.878943920135498,
                "val_loss": 1.1045147315597534,
                "val_top1": 74.72000001464843,
                "val_top5": 92.00000006591797
            },
            {
                "epoch": 84,
                "learning_rate": 0.005449673790581611,
                "model_norm": 167.81846618652344,
                "train_loss": 1.8645994663238525,
                "val_loss": 1.0711748844718934,
                "val_top1": 75.12600004394531,
                "val_top5": 92.39800006835938
            },
            {
                "epoch": 85,
                "learning_rate": 0.004758647376699021,
                "model_norm": 167.70919799804688,
                "train_loss": 1.8523013591766357,
                "val_loss": 1.0802326262664794,
                "val_top1": 75.21600001953125,
                "val_top5": 92.37000014648437
            },
            {
                "epoch": 86,
                "learning_rate": 0.004112268715800943,
                "model_norm": 167.60891723632812,
                "train_loss": 1.8378547430038452,
                "val_loss": 1.0816718969535828,
                "val_top1": 75.37199994140624,
                "val_top5": 92.47799999023438
            },
            {
                "epoch": 87,
                "learning_rate": 0.0035111757055874327,
                "model_norm": 167.51808166503906,
                "train_loss": 1.8266804218292236,
                "val_loss": 1.0691880134391785,
                "val_top1": 75.5800000390625,
                "val_top5": 92.5439998876953
            },
            {
                "epoch": 88,
                "learning_rate": 0.0029559615522887273,
                "model_norm": 167.4369354248047,
                "train_loss": 1.814792275428772,
                "val_loss": 1.0632443713760376,
                "val_top1": 75.61999999267579,
                "val_top5": 92.62999991210937
            },
            {
                "epoch": 89,
                "learning_rate": 0.0024471741852423235,
                "model_norm": 167.36636352539062,
                "train_loss": 1.8041843175888062,
                "val_loss": 1.062250918083191,
                "val_top1": 75.62400007324219,
                "val_top5": 92.73199999023437
            },
            {
                "epoch": 90,
                "learning_rate": 0.0019853157161528524,
                "model_norm": 167.3057403564453,
                "train_loss": 1.7955601215362549,
                "val_loss": 1.0610686960983275,
                "val_top1": 75.78000009521485,
                "val_top5": 92.78400009521485
            },
            {
                "epoch": 91,
                "learning_rate": 0.0015708419435684464,
                "model_norm": 167.25543212890625,
                "train_loss": 1.7851059436798096,
                "val_loss": 1.0543461761474608,
                "val_top1": 75.87200001708985,
                "val_top5": 92.66800009277344
            },
            {
                "epoch": 92,
                "learning_rate": 0.0012041619030626338,
                "model_norm": 167.21470642089844,
                "train_loss": 1.7791138887405396,
                "val_loss": 1.060796194152832,
                "val_top1": 75.96800004150391,
                "val_top5": 92.78600001708985
            },
            {
                "epoch": 93,
                "learning_rate": 0.000885637463565564,
                "model_norm": 167.18319702148438,
                "train_loss": 1.7745474576950073,
                "val_loss": 1.0554516052436829,
                "val_top1": 75.95000004150391,
                "val_top5": 92.76399993896484
            },
            {
                "epoch": 94,
                "learning_rate": 0.0006155829702431171,
                "model_norm": 167.1599578857422,
                "train_loss": 1.7676249742507935,
                "val_loss": 1.0502363832473756,
                "val_top1": 76.04600001708984,
                "val_top5": 92.76999996337891
            },
            {
                "epoch": 95,
                "learning_rate": 0.0003942649342761118,
                "model_norm": 167.14401245117188,
                "train_loss": 1.7626397609710693,
                "val_loss": 1.053306199760437,
                "val_top1": 76.02399996582031,
                "val_top5": 92.86000001464843
            },
            {
                "epoch": 96,
                "learning_rate": 0.0002219017698460002,
                "model_norm": 167.1342010498047,
                "train_loss": 1.7577803134918213,
                "val_loss": 1.0522042008781434,
                "val_top1": 76.08400001953125,
                "val_top5": 92.83400001464844
            },
            {
                "epoch": 97,
                "learning_rate": 9.866357858642206e-05,
                "model_norm": 167.12904357910156,
                "train_loss": 1.756302833557129,
                "val_loss": 1.0475922250938416,
                "val_top1": 76.08200004394531,
                "val_top5": 92.80200009277344
            },
            {
                "epoch": 98,
                "learning_rate": 2.467198171342e-05,
                "model_norm": 167.12713623046875,
                "train_loss": 1.75583815574646,
                "val_loss": 1.0589280411720277,
                "val_top1": 76.08000007080078,
                "val_top5": 92.82800011962891
            },
            {
                "epoch": 99,
                "learning_rate": 0.0,
                "model_norm": 167.12680053710938,
                "train_loss": 1.7538007497787476,
                "val_loss": 1.0466741063690186,
                "val_top1": 76.09600004394531,
                "val_top5": 92.8260000415039
            }
        ],
        "summary": {
            "len_train_loader": 1251,
            "start_time": "2025-03-26 14:21:05.168863"
        }
    },
    {
        "config": {
            "batch_size": 256,
            "dataset": "imagenet1k",
            "gradient_accumulation": 1,
            "max_epoch": 100,
            "model": "resnet50",
            "opt": {
                "lr": 0.05,
                "lr_schedule": "wsd",
                "momentum": 0.9,
                "name": "momentum",
                "weight_decay": 0.0001
            },
            "run_id": 0
        },
        "history": [
            {
                "epoch": 0,
                "learning_rate": 0.010008,
                "model_norm": 237.35316467285156,
                "train_grad_norm": 0.8449722478706524,
                "train_loss": 6.730901718139648,
                "val_loss": 6.364782475128174,
                "val_top1": 2.096000001220703,
                "val_top5": 6.629999990844727
            },
            {
                "epoch": 1,
                "learning_rate": 0.020006,
                "model_norm": 234.095458984375,
                "train_grad_norm": 1.3019414387873298,
                "train_loss": 6.319450855255127,
                "val_loss": 5.975249875640869,
                "val_top1": 3.8460000085449217,
                "val_top5": 11.304000010986329
            },
            {
                "epoch": 2,
                "learning_rate": 0.030004,
                "model_norm": 228.86227416992188,
                "train_grad_norm": 1.304937002993519,
                "train_loss": 6.016332626342773,
                "val_loss": 5.533621992950439,
                "val_top1": 5.9299999914550785,
                "val_top5": 16.654000024414064
            },
            {
                "epoch": 3,
                "learning_rate": 0.040002,
                "model_norm": 222.0059051513672,
                "train_grad_norm": 1.3776202982904386,
                "train_loss": 5.689971923828125,
                "val_loss": 5.099524842681885,
                "val_top1": 9.14800001586914,
                "val_top5": 23.335999990234374
            },
            {
                "epoch": 4,
                "learning_rate": 0.05,
                "model_norm": 214.02658081054688,
                "train_grad_norm": 1.483030858451339,
                "train_loss": 5.317224502563477,
                "val_loss": 4.769045657958984,
                "val_top1": 12.332000029907226,
                "val_top5": 29.142000034179688
            },
            {
                "epoch": 5,
                "learning_rate": 0.05,
                "model_norm": 206.15797424316406,
                "train_grad_norm": 1.5456375706471925,
                "train_loss": 4.908535957336426,
                "val_loss": 4.183493235397339,
                "val_top1": 18.240000032958985,
                "val_top5": 39.30200001586914
            },
            {
                "epoch": 6,
                "learning_rate": 0.05,
                "model_norm": 199.19874572753906,
                "train_grad_norm": 1.596872592823372,
                "train_loss": 4.548012733459473,
                "val_loss": 3.757838631591797,
                "val_top1": 24.24999998413086,
                "val_top5": 47.943999990234374
            },
            {
                "epoch": 7,
                "learning_rate": 0.05,
                "model_norm": 193.03309631347656,
                "train_grad_norm": 1.6262861901710561,
                "train_loss": 4.266979217529297,
                "val_loss": 3.5874305874633787,
                "val_top1": 26.980000006103516,
                "val_top5": 51.31200006347656
            },
            {
                "epoch": 8,
                "learning_rate": 0.05,
                "model_norm": 187.587646484375,
                "train_grad_norm": 1.6423506056830128,
                "train_loss": 4.036535739898682,
                "val_loss": 3.4281060928344727,
                "val_top1": 30.247999991455078,
                "val_top5": 55.2120000390625
            },
            {
                "epoch": 9,
                "learning_rate": 0.05,
                "model_norm": 182.77085876464844,
                "train_grad_norm": 1.6566219654187389,
                "train_loss": 3.8467440605163574,
                "val_loss": 2.9194298893356323,
                "val_top1": 37.05600001831055,
                "val_top5": 63.834000021972656
            },
            {
                "epoch": 10,
                "learning_rate": 0.05,
                "model_norm": 178.51979064941406,
                "train_grad_norm": 1.664528291822548,
                "train_loss": 3.6889827251434326,
                "val_loss": 2.7371753414154054,
                "val_top1": 40.60400005981445,
                "val_top5": 66.85200002197266
            },
            {
                "epoch": 11,
                "learning_rate": 0.05,
                "model_norm": 174.77630615234375,
                "train_grad_norm": 1.6763882536443262,
                "train_loss": 3.561098098754883,
                "val_loss": 2.5833189798355103,
                "val_top1": 42.95200004394531,
                "val_top5": 69.27400007568359
            },
            {
                "epoch": 12,
                "learning_rate": 0.05,
                "model_norm": 171.4856719970703,
                "train_grad_norm": 1.6880299259320017,
                "train_loss": 3.4576821327209473,
                "val_loss": 2.566372567062378,
                "val_top1": 45.015999987792966,
                "val_top5": 70.94400007080078
            },
            {
                "epoch": 13,
                "learning_rate": 0.05,
                "model_norm": 168.60240173339844,
                "train_grad_norm": 1.6928667133589417,
                "train_loss": 3.3688740730285645,
                "val_loss": 2.4588368919754027,
                "val_top1": 47.67000004638672,
                "val_top5": 73.51799999267578
            },
            {
                "epoch": 14,
                "learning_rate": 0.05,
                "model_norm": 166.08863830566406,
                "train_grad_norm": 1.700209404630391,
                "train_loss": 3.2911484241485596,
                "val_loss": 2.364786644592285,
                "val_top1": 48.433999958496095,
                "val_top5": 74.40800001464844
            },
            {
                "epoch": 15,
                "learning_rate": 0.05,
                "model_norm": 163.90943908691406,
                "train_grad_norm": 1.709991431128899,
                "train_loss": 3.225823163986206,
                "val_loss": 2.3556690812683105,
                "val_top1": 49.25799986816406,
                "val_top5": 74.89800005615234
            },
            {
                "epoch": 16,
                "learning_rate": 0.05,
                "model_norm": 162.03152465820312,
                "train_grad_norm": 1.721095060121197,
                "train_loss": 3.16702938079834,
                "val_loss": 2.2603545211029052,
                "val_top1": 50.55999996337891,
                "val_top5": 75.45199990722656
            },
            {
                "epoch": 17,
                "learning_rate": 0.05,
                "model_norm": 160.4145965576172,
                "train_grad_norm": 1.7297461301350132,
                "train_loss": 3.115809917449951,
                "val_loss": 2.229362907180786,
                "val_top1": 51.19999999511719,
                "val_top5": 76.31599999511718
            },
            {
                "epoch": 18,
                "learning_rate": 0.05,
                "model_norm": 159.0471954345703,
                "train_grad_norm": 1.7385550694594802,
                "train_loss": 3.0683343410491943,
                "val_loss": 2.0821746952056883,
                "val_top1": 53.86600006347656,
                "val_top5": 78.51399999511719
            },
            {
                "epoch": 19,
                "learning_rate": 0.05,
                "model_norm": 157.88450622558594,
                "train_grad_norm": 1.7475942951376637,
                "train_loss": 3.024007797241211,
                "val_loss": 2.1107512282562255,
                "val_top1": 53.49200005371094,
                "val_top5": 78.378
            },
            {
                "epoch": 20,
                "learning_rate": 0.05,
                "model_norm": 156.91650390625,
                "train_grad_norm": 1.758055516739631,
                "train_loss": 2.985564708709717,
                "val_loss": 2.055528920478821,
                "val_top1": 54.394000087890625,
                "val_top5": 78.93000002441406
            },
            {
                "epoch": 21,
                "learning_rate": 0.05,
                "model_norm": 156.11715698242188,
                "train_grad_norm": 1.7696971001594806,
                "train_loss": 2.9501430988311768,
                "val_loss": 1.9956613996887207,
                "val_top1": 55.15800004882812,
                "val_top5": 79.71000007324218
            },
            {
                "epoch": 22,
                "learning_rate": 0.05,
                "model_norm": 155.47512817382812,
                "train_grad_norm": 1.7789810442404541,
                "train_loss": 2.9171910285949707,
                "val_loss": 2.01341471534729,
                "val_top1": 55.43000004882813,
                "val_top5": 79.95799999511719
            },
            {
                "epoch": 23,
                "learning_rate": 0.05,
                "model_norm": 154.96975708007812,
                "train_grad_norm": 1.7904035172162398,
                "train_loss": 2.8872931003570557,
                "val_loss": 1.9714704441070556,
                "val_top1": 57.073999907226565,
                "val_top5": 80.67600005126953
            },
            {
                "epoch": 24,
                "learning_rate": 0.05,
                "model_norm": 154.59373474121094,
                "train_grad_norm": 1.8001614898084402,
                "train_loss": 2.857032299041748,
                "val_loss": 1.9378913864135743,
                "val_top1": 57.142000083007815,
                "val_top5": 81.37999999511719
            },
            {
                "epoch": 25,
                "learning_rate": 0.05,
                "model_norm": 154.3265380859375,
                "train_grad_norm": 1.8064638317024262,
                "train_loss": 2.8278207778930664,
                "val_loss": 1.8775165670394898,
                "val_top1": 57.993999921875,
                "val_top5": 81.73399993896484
            },
            {
                "epoch": 26,
                "learning_rate": 0.05,
                "model_norm": 154.1734619140625,
                "train_grad_norm": 1.8194947505147068,
                "train_loss": 2.8011631965637207,
                "val_loss": 1.8908718474197388,
                "val_top1": 56.813999914550784,
                "val_top5": 81.064
            },
            {
                "epoch": 27,
                "learning_rate": 0.05,
                "model_norm": 154.10458374023438,
                "train_grad_norm": 1.8292984186586156,
                "train_loss": 2.773178815841675,
                "val_loss": 1.8338658040618896,
                "val_top1": 58.418000126953125,
                "val_top5": 82.00600001708985
            },
            {
                "epoch": 28,
                "learning_rate": 0.05,
                "model_norm": 154.1162109375,
                "train_grad_norm": 1.8390355419600597,
                "train_loss": 2.7495157718658447,
                "val_loss": 1.8535720191955567,
                "val_top1": 59.31400009765625,
                "val_top5": 82.76400001464843
            },
            {
                "epoch": 29,
                "learning_rate": 0.05,
                "model_norm": 154.19696044921875,
                "train_grad_norm": 1.8493390321212735,
                "train_loss": 2.7252888679504395,
                "val_loss": 1.742951736869812,
                "val_top1": 60.35200002441406,
                "val_top5": 83.48400000976562
            },
            {
                "epoch": 30,
                "learning_rate": 0.05,
                "model_norm": 154.32862854003906,
                "train_grad_norm": 1.8569739528096432,
                "train_loss": 2.7071614265441895,
                "val_loss": 1.8867174672698974,
                "val_top1": 58.924,
                "val_top5": 82.48200006835937
            },
            {
                "epoch": 31,
                "learning_rate": 0.05,
                "model_norm": 154.50140380859375,
                "train_grad_norm": 1.862756650343691,
                "train_loss": 2.684330463409424,
                "val_loss": 1.7807055185699463,
                "val_top1": 60.18200003173828,
                "val_top5": 83.2839999609375
            },
            {
                "epoch": 32,
                "learning_rate": 0.05,
                "model_norm": 154.70753479003906,
                "train_grad_norm": 1.8696242054521752,
                "train_loss": 2.665045738220215,
                "val_loss": 1.764151492881775,
                "val_top1": 59.305999877929686,
                "val_top5": 82.99600009277344
            },
            {
                "epoch": 33,
                "learning_rate": 0.05,
                "model_norm": 154.9497833251953,
                "train_grad_norm": 1.8741775305415778,
                "train_loss": 2.6454505920410156,
                "val_loss": 1.6509777028274537,
                "val_top1": 61.59999994628906,
                "val_top5": 84.68000000976562
            },
            {
                "epoch": 34,
                "learning_rate": 0.05,
                "model_norm": 155.20367431640625,
                "train_grad_norm": 1.8793010016286118,
                "train_loss": 2.6312708854675293,
                "val_loss": 1.7068025774002076,
                "val_top1": 61.68000002441406,
                "val_top5": 84.39000008789063
            },
            {
                "epoch": 35,
                "learning_rate": 0.05,
                "model_norm": 155.48712158203125,
                "train_grad_norm": 1.8825876252943858,
                "train_loss": 2.6144461631774902,
                "val_loss": 1.7585168575668335,
                "val_top1": 60.637999946289064,
                "val_top5": 83.44200006347656
            },
            {
                "epoch": 36,
                "learning_rate": 0.05,
                "model_norm": 155.78228759765625,
                "train_grad_norm": 1.8866378866070854,
                "train_loss": 2.6018829345703125,
                "val_loss": 1.6799651667022706,
                "val_top1": 61.78599999755859,
                "val_top5": 84.69199991210938
            },
            {
                "epoch": 37,
                "learning_rate": 0.05,
                "model_norm": 156.10287475585938,
                "train_grad_norm": 1.8921405650469283,
                "train_loss": 2.5887033939361572,
                "val_loss": 1.7769510555648804,
                "val_top1": 61.02800000488281,
                "val_top5": 83.88799995117188
            },
            {
                "epoch": 38,
                "learning_rate": 0.05,
                "model_norm": 156.42147827148438,
                "train_grad_norm": 1.891535903914666,
                "train_loss": 2.5751445293426514,
                "val_loss": 1.6825593894195556,
                "val_top1": 62.07600004638672,
                "val_top5": 84.58999995117188
            },
            {
                "epoch": 39,
                "learning_rate": 0.05,
                "model_norm": 156.7428436279297,
                "train_grad_norm": 1.8938382673437135,
                "train_loss": 2.562307357788086,
                "val_loss": 1.6479040602493287,
                "val_top1": 62.99799991210938,
                "val_top5": 85.30000013671875
            },
            {
                "epoch": 40,
                "learning_rate": 0.05,
                "model_norm": 157.07733154296875,
                "train_grad_norm": 1.8966081861423594,
                "train_loss": 2.5482966899871826,
                "val_loss": 1.6768919682693482,
                "val_top1": 62.57799995849609,
                "val_top5": 85.00999988769532
            },
            {
                "epoch": 41,
                "learning_rate": 0.05,
                "model_norm": 157.41439819335938,
                "train_grad_norm": 1.9018069076866233,
                "train_loss": 2.539111375808716,
                "val_loss": 1.6512813398742676,
                "val_top1": 61.68800004882812,
                "val_top5": 84.27200005859375
            },
            {
                "epoch": 42,
                "learning_rate": 0.05,
                "model_norm": 157.75975036621094,
                "train_grad_norm": 1.9034270174766588,
                "train_loss": 2.5266010761260986,
                "val_loss": 1.5848100867462158,
                "val_top1": 63.4699999609375,
                "val_top5": 85.90599987548828
            },
            {
                "epoch": 43,
                "learning_rate": 0.05,
                "model_norm": 158.11683654785156,
                "train_grad_norm": 1.9086476770022762,
                "train_loss": 2.517289638519287,
                "val_loss": 1.6291527056884765,
                "val_top1": 63.03999997314453,
                "val_top5": 85.08199993652343
            },
            {
                "epoch": 44,
                "learning_rate": 0.05,
                "model_norm": 158.4663543701172,
                "train_grad_norm": 1.9077120022067864,
                "train_loss": 2.5063345432281494,
                "val_loss": 1.662351527862549,
                "val_top1": 63.19200004394531,
                "val_top5": 85.59800003417969
            },
            {
                "epoch": 45,
                "learning_rate": 0.05,
                "model_norm": 158.82611083984375,
                "train_grad_norm": 1.910889998882888,
                "train_loss": 2.49815034866333,
                "val_loss": 1.6304171144866944,
                "val_top1": 64.31800001220704,
                "val_top5": 86.20200005859375
            },
            {
                "epoch": 46,
                "learning_rate": 0.05,
                "model_norm": 159.17027282714844,
                "train_grad_norm": 1.9103344899120134,
                "train_loss": 2.4878008365631104,
                "val_loss": 1.6125963867568969,
                "val_top1": 63.61799994628906,
                "val_top5": 85.75999992675781
            },
            {
                "epoch": 47,
                "learning_rate": 0.05,
                "model_norm": 159.5216064453125,
                "train_grad_norm": 1.9152218228589677,
                "train_loss": 2.480689287185669,
                "val_loss": 1.6507183363723754,
                "val_top1": 62.58800009765625,
                "val_top5": 84.69200011230468
            },
            {
                "epoch": 48,
                "learning_rate": 0.05,
                "model_norm": 159.8765411376953,
                "train_grad_norm": 1.9190485627599938,
                "train_loss": 2.4740147590637207,
                "val_loss": 1.582451060180664,
                "val_top1": 64.02199997070312,
                "val_top5": 86.14200008789062
            },
            {
                "epoch": 49,
                "learning_rate": 0.05,
                "model_norm": 160.22621154785156,
                "train_grad_norm": 1.9172479828447953,
                "train_loss": 2.464998960494995,
                "val_loss": 1.5126224947547913,
                "val_top1": 64.43199993652344,
                "val_top5": 86.43400002929687
            },
            {
                "epoch": 50,
                "learning_rate": 0.05,
                "model_norm": 160.56495666503906,
                "train_grad_norm": 1.917865887025469,
                "train_loss": 2.458984375,
                "val_loss": 1.5499423070907592,
                "val_top1": 64.63200006103516,
                "val_top5": 86.56200003417969
            },
            {
                "epoch": 51,
                "learning_rate": 0.05,
                "model_norm": 160.91978454589844,
                "train_grad_norm": 1.9236096815192643,
                "train_loss": 2.4498629570007324,
                "val_loss": 1.464922152671814,
                "val_top1": 66.04000005859375,
                "val_top5": 87.21000012695312
            },
            {
                "epoch": 52,
                "learning_rate": 0.05,
                "model_norm": 161.27098083496094,
                "train_grad_norm": 1.9259524138098083,
                "train_loss": 2.4428138732910156,
                "val_loss": 1.5509318914794923,
                "val_top1": 64.48400004882812,
                "val_top5": 86.34599993164062
            },
            {
                "epoch": 53,
                "learning_rate": 0.05,
                "model_norm": 161.61676025390625,
                "train_grad_norm": 1.9248789514660953,
                "train_loss": 2.4349513053894043,
                "val_loss": 1.5980054580688476,
                "val_top1": 63.58000004150391,
                "val_top5": 85.50599998291015
            },
            {
                "epoch": 54,
                "learning_rate": 0.05,
                "model_norm": 161.9622039794922,
                "train_grad_norm": 1.9272634768987713,
                "train_loss": 2.4281938076019287,
                "val_loss": 1.5357487866783142,
                "val_top1": 64.65600001953125,
                "val_top5": 86.22799997558593
            },
            {
                "epoch": 55,
                "learning_rate": 0.05,
                "model_norm": 162.31199645996094,
                "train_grad_norm": 1.931969406723329,
                "train_loss": 2.422551155090332,
                "val_loss": 1.548935608482361,
                "val_top1": 64.44799997558594,
                "val_top5": 86.32800005371094
            },
            {
                "epoch": 56,
                "learning_rate": 0.05,
                "model_norm": 162.65443420410156,
                "train_grad_norm": 1.931114665254993,
                "train_loss": 2.417259693145752,
                "val_loss": 1.5543602782058716,
                "val_top1": 64.3120001171875,
                "val_top5": 86.3579999975586
            },
            {
                "epoch": 57,
                "learning_rate": 0.05,
                "model_norm": 162.9983367919922,
                "train_grad_norm": 1.934291792643272,
                "train_loss": 2.41083025932312,
                "val_loss": 1.5430163591766357,
                "val_top1": 65.28000014160156,
                "val_top5": 86.76800010986328
            },
            {
                "epoch": 58,
                "learning_rate": 0.05,
                "model_norm": 163.35406494140625,
                "train_grad_norm": 1.9379862216126913,
                "train_loss": 2.406668186187744,
                "val_loss": 1.512519828529358,
                "val_top1": 65.6200000390625,
                "val_top5": 87.01799990234375
            },
            {
                "epoch": 59,
                "learning_rate": 0.05,
                "model_norm": 163.68411254882812,
                "train_grad_norm": 1.9346910393330343,
                "train_loss": 2.399371385574341,
                "val_loss": 1.4579472461128236,
                "val_top1": 66.49000016601562,
                "val_top5": 87.7060001611328
            },
            {
                "epoch": 60,
                "learning_rate": 0.05,
                "model_norm": 164.02027893066406,
                "train_grad_norm": 1.937137970767528,
                "train_loss": 2.3943610191345215,
                "val_loss": 1.6509110227394104,
                "val_top1": 63.512000085449216,
                "val_top5": 85.539999921875
            },
            {
                "epoch": 61,
                "learning_rate": 0.05,
                "model_norm": 164.3500518798828,
                "train_grad_norm": 1.9376816438043476,
                "train_loss": 2.38935923576355,
                "val_loss": 1.4800721837425233,
                "val_top1": 65.92200000976563,
                "val_top5": 87.39599995117187
            },
            {
                "epoch": 62,
                "learning_rate": 0.05,
                "model_norm": 164.69053649902344,
                "train_grad_norm": 1.9431283471266645,
                "train_loss": 2.383478879928589,
                "val_loss": 1.5288122465133667,
                "val_top1": 65.49200003662109,
                "val_top5": 86.75200000488282
            },
            {
                "epoch": 63,
                "learning_rate": 0.05,
                "model_norm": 165.02735900878906,
                "train_grad_norm": 1.944118039236773,
                "train_loss": 2.3808846473693848,
                "val_loss": 1.5064211080932617,
                "val_top1": 66.18599995361328,
                "val_top5": 87.45200018554688
            },
            {
                "epoch": 64,
                "learning_rate": 0.05,
                "model_norm": 165.36099243164062,
                "train_grad_norm": 1.9446405423963065,
                "train_loss": 2.3750953674316406,
                "val_loss": 1.491899467086792,
                "val_top1": 66.0439999267578,
                "val_top5": 87.42599997070313
            },
            {
                "epoch": 65,
                "learning_rate": 0.05,
                "model_norm": 165.69161987304688,
                "train_grad_norm": 1.945729379235857,
                "train_loss": 2.3709840774536133,
                "val_loss": 1.5277903295898438,
                "val_top1": 65.44199999511719,
                "val_top5": 87.09200010253906
            },
            {
                "epoch": 66,
                "learning_rate": 0.05,
                "model_norm": 166.02288818359375,
                "train_grad_norm": 1.9479318699328665,
                "train_loss": 2.365720272064209,
                "val_loss": 1.4029994912910462,
                "val_top1": 67.53800001220704,
                "val_top5": 88.07400013671875
            },
            {
                "epoch": 67,
                "learning_rate": 0.05,
                "model_norm": 166.35438537597656,
                "train_grad_norm": 1.9509095763155329,
                "train_loss": 2.3608059883117676,
                "val_loss": 1.5393668972015382,
                "val_top1": 64.33200002197266,
                "val_top5": 86.48200008544922
            },
            {
                "epoch": 68,
                "learning_rate": 0.05,
                "model_norm": 166.68353271484375,
                "train_grad_norm": 1.9509583175743601,
                "train_loss": 2.355959892272949,
                "val_loss": 1.4896834095001221,
                "val_top1": 66.39600006103515,
                "val_top5": 87.67400008300781
            },
            {
                "epoch": 69,
                "learning_rate": 0.05,
                "model_norm": 166.996826171875,
                "train_grad_norm": 1.9511049719986138,
                "train_loss": 2.3529610633850098,
                "val_loss": 1.5338847278594971,
                "val_top1": 66.60000002197266,
                "val_top5": 87.45999993164062
            },
            {
                "epoch": 70,
                "learning_rate": 0.05,
                "model_norm": 167.32347106933594,
                "train_grad_norm": 1.9551399349659748,
                "train_loss": 2.3490514755249023,
                "val_loss": 1.4787355949783325,
                "val_top1": 65.82399996337891,
                "val_top5": 87.03400005371094
            },
            {
                "epoch": 71,
                "learning_rate": 0.05,
                "model_norm": 167.64263916015625,
                "train_grad_norm": 1.9541299134621364,
                "train_loss": 2.3445420265197754,
                "val_loss": 1.6113690062713624,
                "val_top1": 64.88600001220703,
                "val_top5": 86.56400000732422
            },
            {
                "epoch": 72,
                "learning_rate": 0.05,
                "model_norm": 167.95687866210938,
                "train_grad_norm": 1.9556385042790645,
                "train_loss": 2.3407211303710938,
                "val_loss": 1.5832518230819703,
                "val_top1": 64.14400005126953,
                "val_top5": 85.9979998828125
            },
            {
                "epoch": 73,
                "learning_rate": 0.05,
                "model_norm": 168.28074645996094,
                "train_grad_norm": 1.959074133865194,
                "train_loss": 2.338665246963501,
                "val_loss": 1.4493500856399537,
                "val_top1": 66.43200006591798,
                "val_top5": 87.52999992919922
            },
            {
                "epoch": 74,
                "learning_rate": 0.05,
                "model_norm": 168.59078979492188,
                "train_grad_norm": 1.9573531958268306,
                "train_loss": 2.333418130874634,
                "val_loss": 1.5226485087394714,
                "val_top1": 66.41000006347656,
                "val_top5": 87.315999921875
            },
            {
                "epoch": 75,
                "learning_rate": 0.05,
                "model_norm": 168.9107666015625,
                "train_grad_norm": 1.9625975656198484,
                "train_loss": 2.3322677612304688,
                "val_loss": 1.6329388130569458,
                "val_top1": 63.51600001953125,
                "val_top5": 85.41999998535157
            },
            {
                "epoch": 76,
                "learning_rate": 0.05,
                "model_norm": 169.23245239257812,
                "train_grad_norm": 1.9622506056092568,
                "train_loss": 2.326179265975952,
                "val_loss": 1.4044899509048463,
                "val_top1": 67.74000002441406,
                "val_top5": 88.45200015625
            },
            {
                "epoch": 77,
                "learning_rate": 0.05,
                "model_norm": 169.5458984375,
                "train_grad_norm": 1.9638201529442685,
                "train_loss": 2.3226733207702637,
                "val_loss": 1.431941127357483,
                "val_top1": 66.42399999511719,
                "val_top5": 87.94000004882813
            },
            {
                "epoch": 78,
                "learning_rate": 0.05,
                "model_norm": 169.8493194580078,
                "train_grad_norm": 1.9640120296075347,
                "train_loss": 2.321007251739502,
                "val_loss": 1.489378656387329,
                "val_top1": 65.75800006835938,
                "val_top5": 87.16000003173828
            },
            {
                "epoch": 79,
                "learning_rate": 0.047619047619047616,
                "model_norm": 170.0734405517578,
                "train_grad_norm": 1.9645964553190456,
                "train_loss": 2.310549259185791,
                "val_loss": 1.551282751197815,
                "val_top1": 65.04400001220704,
                "val_top5": 86.51200003417969
            },
            {
                "epoch": 80,
                "learning_rate": 0.045238095238095244,
                "model_norm": 170.182861328125,
                "train_grad_norm": 1.9714362872678641,
                "train_loss": 2.292602300643921,
                "val_loss": 1.3493832078361512,
                "val_top1": 69.112,
                "val_top5": 89.01600009765625
            },
            {
                "epoch": 81,
                "learning_rate": 0.042857142857142864,
                "model_norm": 170.212158203125,
                "train_grad_norm": 1.9842952250315544,
                "train_loss": 2.2703857421875,
                "val_loss": 1.3444276870727538,
                "val_top1": 68.49799997558594,
                "val_top5": 88.912
            },
            {
                "epoch": 82,
                "learning_rate": 0.04047619047619048,
                "model_norm": 170.1754150390625,
                "train_grad_norm": 2.000216430466683,
                "train_loss": 2.2533974647521973,
                "val_loss": 1.4076888425445557,
                "val_top1": 67.90000003417968,
                "val_top5": 88.51000005371094
            },
            {
                "epoch": 83,
                "learning_rate": 0.0380952380952381,
                "model_norm": 170.0960693359375,
                "train_grad_norm": 2.0236187412709667,
                "train_loss": 2.2367236614227295,
                "val_loss": 1.337017601890564,
                "val_top1": 68.54400004394532,
                "val_top5": 88.881999921875
            },
            {
                "epoch": 84,
                "learning_rate": 0.03571428571428572,
                "model_norm": 169.96542358398438,
                "train_grad_norm": 2.0412676362829933,
                "train_loss": 2.216226577758789,
                "val_loss": 1.3781656844711303,
                "val_top1": 68.69200008544922,
                "val_top5": 88.91000004882812
            },
            {
                "epoch": 85,
                "learning_rate": 0.03333333333333334,
                "model_norm": 169.7997283935547,
                "train_grad_norm": 2.063764378865578,
                "train_loss": 2.197267532348633,
                "val_loss": 1.3926176294898986,
                "val_top1": 68.12799993164063,
                "val_top5": 88.32800000488281
            },
            {
                "epoch": 86,
                "learning_rate": 0.030952380952380953,
                "model_norm": 169.61398315429688,
                "train_grad_norm": 2.091769520919305,
                "train_loss": 2.1766116619110107,
                "val_loss": 1.2984992227172851,
                "val_top1": 70.44599997558593,
                "val_top5": 89.80600010253906
            },
            {
                "epoch": 87,
                "learning_rate": 0.02857142857142857,
                "model_norm": 169.40432739257812,
                "train_grad_norm": 2.1207729883561797,
                "train_loss": 2.15689754486084,
                "val_loss": 1.2764495121955872,
                "val_top1": 71.086000078125,
                "val_top5": 90.25799997070312
            },
            {
                "epoch": 88,
                "learning_rate": 0.026190476190476195,
                "model_norm": 169.1719512939453,
                "train_grad_norm": 2.148775480561532,
                "train_loss": 2.1352641582489014,
                "val_loss": 1.2461231491279603,
                "val_top1": 71.13199997802734,
                "val_top5": 90.20399997070312
            },
            {
                "epoch": 89,
                "learning_rate": 0.023809523809523808,
                "model_norm": 168.92189025878906,
                "train_grad_norm": 2.178662319206456,
                "train_loss": 2.1126866340637207,
                "val_loss": 1.2479375484466553,
                "val_top1": 71.15800010498047,
                "val_top5": 90.21200004882813
            },
            {
                "epoch": 90,
                "learning_rate": 0.021428571428571432,
                "model_norm": 168.6580047607422,
                "train_grad_norm": 2.2113044213069086,
                "train_loss": 2.0898942947387695,
                "val_loss": 1.2666345910072327,
                "val_top1": 71.11600009765625,
                "val_top5": 90.28800007324219
            },
            {
                "epoch": 91,
                "learning_rate": 0.01904761904761905,
                "model_norm": 168.38790893554688,
                "train_grad_norm": 2.2451805232263413,
                "train_loss": 2.0661189556121826,
                "val_loss": 1.1699887879371642,
                "val_top1": 72.69599999267578,
                "val_top5": 91.04600001953125
            },
            {
                "epoch": 92,
                "learning_rate": 0.01666666666666667,
                "model_norm": 168.1085205078125,
                "train_grad_norm": 2.2763713737392584,
                "train_loss": 2.0414836406707764,
                "val_loss": 1.1690056300354004,
                "val_top1": 72.89999994140625,
                "val_top5": 91.31400006835938
            },
            {
                "epoch": 93,
                "learning_rate": 0.014285714285714285,
                "model_norm": 167.830322265625,
                "train_grad_norm": 2.312835237376174,
                "train_loss": 2.0176587104797363,
                "val_loss": 1.1589269076919555,
                "val_top1": 73.23000007324218,
                "val_top5": 91.32599986328125
            },
            {
                "epoch": 94,
                "learning_rate": 0.011904761904761908,
                "model_norm": 167.5574493408203,
                "train_grad_norm": 2.3385331611598477,
                "train_loss": 1.9878218173980713,
                "val_loss": 1.1385864731788635,
                "val_top1": 73.458,
                "val_top5": 91.51799991699218
            },
            {
                "epoch": 95,
                "learning_rate": 0.009523809523809525,
                "model_norm": 167.3010711669922,
                "train_grad_norm": 2.370215773960615,
                "train_loss": 1.959905982017517,
                "val_loss": 1.1069599979400635,
                "val_top1": 74.46399989257813,
                "val_top5": 91.98600001708985
            },
            {
                "epoch": 96,
                "learning_rate": 0.007142857142857145,
                "model_norm": 167.07371520996094,
                "train_grad_norm": 2.3924149211685632,
                "train_loss": 1.9289159774780273,
                "val_loss": 1.1024889463996888,
                "val_top1": 74.79799999511718,
                "val_top5": 92.12400004394532
            },
            {
                "epoch": 97,
                "learning_rate": 0.004761904761904762,
                "model_norm": 166.88674926757812,
                "train_grad_norm": 2.410205404276813,
                "train_loss": 1.8996992111206055,
                "val_loss": 1.068826172657013,
                "val_top1": 75.37199999023437,
                "val_top5": 92.43799999023437
            },
            {
                "epoch": 98,
                "learning_rate": 0.0023809523809523838,
                "model_norm": 166.75930786132812,
                "train_grad_norm": 2.417088653944629,
                "train_loss": 1.8729195594787598,
                "val_loss": 1.061112990474701,
                "val_top1": 75.81000006835937,
                "val_top5": 92.66800001464844
            },
            {
                "epoch": 99,
                "learning_rate": 0.0,
                "model_norm": 166.71185302734375,
                "train_grad_norm": 2.404908374385898,
                "train_loss": 1.845858097076416,
                "val_loss": 1.044421075820923,
                "val_top1": 76.0020000415039,
                "val_top5": 92.8000000415039
            }
        ],
        "summary": {
            "len_train_loader": 1251,
            "start_time": "2025-03-27 06:52:23.330537"
        }
    },
    {
        "config": {
            "batch_size": 256,
            "dataset": "imagenet1k",
            "gradient_accumulation": 1,
            "max_epoch": 100,
            "model": "resnet50",
            "opt": {
                "lr": 0.8,
                "lr_schedule": "cosine",
                "momentum": 0.9,
                "name": "momentum",
                "weight_decay": 0.0001
            },
            "run_id": 0
        },
        "history": [
            {
                "epoch": 0,
                "learning_rate": 0.160008,
                "model_norm": 221.6685333251953,
                "train_grad_norm": 0.9139387375326757,
                "train_loss": 6.326782703399658,
                "val_loss": 5.653774476928711,
                "val_top1": 5.030000008239746,
                "val_top5": 14.031999986572266
            },
            {
                "epoch": 1,
                "learning_rate": 0.320006,
                "model_norm": 187.94020080566406,
                "train_grad_norm": 0.9073527089616047,
                "train_loss": 5.307873725891113,
                "val_loss": 4.450770338134766,
                "val_top1": 15.45000004638672,
                "val_top5": 35.01999997314453
            },
            {
                "epoch": 2,
                "learning_rate": 0.48000400000000004,
                "model_norm": 167.68589782714844,
                "train_grad_norm": 0.8503624517379329,
                "train_loss": 4.459299087524414,
                "val_loss": 3.7029609226989746,
                "val_top1": 25.068000017089844,
                "val_top5": 49.592000020751954
            },
            {
                "epoch": 3,
                "learning_rate": 0.640002,
                "model_norm": 169.51007080078125,
                "train_grad_norm": 0.7908521051478659,
                "train_loss": 3.9852521419525146,
                "val_loss": 3.3077935037994384,
                "val_top1": 31.130000092773436,
                "val_top5": 57.35800000244141
            },
            {
                "epoch": 4,
                "learning_rate": 0.7950753362380552,
                "model_norm": 181.77801513671875,
                "train_grad_norm": 0.7481970830220498,
                "train_loss": 3.753629684448242,
                "val_loss": 3.310362491760254,
                "val_top1": 32.13200000610352,
                "val_top5": 57.234000053710936
            },
            {
                "epoch": 5,
                "learning_rate": 0.7929149002914756,
                "model_norm": 191.98997497558594,
                "train_grad_norm": 0.7271234315734381,
                "train_loss": 3.6067311763763428,
                "val_loss": 3.1049879083251954,
                "val_top1": 36.10800001220703,
                "val_top5": 62.11799986816406
            },
            {
                "epoch": 6,
                "learning_rate": 0.790366704775499,
                "model_norm": 200.44241333007812,
                "train_grad_norm": 0.7339490641758667,
                "train_loss": 3.492748498916626,
                "val_loss": 2.9405484186553954,
                "val_top1": 37.647999951171876,
                "val_top5": 64.12400000976562
            },
            {
                "epoch": 7,
                "learning_rate": 0.7874332644514525,
                "model_norm": 207.99008178710938,
                "train_grad_norm": 0.7408930923091555,
                "train_loss": 3.421031951904297,
                "val_loss": 2.838371682662964,
                "val_top1": 39.76999995849609,
                "val_top5": 66.45400006347656
            },
            {
                "epoch": 8,
                "learning_rate": 0.7841174742707773,
                "model_norm": 214.69976806640625,
                "train_grad_norm": 0.7455318338963268,
                "train_loss": 3.3687543869018555,
                "val_loss": 2.894832588119507,
                "val_top1": 38.545999997558596,
                "val_top5": 64.94000007080078
            },
            {
                "epoch": 9,
                "learning_rate": 0.7804226065180615,
                "model_norm": 221.06187438964844,
                "train_grad_norm": 0.7513299598685056,
                "train_loss": 3.3291330337524414,
                "val_loss": 2.6990825862503054,
                "val_top1": 41.69800001098633,
                "val_top5": 68.23000002929687
            },
            {
                "epoch": 10,
                "learning_rate": 0.7763523075816903,
                "model_norm": 226.86203002929688,
                "train_grad_norm": 0.7553871651647892,
                "train_loss": 3.293640613555908,
                "val_loss": 2.7975401192474365,
                "val_top1": 39.616000072021485,
                "val_top5": 66.0879999633789
            },
            {
                "epoch": 11,
                "learning_rate": 0.7719105943553006,
                "model_norm": 232.5075225830078,
                "train_grad_norm": 0.7610330916537641,
                "train_loss": 3.2650389671325684,
                "val_loss": 2.647122301559448,
                "val_top1": 42.992000032958984,
                "val_top5": 69.18399998779297
            },
            {
                "epoch": 12,
                "learning_rate": 0.7671018502735925,
                "model_norm": 237.74862670898438,
                "train_grad_norm": 0.7638166417978813,
                "train_loss": 3.2437498569488525,
                "val_loss": 2.5630611611175538,
                "val_top1": 45.048,
                "val_top5": 71.67799998535156
            },
            {
                "epoch": 13,
                "learning_rate": 0.7619308209864079,
                "model_norm": 242.61073303222656,
                "train_grad_norm": 0.7668467003459261,
                "train_loss": 3.2222719192504883,
                "val_loss": 2.773816017570496,
                "val_top1": 41.593999963378906,
                "val_top5": 67.86399997802734
            },
            {
                "epoch": 14,
                "learning_rate": 0.7564026096753471,
                "model_norm": 247.32574462890625,
                "train_grad_norm": 0.770874952419936,
                "train_loss": 3.2048962116241455,
                "val_loss": 2.528944648780823,
                "val_top1": 45.30799997802735,
                "val_top5": 71.604000078125
            },
            {
                "epoch": 15,
                "learning_rate": 0.7505226720175454,
                "model_norm": 251.7828826904297,
                "train_grad_norm": 0.7735973730533143,
                "train_loss": 3.189204454421997,
                "val_loss": 2.54111113822937,
                "val_top1": 45.090000051269534,
                "val_top5": 71.215999921875
            },
            {
                "epoch": 16,
                "learning_rate": 0.7442968108015775,
                "model_norm": 255.97158813476562,
                "train_grad_norm": 0.7756359282984228,
                "train_loss": 3.1732044219970703,
                "val_loss": 2.917116057510376,
                "val_top1": 39.430000046386716,
                "val_top5": 65.91400006591797
            },
            {
                "epoch": 17,
                "learning_rate": 0.737731170200806,
                "model_norm": 260.068115234375,
                "train_grad_norm": 0.7788135656074395,
                "train_loss": 3.159501314163208,
                "val_loss": 2.564039775047302,
                "val_top1": 44.426000053710936,
                "val_top5": 70.6239999633789
            },
            {
                "epoch": 18,
                "learning_rate": 0.7308322297098248,
                "model_norm": 264.0333251953125,
                "train_grad_norm": 0.7813003312598218,
                "train_loss": 3.149113178253174,
                "val_loss": 2.2794239818191526,
                "val_top1": 49.24399993164062,
                "val_top5": 75.61799993652343
            },
            {
                "epoch": 19,
                "learning_rate": 0.723606797749979,
                "model_norm": 267.7706298828125,
                "train_grad_norm": 0.7840617318937634,
                "train_loss": 3.134941816329956,
                "val_loss": 2.559788043022156,
                "val_top1": 45.866,
                "val_top5": 72.01200006591797
            },
            {
                "epoch": 20,
                "learning_rate": 0.7160620049502762,
                "model_norm": 271.54400634765625,
                "train_grad_norm": 0.7874364855670116,
                "train_loss": 3.1248233318328857,
                "val_loss": 2.731786636657715,
                "val_top1": 42.117999970703124,
                "val_top5": 68.13199993896484
            },
            {
                "epoch": 21,
                "learning_rate": 0.7082052971103158,
                "model_norm": 275.0502014160156,
                "train_grad_norm": 0.7903734280442298,
                "train_loss": 3.111811399459839,
                "val_loss": 2.3990491429138183,
                "val_top1": 47.12800002685547,
                "val_top5": 73.33400005126953
            },
            {
                "epoch": 22,
                "learning_rate": 0.7000444278521839,
                "model_norm": 278.3857421875,
                "train_grad_norm": 0.7933488102232779,
                "train_loss": 3.1006627082824707,
                "val_loss": 2.3650254860687254,
                "val_top1": 48.14000006835938,
                "val_top5": 74.13800000976562
            },
            {
                "epoch": 23,
                "learning_rate": 0.6915874509685647,
                "model_norm": 281.71124267578125,
                "train_grad_norm": 0.7968269282378899,
                "train_loss": 3.090744972229004,
                "val_loss": 2.609051834564209,
                "val_top1": 44.51600003417969,
                "val_top5": 70.46399995117187
            },
            {
                "epoch": 24,
                "learning_rate": 0.682842712474619,
                "model_norm": 284.71820068359375,
                "train_grad_norm": 0.7992424298524967,
                "train_loss": 3.0785651206970215,
                "val_loss": 2.897853701171875,
                "val_top1": 39.609999979248045,
                "val_top5": 65.24200003417968
            },
            {
                "epoch": 25,
                "learning_rate": 0.6738188423714755,
                "model_norm": 287.7253723144531,
                "train_grad_norm": 0.8025712476433058,
                "train_loss": 3.06962513923645,
                "val_loss": 2.6570297622680665,
                "val_top1": 43.179999998779294,
                "val_top5": 69.4720000024414
            },
            {
                "epoch": 26,
                "learning_rate": 0.6645247461294608,
                "model_norm": 290.6405029296875,
                "train_grad_norm": 0.8065105997717542,
                "train_loss": 3.058534622192383,
                "val_loss": 2.306358982849121,
                "val_top1": 48.40200008544922,
                "val_top5": 74.8219999584961
            },
            {
                "epoch": 27,
                "learning_rate": 0.6549695958994759,
                "model_norm": 293.40826416015625,
                "train_grad_norm": 0.8105722115319447,
                "train_loss": 3.0486512184143066,
                "val_loss": 2.924646444244385,
                "val_top1": 39.700000012207035,
                "val_top5": 65.36399991699219
            },
            {
                "epoch": 28,
                "learning_rate": 0.6451628214611906,
                "model_norm": 296.072998046875,
                "train_grad_norm": 0.8135719322429029,
                "train_loss": 3.0398242473602295,
                "val_loss": 2.7746509237670898,
                "val_top1": 42.33599997070313,
                "val_top5": 67.72800006835938
            },
            {
                "epoch": 29,
                "learning_rate": 0.6351141009169893,
                "model_norm": 298.737548828125,
                "train_grad_norm": 0.8193233301246147,
                "train_loss": 3.027637004852295,
                "val_loss": 2.1818141331100462,
                "val_top1": 51.794000102539066,
                "val_top5": 77.57799999511718
            },
            {
                "epoch": 30,
                "learning_rate": 0.6248333511408524,
                "model_norm": 301.1788024902344,
                "train_grad_norm": 0.8228334721779038,
                "train_loss": 3.0201337337493896,
                "val_loss": 2.6158414861297605,
                "val_top1": 44.25000004150391,
                "val_top5": 70.31799997802734
            },
            {
                "epoch": 31,
                "learning_rate": 0.6143307179915987,
                "model_norm": 303.5726623535156,
                "train_grad_norm": 0.8267692534905476,
                "train_loss": 3.0072779655456543,
                "val_loss": 2.557196389579773,
                "val_top1": 45.88000000488281,
                "val_top5": 71.44800001220703
            },
            {
                "epoch": 32,
                "learning_rate": 0.6036165663001486,
                "model_norm": 305.8443298339844,
                "train_grad_norm": 0.8310421465392674,
                "train_loss": 2.9953079223632812,
                "val_loss": 2.2960590843963624,
                "val_top1": 49.10800006958008,
                "val_top5": 75.14599998535157
            },
            {
                "epoch": 33,
                "learning_rate": 0.5927014696406862,
                "model_norm": 308.119384765625,
                "train_grad_norm": 0.836620907925538,
                "train_loss": 2.9845383167266846,
                "val_loss": 2.3891310886383055,
                "val_top1": 47.48400008789063,
                "val_top5": 73.58800008789062
            },
            {
                "epoch": 34,
                "learning_rate": 0.5815961998958187,
                "model_norm": 310.2023010253906,
                "train_grad_norm": 0.8410245878462652,
                "train_loss": 2.9744925498962402,
                "val_loss": 2.3476449794769287,
                "val_top1": 48.76800003540039,
                "val_top5": 74.50600005859376
            },
            {
                "epoch": 35,
                "learning_rate": 0.5703117166260291,
                "model_norm": 312.2879333496094,
                "train_grad_norm": 0.8476534556021741,
                "train_loss": 2.9653422832489014,
                "val_loss": 2.4351321113586426,
                "val_top1": 47.23600001953125,
                "val_top5": 73.2079999609375
            },
            {
                "epoch": 36,
                "learning_rate": 0.5588591562539124,
                "model_norm": 314.25469970703125,
                "train_grad_norm": 0.8521070928806801,
                "train_loss": 2.95550274848938,
                "val_loss": 2.163034867477417,
                "val_top1": 52.66,
                "val_top5": 77.91200005371094
            },
            {
                "epoch": 37,
                "learning_rate": 0.5472498210738712,
                "model_norm": 316.0137634277344,
                "train_grad_norm": 0.8562570037415941,
                "train_loss": 2.9434947967529297,
                "val_loss": 2.2331218904113768,
                "val_top1": 51.10799986328125,
                "val_top5": 76.68399992431641
            },
            {
                "epoch": 38,
                "learning_rate": 0.5354951680981167,
                "model_norm": 317.90325927734375,
                "train_grad_norm": 0.8644684255435485,
                "train_loss": 2.9343109130859375,
                "val_loss": 2.2927506241989137,
                "val_top1": 51.19600001220703,
                "val_top5": 76.12600003173829
            },
            {
                "epoch": 39,
                "learning_rate": 0.523606797749979,
                "model_norm": 319.6226501464844,
                "train_grad_norm": 0.8696589586777543,
                "train_loss": 2.9222097396850586,
                "val_loss": 2.1738149828338624,
                "val_top1": 51.55800005859375,
                "val_top5": 77.44000002929687
            },
            {
                "epoch": 40,
                "learning_rate": 0.5115964424156918,
                "model_norm": 321.2285461425781,
                "train_grad_norm": 0.8751084776657285,
                "train_loss": 2.906749963760376,
                "val_loss": 2.3614285567474367,
                "val_top1": 48.26000004638672,
                "val_top5": 73.98600006347657
            },
            {
                "epoch": 41,
                "learning_rate": 0.49947595486594204,
                "model_norm": 322.8030090332031,
                "train_grad_norm": 0.8820696780468181,
                "train_loss": 2.897343635559082,
                "val_loss": 2.3317259460067747,
                "val_top1": 49.05000002685547,
                "val_top5": 74.63800008789063
            },
            {
                "epoch": 42,
                "learning_rate": 0.48725729655861705,
                "model_norm": 324.31488037109375,
                "train_grad_norm": 0.8889272957918946,
                "train_loss": 2.8846938610076904,
                "val_loss": 2.8932476592254637,
                "val_top1": 40.41599998779297,
                "val_top5": 65.61199997070312
            },
            {
                "epoch": 43,
                "learning_rate": 0.47495252583428993,
                "model_norm": 325.7272033691406,
                "train_grad_norm": 0.8957634896385214,
                "train_loss": 2.87298583984375,
                "val_loss": 2.158824303779602,
                "val_top1": 52.937999877929684,
                "val_top5": 77.80600008300782
            },
            {
                "epoch": 44,
                "learning_rate": 0.4625737860160924,
                "model_norm": 327.1081848144531,
                "train_grad_norm": 0.9030633796001281,
                "train_loss": 2.859874725341797,
                "val_loss": 2.283328854217529,
                "val_top1": 49.957999978027345,
                "val_top5": 75.12999987792969
            },
            {
                "epoch": 45,
                "learning_rate": 0.4501332934257217,
                "model_norm": 328.3419189453125,
                "train_grad_norm": 0.9091913334319237,
                "train_loss": 2.8487229347229004,
                "val_loss": 2.0553175217056276,
                "val_top1": 54.79800007080078,
                "val_top5": 79.36199994873047
            },
            {
                "epoch": 46,
                "learning_rate": 0.43764332532740574,
                "model_norm": 329.5508728027344,
                "train_grad_norm": 0.9172925883666786,
                "train_loss": 2.8337574005126953,
                "val_loss": 2.09807944606781,
                "val_top1": 53.182000073242186,
                "val_top5": 78.57399999023437
            },
            {
                "epoch": 47,
                "learning_rate": 0.42511620781172543,
                "model_norm": 330.73577880859375,
                "train_grad_norm": 0.9258045784328757,
                "train_loss": 2.8219990730285645,
                "val_loss": 2.2261730264282225,
                "val_top1": 50.90800006835938,
                "val_top5": 76.01599991210938
            },
            {
                "epoch": 48,
                "learning_rate": 0.41256430363125124,
                "model_norm": 331.83984375,
                "train_grad_norm": 0.9340984578360007,
                "train_loss": 2.8098318576812744,
                "val_loss": 1.9515249437713622,
                "val_top1": 56.14800006835937,
                "val_top5": 80.48000004882813
            },
            {
                "epoch": 49,
                "learning_rate": 0.4,
                "model_norm": 332.802734375,
                "train_grad_norm": 0.941137993795818,
                "train_loss": 2.79689359664917,
                "val_loss": 2.2955209076690672,
                "val_top1": 49.21000005493164,
                "val_top5": 74.82999996826172
            },
            {
                "epoch": 50,
                "learning_rate": 0.3874356963687488,
                "model_norm": 333.799072265625,
                "train_grad_norm": 0.9517953790591117,
                "train_loss": 2.7834389209747314,
                "val_loss": 2.2562972562408445,
                "val_top1": 51.166000100097655,
                "val_top5": 76.05400005615235
            },
            {
                "epoch": 51,
                "learning_rate": 0.37488379218827467,
                "model_norm": 334.759765625,
                "train_grad_norm": 0.9615811112264918,
                "train_loss": 2.7693428993225098,
                "val_loss": 2.06507170463562,
                "val_top1": 54.38799996582031,
                "val_top5": 79.15399996337891
            },
            {
                "epoch": 52,
                "learning_rate": 0.36235667467259436,
                "model_norm": 335.5762634277344,
                "train_grad_norm": 0.9700356076487765,
                "train_loss": 2.7549707889556885,
                "val_loss": 2.027049013786316,
                "val_top1": 54.87200000732422,
                "val_top5": 79.7200000048828
            },
            {
                "epoch": 53,
                "learning_rate": 0.3498667065742784,
                "model_norm": 336.38018798828125,
                "train_grad_norm": 0.9808574018726499,
                "train_loss": 2.7406692504882812,
                "val_loss": 2.0253373906707766,
                "val_top1": 54.33999997802734,
                "val_top5": 79.02199998046875
            },
            {
                "epoch": 54,
                "learning_rate": 0.3374262139839077,
                "model_norm": 337.12420654296875,
                "train_grad_norm": 0.9909743790036872,
                "train_loss": 2.7249910831451416,
                "val_loss": 1.9327496308898926,
                "val_top1": 56.409999951171876,
                "val_top5": 81.02600001953125
            },
            {
                "epoch": 55,
                "learning_rate": 0.32504747416571017,
                "model_norm": 337.80426025390625,
                "train_grad_norm": 1.0016065313543374,
                "train_loss": 2.7088894844055176,
                "val_loss": 1.9892105005645753,
                "val_top1": 55.847999946289065,
                "val_top5": 80.40999999023437
            },
            {
                "epoch": 56,
                "learning_rate": 0.312742703441383,
                "model_norm": 338.4502258300781,
                "train_grad_norm": 1.013115365493787,
                "train_loss": 2.6959197521209717,
                "val_loss": 1.8539710626983643,
                "val_top1": 58.328000021972656,
                "val_top5": 82.49800002197266
            },
            {
                "epoch": 57,
                "learning_rate": 0.30052404513405817,
                "model_norm": 339.0672912597656,
                "train_grad_norm": 1.024862965564725,
                "train_loss": 2.6807150840759277,
                "val_loss": 2.0080919661712646,
                "val_top1": 56.878000053710934,
                "val_top5": 80.87400000976562
            },
            {
                "epoch": 58,
                "learning_rate": 0.28840355758430836,
                "model_norm": 339.6318664550781,
                "train_grad_norm": 1.0377607245260878,
                "train_loss": 2.6653237342834473,
                "val_loss": 1.9718823169708253,
                "val_top1": 56.109999956054686,
                "val_top5": 80.50199994140625
            },
            {
                "epoch": 59,
                "learning_rate": 0.27639320225002106,
                "model_norm": 340.0707092285156,
                "train_grad_norm": 1.048409376315693,
                "train_loss": 2.6478400230407715,
                "val_loss": 1.8279224387741089,
                "val_top1": 59.04399998779297,
                "val_top5": 82.59000015136719
            },
            {
                "epoch": 60,
                "learning_rate": 0.26450483190188345,
                "model_norm": 340.48779296875,
                "train_grad_norm": 1.0616898872551053,
                "train_loss": 2.6314687728881836,
                "val_loss": 1.7737344131088257,
                "val_top1": 60.43600004150391,
                "val_top5": 83.66800002929688
            },
            {
                "epoch": 61,
                "learning_rate": 0.25275017892612894,
                "model_norm": 340.91754150390625,
                "train_grad_norm": 1.0776621149641044,
                "train_loss": 2.6160566806793213,
                "val_loss": 1.7229108418655394,
                "val_top1": 61.23200007324219,
                "val_top5": 84.07000001220703
            },
            {
                "epoch": 62,
                "learning_rate": 0.2411408437460877,
                "model_norm": 341.2911682128906,
                "train_grad_norm": 1.0921463741613415,
                "train_loss": 2.5964207649230957,
                "val_loss": 1.7490350630187987,
                "val_top1": 59.905999978027346,
                "val_top5": 83.44800009277344
            },
            {
                "epoch": 63,
                "learning_rate": 0.22968828337397096,
                "model_norm": 341.59686279296875,
                "train_grad_norm": 1.1055533415819823,
                "train_loss": 2.580775737762451,
                "val_loss": 1.6892269268035889,
                "val_top1": 61.44600001953125,
                "val_top5": 84.2539999633789
            },
            {
                "epoch": 64,
                "learning_rate": 0.2184038001041813,
                "model_norm": 341.8564758300781,
                "train_grad_norm": 1.1207360557410433,
                "train_loss": 2.5620625019073486,
                "val_loss": 1.7246744378662109,
                "val_top1": 61.057999997558596,
                "val_top5": 84.2700000415039
            },
            {
                "epoch": 65,
                "learning_rate": 0.20729853035931384,
                "model_norm": 342.0746765136719,
                "train_grad_norm": 1.1374299389822964,
                "train_loss": 2.5450940132141113,
                "val_loss": 1.6946577562713623,
                "val_top1": 61.748,
                "val_top5": 84.43800000976563
            },
            {
                "epoch": 66,
                "learning_rate": 0.19638343369985148,
                "model_norm": 342.27374267578125,
                "train_grad_norm": 1.1552164329124355,
                "train_loss": 2.5272955894470215,
                "val_loss": 1.601941304550171,
                "val_top1": 63.46599996582031,
                "val_top5": 85.74200000732422
            },
            {
                "epoch": 67,
                "learning_rate": 0.18566928200840144,
                "model_norm": 342.4322509765625,
                "train_grad_norm": 1.17426139191138,
                "train_loss": 2.5081210136413574,
                "val_loss": 1.589969792251587,
                "val_top1": 64.09399995117188,
                "val_top5": 86.2159999609375
            },
            {
                "epoch": 68,
                "learning_rate": 0.17516664885914787,
                "model_norm": 342.5345458984375,
                "train_grad_norm": 1.1904430702358244,
                "train_loss": 2.48567533493042,
                "val_loss": 1.9612572930908203,
                "val_top1": 57.05000001220703,
                "val_top5": 80.8720000439453
            },
            {
                "epoch": 69,
                "learning_rate": 0.1648858990830108,
                "model_norm": 342.625244140625,
                "train_grad_norm": 1.2118604466320153,
                "train_loss": 2.468029022216797,
                "val_loss": 1.6316329247283936,
                "val_top1": 63.25600002929688,
                "val_top5": 85.81199995605469
            },
            {
                "epoch": 70,
                "learning_rate": 0.15483717853880938,
                "model_norm": 342.67852783203125,
                "train_grad_norm": 1.2321107122367103,
                "train_loss": 2.4494690895080566,
                "val_loss": 1.5380256036758422,
                "val_top1": 64.62400007080078,
                "val_top5": 86.39200000488282
            },
            {
                "epoch": 71,
                "learning_rate": 0.14503040410052412,
                "model_norm": 342.7039489746094,
                "train_grad_norm": 1.2546353573069164,
                "train_loss": 2.4277865886688232,
                "val_loss": 1.7347912905502318,
                "val_top1": 61.556,
                "val_top5": 84.2320001171875
            },
            {
                "epoch": 72,
                "learning_rate": 0.13547525387053932,
                "model_norm": 342.6865234375,
                "train_grad_norm": 1.275919037790559,
                "train_loss": 2.4065637588500977,
                "val_loss": 1.5368379938125611,
                "val_top1": 64.91800004882812,
                "val_top5": 86.44799990722656
            },
            {
                "epoch": 73,
                "learning_rate": 0.12618115762852464,
                "model_norm": 342.6551818847656,
                "train_grad_norm": 1.3010194068790368,
                "train_loss": 2.385295867919922,
                "val_loss": 1.4244436378479004,
                "val_top1": 67.6800000805664,
                "val_top5": 88.075999921875
            },
            {
                "epoch": 74,
                "learning_rate": 0.11715728752538089,
                "model_norm": 342.5888977050781,
                "train_grad_norm": 1.3254478925883064,
                "train_loss": 2.3639979362487793,
                "val_loss": 1.471112883090973,
                "val_top1": 66.98199993164063,
                "val_top5": 87.875999921875
            },
            {
                "epoch": 75,
                "learning_rate": 0.10841254903143534,
                "model_norm": 342.4913330078125,
                "train_grad_norm": 1.3508603833285389,
                "train_loss": 2.341714859008789,
                "val_loss": 1.401872262763977,
                "val_top1": 67.57800006835937,
                "val_top5": 88.38599995361328
            },
            {
                "epoch": 76,
                "learning_rate": 0.09995557214781617,
                "model_norm": 342.3705749511719,
                "train_grad_norm": 1.3766054226617213,
                "train_loss": 2.3174757957458496,
                "val_loss": 1.5687546337509155,
                "val_top1": 64.22799997070312,
                "val_top5": 86.31000010742187
            },
            {
                "epoch": 77,
                "learning_rate": 0.09179470288968435,
                "model_norm": 342.2272644042969,
                "train_grad_norm": 1.406496533831224,
                "train_loss": 2.293062686920166,
                "val_loss": 1.45713538898468,
                "val_top1": 66.9820000048828,
                "val_top5": 87.71999997070313
            },
            {
                "epoch": 78,
                "learning_rate": 0.08393799504972393,
                "model_norm": 342.059814453125,
                "train_grad_norm": 1.435221182603743,
                "train_loss": 2.270535945892334,
                "val_loss": 1.3489501847267151,
                "val_top1": 68.78600002441407,
                "val_top5": 89.21800002441407
            },
            {
                "epoch": 79,
                "learning_rate": 0.07639320225002107,
                "model_norm": 341.8714294433594,
                "train_grad_norm": 1.4647069419245131,
                "train_loss": 2.2474515438079834,
                "val_loss": 1.2683924631500245,
                "val_top1": 70.3140000024414,
                "val_top5": 90.09600018066406
            },
            {
                "epoch": 80,
                "learning_rate": 0.06916777029017522,
                "model_norm": 341.6710510253906,
                "train_grad_norm": 1.4978908660015922,
                "train_loss": 2.2234084606170654,
                "val_loss": 1.3298531278038024,
                "val_top1": 69.5459999243164,
                "val_top5": 89.50400004882812
            },
            {
                "epoch": 81,
                "learning_rate": 0.06226882979919397,
                "model_norm": 341.4537658691406,
                "train_grad_norm": 1.5301803234809956,
                "train_loss": 2.194408893585205,
                "val_loss": 1.2797425301742553,
                "val_top1": 70.33400005371094,
                "val_top5": 90.15200013183593
            },
            {
                "epoch": 82,
                "learning_rate": 0.05570318919842259,
                "model_norm": 341.22955322265625,
                "train_grad_norm": 1.5669079739278686,
                "train_loss": 2.170236110687256,
                "val_loss": 1.2385823587608338,
                "val_top1": 71.07199994384766,
                "val_top5": 90.51600004638672
            },
            {
                "epoch": 83,
                "learning_rate": 0.04947732798245466,
                "model_norm": 340.9942626953125,
                "train_grad_norm": 1.600432489236141,
                "train_loss": 2.143916130065918,
                "val_loss": 1.2780296813583374,
                "val_top1": 70.54199994873046,
                "val_top5": 89.95600005371094
            },
            {
                "epoch": 84,
                "learning_rate": 0.04359739032465289,
                "model_norm": 340.75555419921875,
                "train_grad_norm": 1.639708842099281,
                "train_loss": 2.116960048675537,
                "val_loss": 1.1962278197479248,
                "val_top1": 72.401999921875,
                "val_top5": 91.08399997070312
            },
            {
                "epoch": 85,
                "learning_rate": 0.03806917901359217,
                "model_norm": 340.510009765625,
                "train_grad_norm": 1.673597126693212,
                "train_loss": 2.0891239643096924,
                "val_loss": 1.2117165809249877,
                "val_top1": 72.35000005126953,
                "val_top5": 90.974
            },
            {
                "epoch": 86,
                "learning_rate": 0.03289814972640755,
                "model_norm": 340.2681579589844,
                "train_grad_norm": 1.712453800019562,
                "train_loss": 2.059279441833496,
                "val_loss": 1.1432709991073609,
                "val_top1": 73.76200007080078,
                "val_top5": 91.78599991699218
            },
            {
                "epoch": 87,
                "learning_rate": 0.028089405644699462,
                "model_norm": 340.0315856933594,
                "train_grad_norm": 1.748746248296971,
                "train_loss": 2.0325279235839844,
                "val_loss": 1.125073257007599,
                "val_top1": 73.97200006835938,
                "val_top5": 91.88200011962891
            },
            {
                "epoch": 88,
                "learning_rate": 0.02364769241830982,
                "model_norm": 339.80560302734375,
                "train_grad_norm": 1.7871367229848294,
                "train_loss": 2.0032668113708496,
                "val_loss": 1.104659596824646,
                "val_top1": 74.24199996582031,
                "val_top5": 92.21599993896484
            },
            {
                "epoch": 89,
                "learning_rate": 0.019577393481938588,
                "model_norm": 339.5938415527344,
                "train_grad_norm": 1.8247116809506032,
                "train_loss": 1.9755287170410156,
                "val_loss": 1.0785895997619628,
                "val_top1": 75.09399998779297,
                "val_top5": 92.51399996337891
            },
            {
                "epoch": 90,
                "learning_rate": 0.01588252572922282,
                "model_norm": 339.3990173339844,
                "train_grad_norm": 1.8594653376996324,
                "train_loss": 1.9490265846252441,
                "val_loss": 1.0477483436203003,
                "val_top1": 75.8299999609375,
                "val_top5": 92.97400001464844
            },
            {
                "epoch": 91,
                "learning_rate": 0.012566735548547571,
                "model_norm": 339.22589111328125,
                "train_grad_norm": 1.8901230672991831,
                "train_loss": 1.9216282367706299,
                "val_loss": 1.0463522092437745,
                "val_top1": 75.82200006103515,
                "val_top5": 92.72599993896485
            },
            {
                "epoch": 92,
                "learning_rate": 0.00963329522450107,
                "model_norm": 339.0765686035156,
                "train_grad_norm": 1.9180106486084578,
                "train_loss": 1.8987126350402832,
                "val_loss": 1.0262660688209533,
                "val_top1": 76.24000011230468,
                "val_top5": 93.0779999633789
            },
            {
                "epoch": 93,
                "learning_rate": 0.007085099708524512,
                "model_norm": 338.9541931152344,
                "train_grad_norm": 1.9435172942762482,
                "train_loss": 1.8778928518295288,
                "val_loss": 1.0081923922348022,
                "val_top1": 76.56600000488281,
                "val_top5": 93.2500000390625
            },
            {
                "epoch": 94,
                "learning_rate": 0.004924663761944937,
                "model_norm": 338.8592834472656,
                "train_grad_norm": 1.957917482162043,
                "train_loss": 1.8568767309188843,
                "val_loss": 0.9896414839935302,
                "val_top1": 77.03799995605469,
                "val_top5": 93.52200009277344
            },
            {
                "epoch": 95,
                "learning_rate": 0.0031541194742088943,
                "model_norm": 338.79156494140625,
                "train_grad_norm": 1.9729026377597483,
                "train_loss": 1.8391802310943604,
                "val_loss": 0.9870094503211975,
                "val_top1": 77.10599998291016,
                "val_top5": 93.5200000415039
            },
            {
                "epoch": 96,
                "learning_rate": 0.0017752141587680016,
                "model_norm": 338.7481994628906,
                "train_grad_norm": 1.9748548828756052,
                "train_loss": 1.8253111839294434,
                "val_loss": 0.9812143080139161,
                "val_top1": 77.31799992919922,
                "val_top5": 93.65800001464844
            },
            {
                "epoch": 97,
                "learning_rate": 0.0007893086286913765,
                "model_norm": 338.72503662109375,
                "train_grad_norm": 1.9782457367914958,
                "train_loss": 1.815977931022644,
                "val_loss": 0.978742622680664,
                "val_top1": 77.46399992919922,
                "val_top5": 93.69400006591796
            },
            {
                "epoch": 98,
                "learning_rate": 0.00019737585370736,
                "model_norm": 338.7162780761719,
                "train_grad_norm": 1.9784560020012478,
                "train_loss": 1.812284231185913,
                "val_loss": 0.9857081330108642,
                "val_top1": 77.51600003417968,
                "val_top5": 93.6200000415039
            },
            {
                "epoch": 99,
                "learning_rate": 0.0,
                "model_norm": 338.7149963378906,
                "train_grad_norm": 1.9768165006805711,
                "train_loss": 1.8080360889434814,
                "val_loss": 0.9735933298873901,
                "val_top1": 77.52000005859375,
                "val_top5": 93.63999996337891
            }
        ],
        "summary": {
            "len_train_loader": 1251,
            "start_time": "2025-03-28 05:27:07.093261"
        }
    },
    {
        "config": {
            "batch_size": 256,
            "dataset": "imagenet1k",
            "gradient_accumulation": 1,
            "max_epoch": 100,
            "model": "resnet50",
            "opt": {
                "lr": 0.05,
                "lr_schedule": "cosine",
                "momentum": 0.9,
                "name": "momentum",
                "weight_decay": 0.0001
            },
            "run_id": 0
        },
        "history": [
            {
                "epoch": 0,
                "learning_rate": 0.010008,
                "model_norm": 237.3531494140625,
                "train_grad_norm": 0.8443082665461962,
                "train_loss": 6.730618476867676,
                "val_loss": 6.368458641662597,
                "val_top1": 2.0640000122070314,
                "val_top5": 6.504000007324219
            },
            {
                "epoch": 1,
                "learning_rate": 0.020006,
                "model_norm": 234.09422302246094,
                "train_grad_norm": 1.2991238288878146,
                "train_loss": 6.319809913635254,
                "val_loss": 5.93549742980957,
                "val_top1": 4.135999998168946,
                "val_top5": 11.864000028076171
            },
            {
                "epoch": 2,
                "learning_rate": 0.030004,
                "model_norm": 228.8616485595703,
                "train_grad_norm": 1.2935362860156883,
                "train_loss": 6.015058994293213,
                "val_loss": 5.51091511138916,
                "val_top1": 6.121999997558594,
                "val_top5": 16.94400001098633
            },
            {
                "epoch": 3,
                "learning_rate": 0.040002,
                "model_norm": 222.0037841796875,
                "train_grad_norm": 1.3745914990660857,
                "train_loss": 5.6893463134765625,
                "val_loss": 5.058516919250488,
                "val_top1": 9.17000000061035,
                "val_top5": 23.687999985351563
            },
            {
                "epoch": 4,
                "learning_rate": 0.04969220851487845,
                "model_norm": 214.02706909179688,
                "train_grad_norm": 1.484510625222221,
                "train_loss": 5.316610336303711,
                "val_loss": 4.6559423858642575,
                "val_top1": 13.081999982910157,
                "val_top5": 30.55600000732422
            },
            {
                "epoch": 5,
                "learning_rate": 0.049557181268217225,
                "model_norm": 206.21778869628906,
                "train_grad_norm": 1.5548227476853018,
                "train_loss": 4.90717077255249,
                "val_loss": 4.502787880477905,
                "val_top1": 15.405999989013672,
                "val_top5": 34.32200002441406
            },
            {
                "epoch": 6,
                "learning_rate": 0.049397919048468686,
                "model_norm": 199.316162109375,
                "train_grad_norm": 1.6007901508658373,
                "train_loss": 4.5499114990234375,
                "val_loss": 3.785485757369995,
                "val_top1": 23.625999995117187,
                "val_top5": 47.30000005615234
            },
            {
                "epoch": 7,
                "learning_rate": 0.04921457902821578,
                "model_norm": 193.20603942871094,
                "train_grad_norm": 1.6344962118428654,
                "train_loss": 4.271883010864258,
                "val_loss": 3.4548992414093016,
                "val_top1": 29.04399999633789,
                "val_top5": 54.05800002197265
            },
            {
                "epoch": 8,
                "learning_rate": 0.04900734214192358,
                "model_norm": 187.8235321044922,
                "train_grad_norm": 1.6543611720573654,
                "train_loss": 4.046149253845215,
                "val_loss": 3.2451186267852785,
                "val_top1": 33.254000029296876,
                "val_top5": 59.24999997070312
            },
            {
                "epoch": 9,
                "learning_rate": 0.048776412907378844,
                "model_norm": 183.06817626953125,
                "train_grad_norm": 1.667044551639615,
                "train_loss": 3.8560051918029785,
                "val_loss": 3.1581799618530275,
                "val_top1": 33.53199997192383,
                "val_top5": 59.76400009765625
            },
            {
                "epoch": 10,
                "learning_rate": 0.04852201922385564,
                "model_norm": 178.87136840820312,
                "train_grad_norm": 1.6781390705486516,
                "train_loss": 3.699211359024048,
                "val_loss": 2.732769893989563,
                "val_top1": 41.20999998046875,
                "val_top5": 67.28000001464844
            },
            {
                "epoch": 11,
                "learning_rate": 0.04824441214720629,
                "model_norm": 175.1813201904297,
                "train_grad_norm": 1.6931168772447691,
                "train_loss": 3.5704872608184814,
                "val_loss": 2.6669410150146486,
                "val_top1": 41.87000001586914,
                "val_top5": 68.03200004882812
            },
            {
                "epoch": 12,
                "learning_rate": 0.04794386564209953,
                "model_norm": 171.93841552734375,
                "train_grad_norm": 1.7047582757798652,
                "train_loss": 3.4662017822265625,
                "val_loss": 2.605321597251892,
                "val_top1": 44.38200008056641,
                "val_top5": 70.4220000756836
            },
            {
                "epoch": 13,
                "learning_rate": 0.04762067631165049,
                "model_norm": 169.09423828125,
                "train_grad_norm": 1.714825749396644,
                "train_loss": 3.3766541481018066,
                "val_loss": 2.677158893432617,
                "val_top1": 44.35599994873047,
                "val_top5": 69.95599999511718
            },
            {
                "epoch": 14,
                "learning_rate": 0.047275163104709195,
                "model_norm": 166.6055145263672,
                "train_grad_norm": 1.7253000721354808,
                "train_loss": 3.2955703735351562,
                "val_loss": 2.3835465839385988,
                "val_top1": 48.35000013183594,
                "val_top5": 73.59199998046876
            },
            {
                "epoch": 15,
                "learning_rate": 0.04690766700109659,
                "model_norm": 164.43075561523438,
                "train_grad_norm": 1.7347021082315774,
                "train_loss": 3.231023073196411,
                "val_loss": 2.3065513792800902,
                "val_top1": 49.38400007080078,
                "val_top5": 75.4380000732422
            },
            {
                "epoch": 16,
                "learning_rate": 0.046518550675098594,
                "model_norm": 162.5351104736328,
                "train_grad_norm": 1.745852328352224,
                "train_loss": 3.1699657440185547,
                "val_loss": 2.312043529129028,
                "val_top1": 50.38799994873047,
                "val_top5": 75.05800003173829
            },
            {
                "epoch": 17,
                "learning_rate": 0.04610819813755038,
                "model_norm": 160.8962860107422,
                "train_grad_norm": 1.7615847709397776,
                "train_loss": 3.117058038711548,
                "val_loss": 2.1572990420150755,
                "val_top1": 51.77999994628906,
                "val_top5": 76.79799999755859
            },
            {
                "epoch": 18,
                "learning_rate": 0.04567701435686405,
                "model_norm": 159.4771728515625,
                "train_grad_norm": 1.7715334871644337,
                "train_loss": 3.069014549255371,
                "val_loss": 2.0837660125732422,
                "val_top1": 54.25399993164063,
                "val_top5": 78.89599994140625
            },
            {
                "epoch": 19,
                "learning_rate": 0.04522542485937369,
                "model_norm": 158.25794982910156,
                "train_grad_norm": 1.787124509696847,
                "train_loss": 3.0246448516845703,
                "val_loss": 2.0256294397735597,
                "val_top1": 54.331999982910155,
                "val_top5": 79.39200012207031
            },
            {
                "epoch": 20,
                "learning_rate": 0.04475387530939226,
                "model_norm": 157.217041015625,
                "train_grad_norm": 1.7998146338762278,
                "train_loss": 2.984961986541748,
                "val_loss": 1.9973844534301757,
                "val_top1": 55.842000056152344,
                "val_top5": 80.28399999267579
            },
            {
                "epoch": 21,
                "learning_rate": 0.044262831069394735,
                "model_norm": 156.32806396484375,
                "train_grad_norm": 1.8159791742314741,
                "train_loss": 2.949312925338745,
                "val_loss": 2.0431425563812255,
                "val_top1": 54.71399995117188,
                "val_top5": 79.28200009277344
            },
            {
                "epoch": 22,
                "learning_rate": 0.043752776740761494,
                "model_norm": 155.57095336914062,
                "train_grad_norm": 1.8301657637649942,
                "train_loss": 2.9140968322753906,
                "val_loss": 1.9189091536331178,
                "val_top1": 57.74400016113281,
                "val_top5": 81.65799999755859
            },
            {
                "epoch": 23,
                "learning_rate": 0.04322421568553529,
                "model_norm": 154.9437255859375,
                "train_grad_norm": 1.84789529412231,
                "train_loss": 2.88303542137146,
                "val_loss": 1.9370119998168944,
                "val_top1": 57.47800010253906,
                "val_top5": 81.16199999267577
            },
            {
                "epoch": 24,
                "learning_rate": 0.04267766952966369,
                "model_norm": 154.42391967773438,
                "train_grad_norm": 1.8628089621842556,
                "train_loss": 2.8511297702789307,
                "val_loss": 1.8786304441070556,
                "val_top1": 57.91200011230469,
                "val_top5": 81.51399999023438
            },
            {
                "epoch": 25,
                "learning_rate": 0.04211367764821722,
                "model_norm": 153.9847869873047,
                "train_grad_norm": 1.8755526828388591,
                "train_loss": 2.8219923973083496,
                "val_loss": 1.9371227955627441,
                "val_top1": 57.376000100097656,
                "val_top5": 81.49000006835938
            },
            {
                "epoch": 26,
                "learning_rate": 0.0415327966330913,
                "model_norm": 153.64566040039062,
                "train_grad_norm": 1.8953143945055195,
                "train_loss": 2.7941882610321045,
                "val_loss": 1.8576129927444458,
                "val_top1": 57.534000107421875,
                "val_top5": 81.49000009277344
            },
            {
                "epoch": 27,
                "learning_rate": 0.040935599743717244,
                "model_norm": 153.3796844482422,
                "train_grad_norm": 1.9095368161110313,
                "train_loss": 2.7657625675201416,
                "val_loss": 1.7285465240478515,
                "val_top1": 60.19200008300781,
                "val_top5": 83.41200016601563
            },
            {
                "epoch": 28,
                "learning_rate": 0.040322676341324415,
                "model_norm": 153.1851806640625,
                "train_grad_norm": 1.9290864180645173,
                "train_loss": 2.739490032196045,
                "val_loss": 1.7879994418716432,
                "val_top1": 60.35999994873047,
                "val_top5": 83.58800001464844
            },
            {
                "epoch": 29,
                "learning_rate": 0.03969463130731183,
                "model_norm": 153.04202270507812,
                "train_grad_norm": 1.9464295269573975,
                "train_loss": 2.711909294128418,
                "val_loss": 1.7098903692245484,
                "val_top1": 60.94400007324219,
                "val_top5": 84.22200003417969
            },
            {
                "epoch": 30,
                "learning_rate": 0.03905208444630327,
                "model_norm": 152.9463348388672,
                "train_grad_norm": 1.9683313769568607,
                "train_loss": 2.692472457885742,
                "val_loss": 1.7726505796813965,
                "val_top1": 60.226000026855466,
                "val_top5": 83.5440000366211
            },
            {
                "epoch": 31,
                "learning_rate": 0.038395669874474916,
                "model_norm": 152.88662719726562,
                "train_grad_norm": 1.9831289577843192,
                "train_loss": 2.6661105155944824,
                "val_loss": 1.7277835989761352,
                "val_top1": 61.08000010253906,
                "val_top5": 83.86000009277343
            },
            {
                "epoch": 32,
                "learning_rate": 0.03772603539375929,
                "model_norm": 152.8472137451172,
                "train_grad_norm": 1.9988925223100371,
                "train_loss": 2.6433370113372803,
                "val_loss": 1.6918518102264404,
                "val_top1": 60.90600009277344,
                "val_top5": 84.1219999560547
            },
            {
                "epoch": 33,
                "learning_rate": 0.037043841852542884,
                "model_norm": 152.84141540527344,
                "train_grad_norm": 2.0159397124773277,
                "train_loss": 2.6213479042053223,
                "val_loss": 1.7646333588027954,
                "val_top1": 59.82600002929688,
                "val_top5": 83.15999993408204
            },
            {
                "epoch": 34,
                "learning_rate": 0.03634976249348867,
                "model_norm": 152.84144592285156,
                "train_grad_norm": 2.0301824170251215,
                "train_loss": 2.603050470352173,
                "val_loss": 1.7276409093475342,
                "val_top1": 60.96599994628906,
                "val_top5": 83.95000013671876
            },
            {
                "epoch": 35,
                "learning_rate": 0.03564448228912682,
                "model_norm": 152.8561553955078,
                "train_grad_norm": 2.044289816892636,
                "train_loss": 2.582864284515381,
                "val_loss": 1.8325899099349976,
                "val_top1": 59.13399994140625,
                "val_top5": 82.41000002685547
            },
            {
                "epoch": 36,
                "learning_rate": 0.03492869726586952,
                "model_norm": 152.88124084472656,
                "train_grad_norm": 2.0600348279770397,
                "train_loss": 2.5663681030273438,
                "val_loss": 1.615239915008545,
                "val_top1": 63.442000017089846,
                "val_top5": 85.5780001123047
            },
            {
                "epoch": 37,
                "learning_rate": 0.03420311381711695,
                "model_norm": 152.92039489746094,
                "train_grad_norm": 2.0784137809033467,
                "train_loss": 2.5478904247283936,
                "val_loss": 1.6632684615898132,
                "val_top1": 62.76200000976562,
                "val_top5": 85.21800008056641
            },
            {
                "epoch": 38,
                "learning_rate": 0.033468448006132294,
                "model_norm": 152.9606475830078,
                "train_grad_norm": 2.09059305215171,
                "train_loss": 2.530409812927246,
                "val_loss": 1.5935132136535644,
                "val_top1": 63.995999992675785,
                "val_top5": 85.7899999584961
            },
            {
                "epoch": 39,
                "learning_rate": 0.032725424859373686,
                "model_norm": 153.00149536132812,
                "train_grad_norm": 2.1061306950306156,
                "train_loss": 2.515077829360962,
                "val_loss": 1.6164517798995972,
                "val_top1": 63.936000017089846,
                "val_top5": 85.84800000976563
            },
            {
                "epoch": 40,
                "learning_rate": 0.03197477765098074,
                "model_norm": 153.04684448242188,
                "train_grad_norm": 2.122698127621957,
                "train_loss": 2.4973080158233643,
                "val_loss": 1.546935587463379,
                "val_top1": 65.46000001220703,
                "val_top5": 86.81600000244141
            },
            {
                "epoch": 41,
                "learning_rate": 0.031217247179121378,
                "model_norm": 153.08551025390625,
                "train_grad_norm": 2.136210890251396,
                "train_loss": 2.4820597171783447,
                "val_loss": 1.5097658134269714,
                "val_top1": 64.6780000390625,
                "val_top5": 86.35999995117187
            },
            {
                "epoch": 42,
                "learning_rate": 0.030453581034913565,
                "model_norm": 153.12774658203125,
                "train_grad_norm": 2.154044800951325,
                "train_loss": 2.46535587310791,
                "val_loss": 1.5273187299346924,
                "val_top1": 65.2740001171875,
                "val_top5": 86.73599993164062
            },
            {
                "epoch": 43,
                "learning_rate": 0.02968453286464312,
                "model_norm": 153.16941833496094,
                "train_grad_norm": 2.1732898298774033,
                "train_loss": 2.450498580932617,
                "val_loss": 1.516260458869934,
                "val_top1": 65.54400014160156,
                "val_top5": 87.09599997314453
            },
            {
                "epoch": 44,
                "learning_rate": 0.028910861626005774,
                "model_norm": 153.20660400390625,
                "train_grad_norm": 2.1905949099518405,
                "train_loss": 2.436309337615967,
                "val_loss": 1.5492191107559203,
                "val_top1": 64.78800006103516,
                "val_top5": 86.39799998046875
            },
            {
                "epoch": 45,
                "learning_rate": 0.028133330839107608,
                "model_norm": 153.24072265625,
                "train_grad_norm": 2.2071992811997045,
                "train_loss": 2.422088146209717,
                "val_loss": 1.5362823987960816,
                "val_top1": 65.86600003417969,
                "val_top5": 87.28799995361328
            },
            {
                "epoch": 46,
                "learning_rate": 0.02735270783296286,
                "model_norm": 153.2677001953125,
                "train_grad_norm": 2.2242316072667143,
                "train_loss": 2.4073891639709473,
                "val_loss": 1.5239372786903382,
                "val_top1": 65.53800005615234,
                "val_top5": 87.02800005126953
            },
            {
                "epoch": 47,
                "learning_rate": 0.02656976298823284,
                "model_norm": 153.28790283203125,
                "train_grad_norm": 2.241551587023532,
                "train_loss": 2.3951609134674072,
                "val_loss": 1.487183679332733,
                "val_top1": 65.57200004394531,
                "val_top5": 86.86000000976563
            },
            {
                "epoch": 48,
                "learning_rate": 0.025785268976953202,
                "model_norm": 153.3004913330078,
                "train_grad_norm": 2.261042753871046,
                "train_loss": 2.3827431201934814,
                "val_loss": 1.4392456704711913,
                "val_top1": 66.8059998779297,
                "val_top5": 87.85200005371094
            },
            {
                "epoch": 49,
                "learning_rate": 0.025,
                "model_norm": 153.31163024902344,
                "train_grad_norm": 2.2808803324055393,
                "train_loss": 2.368452310562134,
                "val_loss": 1.446719179725647,
                "val_top1": 66.20800000732422,
                "val_top5": 87.41000002441406
            },
            {
                "epoch": 50,
                "learning_rate": 0.0242147310230468,
                "model_norm": 153.3129119873047,
                "train_grad_norm": 2.298474977232008,
                "train_loss": 2.3556554317474365,
                "val_loss": 1.4765093649291992,
                "val_top1": 66.6080000415039,
                "val_top5": 87.64599998291015
            },
            {
                "epoch": 51,
                "learning_rate": 0.023430237011767167,
                "model_norm": 153.3133544921875,
                "train_grad_norm": 2.3214057421942806,
                "train_loss": 2.341376304626465,
                "val_loss": 1.3882978644752502,
                "val_top1": 67.99800003417968,
                "val_top5": 88.43199994628907
            },
            {
                "epoch": 52,
                "learning_rate": 0.022647292167037147,
                "model_norm": 153.30853271484375,
                "train_grad_norm": 2.3444776294320393,
                "train_loss": 2.3287744522094727,
                "val_loss": 1.419320802707672,
                "val_top1": 67.47400009277344,
                "val_top5": 88.24599992919921
            },
            {
                "epoch": 53,
                "learning_rate": 0.0218666691608924,
                "model_norm": 153.2968292236328,
                "train_grad_norm": 2.3637030168273796,
                "train_loss": 2.31583571434021,
                "val_loss": 1.449365405921936,
                "val_top1": 66.5320000024414,
                "val_top5": 87.54000005371094
            },
            {
                "epoch": 54,
                "learning_rate": 0.021089138373994232,
                "model_norm": 153.28086853027344,
                "train_grad_norm": 2.386320708316805,
                "train_loss": 2.3025705814361572,
                "val_loss": 1.369599519958496,
                "val_top1": 68.15800008789063,
                "val_top5": 88.81599997558594
            },
            {
                "epoch": 55,
                "learning_rate": 0.020315467135356886,
                "model_norm": 153.2544708251953,
                "train_grad_norm": 2.406109815558459,
                "train_loss": 2.2891361713409424,
                "val_loss": 1.387344868850708,
                "val_top1": 68.04800002197265,
                "val_top5": 88.600000078125
            },
            {
                "epoch": 56,
                "learning_rate": 0.019546418965086437,
                "model_norm": 153.22598266601562,
                "train_grad_norm": 2.4310187748726886,
                "train_loss": 2.2781410217285156,
                "val_loss": 1.457796976852417,
                "val_top1": 66.6320000415039,
                "val_top5": 87.59400016113281
            },
            {
                "epoch": 57,
                "learning_rate": 0.018782752820878636,
                "model_norm": 153.19241333007812,
                "train_grad_norm": 2.456702647266373,
                "train_loss": 2.2654805183410645,
                "val_loss": 1.3671268950653077,
                "val_top1": 68.66000010498047,
                "val_top5": 88.80000012695312
            },
            {
                "epoch": 58,
                "learning_rate": 0.018025222349019272,
                "model_norm": 153.15208435058594,
                "train_grad_norm": 2.479414501725445,
                "train_loss": 2.252239465713501,
                "val_loss": 1.384885312309265,
                "val_top1": 68.02599995605469,
                "val_top5": 88.57200010742187
            },
            {
                "epoch": 59,
                "learning_rate": 0.017274575140626316,
                "model_norm": 153.1044921875,
                "train_grad_norm": 2.5019610908027854,
                "train_loss": 2.2392473220825195,
                "val_loss": 1.356501791305542,
                "val_top1": 69.31399995117188,
                "val_top5": 89.29000002197266
            },
            {
                "epoch": 60,
                "learning_rate": 0.016531551993867716,
                "model_norm": 153.05099487304688,
                "train_grad_norm": 2.5271205912940617,
                "train_loss": 2.227393627166748,
                "val_loss": 1.3347890230560302,
                "val_top1": 69.70199997314454,
                "val_top5": 89.4500000732422
            },
            {
                "epoch": 61,
                "learning_rate": 0.01579688618288306,
                "model_norm": 152.9960479736328,
                "train_grad_norm": 2.557451012125056,
                "train_loss": 2.2153851985931396,
                "val_loss": 1.3173968448829652,
                "val_top1": 69.64800005615234,
                "val_top5": 89.36799986816406
            },
            {
                "epoch": 62,
                "learning_rate": 0.015071302734130482,
                "model_norm": 152.93858337402344,
                "train_grad_norm": 2.587043279796318,
                "train_loss": 2.200507402420044,
                "val_loss": 1.3129171646499633,
                "val_top1": 69.39200012939453,
                "val_top5": 89.45399994384766
            },
            {
                "epoch": 63,
                "learning_rate": 0.014355517710873185,
                "model_norm": 152.87167358398438,
                "train_grad_norm": 2.6082608783294865,
                "train_loss": 2.1900579929351807,
                "val_loss": 1.298686080608368,
                "val_top1": 69.44400008300781,
                "val_top5": 89.56799997070313
            },
            {
                "epoch": 64,
                "learning_rate": 0.013650237506511332,
                "model_norm": 152.79876708984375,
                "train_grad_norm": 2.634972631333839,
                "train_loss": 2.175963878631592,
                "val_loss": 1.275790282459259,
                "val_top1": 70.27599995361328,
                "val_top5": 89.87200004882813
            },
            {
                "epoch": 65,
                "learning_rate": 0.012956158147457115,
                "model_norm": 152.72451782226562,
                "train_grad_norm": 2.6650907786528935,
                "train_loss": 2.164346933364868,
                "val_loss": 1.2910849181175232,
                "val_top1": 70.26600000732422,
                "val_top5": 89.94200004394531
            },
            {
                "epoch": 66,
                "learning_rate": 0.012273964606240717,
                "model_norm": 152.6470947265625,
                "train_grad_norm": 2.693200543659513,
                "train_loss": 2.1502766609191895,
                "val_loss": 1.3105157500839233,
                "val_top1": 70.15799994628907,
                "val_top5": 89.66799997070312
            },
            {
                "epoch": 67,
                "learning_rate": 0.01160433012552509,
                "model_norm": 152.56590270996094,
                "train_grad_norm": 2.722689392080516,
                "train_loss": 2.137397289276123,
                "val_loss": 1.2091868870735167,
                "val_top1": 71.32600004882812,
                "val_top5": 90.45600001953125
            },
            {
                "epoch": 68,
                "learning_rate": 0.010947915553696742,
                "model_norm": 152.48330688476562,
                "train_grad_norm": 2.755028179629089,
                "train_loss": 2.1232056617736816,
                "val_loss": 1.2549465487480163,
                "val_top1": 71.16599999511719,
                "val_top5": 90.20400007324218
            },
            {
                "epoch": 69,
                "learning_rate": 0.010305368692688175,
                "model_norm": 152.3977813720703,
                "train_grad_norm": 2.7866948418422433,
                "train_loss": 2.111647367477417,
                "val_loss": 1.2548619952011109,
                "val_top1": 71.22200005126953,
                "val_top5": 90.29599996582031
            },
            {
                "epoch": 70,
                "learning_rate": 0.009677323658675586,
                "model_norm": 152.3092803955078,
                "train_grad_norm": 2.81854184322088,
                "train_loss": 2.099632501602173,
                "val_loss": 1.2066743872642518,
                "val_top1": 71.652,
                "val_top5": 90.55800001953125
            },
            {
                "epoch": 71,
                "learning_rate": 0.009064400256282757,
                "model_norm": 152.22119140625,
                "train_grad_norm": 2.848917612417346,
                "train_loss": 2.0862905979156494,
                "val_loss": 1.283783456249237,
                "val_top1": 71.6459999951172,
                "val_top5": 90.64200002197266
            },
            {
                "epoch": 72,
                "learning_rate": 0.008467203366908708,
                "model_norm": 152.13006591796875,
                "train_grad_norm": 2.875135038751839,
                "train_loss": 2.0730321407318115,
                "val_loss": 1.2347657051467895,
                "val_top1": 71.707999921875,
                "val_top5": 90.47800004638673
            },
            {
                "epoch": 73,
                "learning_rate": 0.00788632235178279,
                "model_norm": 152.039794921875,
                "train_grad_norm": 2.91075904124426,
                "train_loss": 2.061131715774536,
                "val_loss": 1.2308753761100768,
                "val_top1": 71.87199999755859,
                "val_top5": 90.5699999194336
            },
            {
                "epoch": 74,
                "learning_rate": 0.007322330470336306,
                "model_norm": 151.9490509033203,
                "train_grad_norm": 2.943862418224838,
                "train_loss": 2.0475263595581055,
                "val_loss": 1.227975756225586,
                "val_top1": 72.24800002441407,
                "val_top5": 90.72799991699219
            },
            {
                "epoch": 75,
                "learning_rate": 0.006775784314464709,
                "model_norm": 151.85986328125,
                "train_grad_norm": 2.976262589841947,
                "train_loss": 2.0365920066833496,
                "val_loss": 1.228227366142273,
                "val_top1": 72.18,
                "val_top5": 90.82799994140625
            },
            {
                "epoch": 76,
                "learning_rate": 0.0062472232592385105,
                "model_norm": 151.7713165283203,
                "train_grad_norm": 3.0086757731850344,
                "train_loss": 2.021458148956299,
                "val_loss": 1.1863915616226197,
                "val_top1": 72.50599991210937,
                "val_top5": 91.06799996826172
            },
            {
                "epoch": 77,
                "learning_rate": 0.005737168930605272,
                "model_norm": 151.6839599609375,
                "train_grad_norm": 3.0417670875039153,
                "train_loss": 2.009321689605713,
                "val_loss": 1.1573161428260803,
                "val_top1": 72.7659999975586,
                "val_top5": 91.25399986328125
            },
            {
                "epoch": 78,
                "learning_rate": 0.005246124690607746,
                "model_norm": 151.59866333007812,
                "train_grad_norm": 3.071770818385459,
                "train_loss": 1.998687982559204,
                "val_loss": 1.1630686868667603,
                "val_top1": 73.00999994628906,
                "val_top5": 91.27199994140625
            },
            {
                "epoch": 79,
                "learning_rate": 0.004774575140626317,
                "model_norm": 151.5153350830078,
                "train_grad_norm": 3.0998766752230886,
                "train_loss": 1.9862234592437744,
                "val_loss": 1.148596162662506,
                "val_top1": 73.05599997314454,
                "val_top5": 91.32600004394531
            },
            {
                "epoch": 80,
                "learning_rate": 0.004322985643135951,
                "model_norm": 151.43658447265625,
                "train_grad_norm": 3.133288670695395,
                "train_loss": 1.9746794700622559,
                "val_loss": 1.1702457222747802,
                "val_top1": 73.05399991455079,
                "val_top5": 91.23599999023438
            },
            {
                "epoch": 81,
                "learning_rate": 0.0038918018624496233,
                "model_norm": 151.36138916015625,
                "train_grad_norm": 3.163731921640558,
                "train_loss": 1.9599665403366089,
                "val_loss": 1.1435531120872497,
                "val_top1": 73.65600001464844,
                "val_top5": 91.5159999633789
            },
            {
                "epoch": 82,
                "learning_rate": 0.003481449324901412,
                "model_norm": 151.28953552246094,
                "train_grad_norm": 3.1922184854481017,
                "train_loss": 1.9505828619003296,
                "val_loss": 1.1508015476989746,
                "val_top1": 73.66600009765625,
                "val_top5": 91.63800009521485
            },
            {
                "epoch": 83,
                "learning_rate": 0.0030923329989034163,
                "model_norm": 151.22186279296875,
                "train_grad_norm": 3.2209699593452488,
                "train_loss": 1.9415624141693115,
                "val_loss": 1.1523837814712525,
                "val_top1": 73.64999999511718,
                "val_top5": 91.45600001708985
            },
            {
                "epoch": 84,
                "learning_rate": 0.0027248368952908055,
                "model_norm": 151.1595001220703,
                "train_grad_norm": 3.248086744909276,
                "train_loss": 1.929469108581543,
                "val_loss": 1.1370704524803161,
                "val_top1": 74.08599994140624,
                "val_top5": 91.69400004394531
            },
            {
                "epoch": 85,
                "learning_rate": 0.0023793236883495107,
                "model_norm": 151.10165405273438,
                "train_grad_norm": 3.2721939008525998,
                "train_loss": 1.9204769134521484,
                "val_loss": 1.1351093342781067,
                "val_top1": 74.01600004638672,
                "val_top5": 91.80600014648438
            },
            {
                "epoch": 86,
                "learning_rate": 0.0020561343579004717,
                "model_norm": 151.04937744140625,
                "train_grad_norm": 3.291302296163188,
                "train_loss": 1.9083751440048218,
                "val_loss": 1.13302422706604,
                "val_top1": 74.13599996582032,
                "val_top5": 91.77000007080078
            },
            {
                "epoch": 87,
                "learning_rate": 0.0017555878527937164,
                "model_norm": 151.0030517578125,
                "train_grad_norm": 3.3111230102027753,
                "train_loss": 1.8999207019805908,
                "val_loss": 1.132313998260498,
                "val_top1": 74.24599998779297,
                "val_top5": 91.80399993896485
            },
            {
                "epoch": 88,
                "learning_rate": 0.0014779807761443637,
                "model_norm": 150.96192932128906,
                "train_grad_norm": 3.330997982804968,
                "train_loss": 1.8908259868621826,
                "val_loss": 1.116415378780365,
                "val_top1": 74.33200001953125,
                "val_top5": 91.80000014648438
            },
            {
                "epoch": 89,
                "learning_rate": 0.0012235870926211618,
                "model_norm": 150.9265594482422,
                "train_grad_norm": 3.347843694565391,
                "train_loss": 1.8825035095214844,
                "val_loss": 1.1187427619171142,
                "val_top1": 74.55400001953124,
                "val_top5": 91.91799993896484
            },
            {
                "epoch": 90,
                "learning_rate": 0.0009926578580764262,
                "model_norm": 150.89646911621094,
                "train_grad_norm": 3.3603576196445606,
                "train_loss": 1.8763335943222046,
                "val_loss": 1.1272156756591798,
                "val_top1": 74.58599996337891,
                "val_top5": 91.93000001708984
            },
            {
                "epoch": 91,
                "learning_rate": 0.0007854209717842232,
                "model_norm": 150.87159729003906,
                "train_grad_norm": 3.3703564251039118,
                "train_loss": 1.869710922241211,
                "val_loss": 1.1102490996170045,
                "val_top1": 74.54400014648438,
                "val_top5": 92.00399996582031
            },
            {
                "epoch": 92,
                "learning_rate": 0.0006020809515313169,
                "model_norm": 150.8517303466797,
                "train_grad_norm": 3.3782881244062386,
                "train_loss": 1.8647195100784302,
                "val_loss": 1.1182547006988526,
                "val_top1": 74.57199999023437,
                "val_top5": 92.02600014648438
            },
            {
                "epoch": 93,
                "learning_rate": 0.000442818731782782,
                "model_norm": 150.8365020751953,
                "train_grad_norm": 3.39058550632757,
                "train_loss": 1.8613858222961426,
                "val_loss": 1.1170789715766907,
                "val_top1": 74.63800001464844,
                "val_top5": 92.00199991455078
            },
            {
                "epoch": 94,
                "learning_rate": 0.00030779148512155856,
                "model_norm": 150.82528686523438,
                "train_grad_norm": 3.3894152684399375,
                "train_loss": 1.8555470705032349,
                "val_loss": 1.109383995704651,
                "val_top1": 74.7540000415039,
                "val_top5": 92.07200009521485
            },
            {
                "epoch": 95,
                "learning_rate": 0.0001971324671380559,
                "model_norm": 150.81764221191406,
                "train_grad_norm": 3.395086267843628,
                "train_loss": 1.852534294128418,
                "val_loss": 1.112745607032776,
                "val_top1": 74.6520000439453,
                "val_top5": 92.03400009521485
            },
            {
                "epoch": 96,
                "learning_rate": 0.0001109508849230001,
                "model_norm": 150.81295776367188,
                "train_grad_norm": 3.3888698162988034,
                "train_loss": 1.8484946489334106,
                "val_loss": 1.1097478731155395,
                "val_top1": 74.68199996582031,
                "val_top5": 92.08200004394531
            },
            {
                "epoch": 97,
                "learning_rate": 4.933178929321103e-05,
                "model_norm": 150.81053161621094,
                "train_grad_norm": 3.390539686437771,
                "train_loss": 1.846944808959961,
                "val_loss": 1.1068251117706298,
                "val_top1": 74.8160001220703,
                "val_top5": 92.09200004394532
            },
            {
                "epoch": 98,
                "learning_rate": 1.233599085671e-05,
                "model_norm": 150.80958557128906,
                "train_grad_norm": 3.389879930670835,
                "train_loss": 1.847142219543457,
                "val_loss": 1.1180543481445313,
                "val_top1": 74.7500000439453,
                "val_top5": 92.03400004394531
            },
            {
                "epoch": 99,
                "learning_rate": 0.0,
                "model_norm": 150.80941772460938,
                "train_grad_norm": 3.390400044145268,
                "train_loss": 1.8454235792160034,
                "val_loss": 1.1057331863403321,
                "val_top1": 74.78800006835938,
                "val_top5": 92.05600004394532
            }
        ],
        "summary": {
            "len_train_loader": 1251,
            "start_time": "2025-03-27 06:51:30.837147"
        }
    },
    {
        "config": {
            "batch_size": 256,
            "dataset": "imagenet1k",
            "gradient_accumulation": 1,
            "max_epoch": 100,
            "model": "resnet50",
            "opt": {
                "lr": 0.1,
                "lr_schedule": "wsd",
                "momentum": 0.9,
                "name": "momentum",
                "weight_decay": 0.0001
            },
            "run_id": 0
        },
        "history": [
            {
                "epoch": 0,
                "learning_rate": 0.020008,
                "model_norm": 236.2531280517578,
                "train_loss": 6.6448163986206055,
                "val_loss": 6.187772315673828,
                "val_top1": 2.813999993286133,
                "val_top5": 8.418000002441406
            },
            {
                "epoch": 1,
                "learning_rate": 0.04000600000000001,
                "model_norm": 229.86277770996094,
                "train_loss": 6.15468692779541,
                "val_loss": 5.639342310943603,
                "val_top1": 5.642000017700195,
                "val_top5": 15.152000020751952
            },
            {
                "epoch": 2,
                "learning_rate": 0.06000400000000001,
                "model_norm": 220.06539916992188,
                "train_loss": 5.730123519897461,
                "val_loss": 5.024197291870117,
                "val_top1": 9.492000017700196,
                "val_top5": 24.03000005981445
            },
            {
                "epoch": 3,
                "learning_rate": 0.080002,
                "model_norm": 208.2587432861328,
                "train_loss": 5.23941707611084,
                "val_loss": 4.68234298461914,
                "val_top1": 13.246000015869141,
                "val_top5": 31.06400003417969
            },
            {
                "epoch": 4,
                "learning_rate": 0.1,
                "model_norm": 196.00283813476562,
                "train_loss": 4.734055042266846,
                "val_loss": 3.9224654861450197,
                "val_top1": 22.109999997558592,
                "val_top5": 45.31000005859375
            },
            {
                "epoch": 5,
                "learning_rate": 0.1,
                "model_norm": 185.4060821533203,
                "train_loss": 4.303371429443359,
                "val_loss": 3.5885289027404785,
                "val_top1": 26.41400000732422,
                "val_top5": 51.03800002685547
            },
            {
                "epoch": 6,
                "learning_rate": 0.1,
                "model_norm": 177.28973388671875,
                "train_loss": 3.9677228927612305,
                "val_loss": 3.1369212327194216,
                "val_top1": 34.04799999023437,
                "val_top5": 60.154000083007816
            },
            {
                "epoch": 7,
                "learning_rate": 0.1,
                "model_norm": 171.1216278076172,
                "train_loss": 3.7311794757843018,
                "val_loss": 2.8107258307266236,
                "val_top1": 39.26399998535156,
                "val_top5": 65.73400013183594
            },
            {
                "epoch": 8,
                "learning_rate": 0.1,
                "model_norm": 166.4946746826172,
                "train_loss": 3.5556092262268066,
                "val_loss": 2.603698405609131,
                "val_top1": 43.12399996826172,
                "val_top5": 69.81599996826172
            },
            {
                "epoch": 9,
                "learning_rate": 0.1,
                "model_norm": 163.08984375,
                "train_loss": 3.417830467224121,
                "val_loss": 2.540425848312378,
                "val_top1": 44.52000006835937,
                "val_top5": 71.18800006835937
            },
            {
                "epoch": 10,
                "learning_rate": 0.1,
                "model_norm": 160.70721435546875,
                "train_loss": 3.3086092472076416,
                "val_loss": 2.323011621055603,
                "val_top1": 47.86999999267578,
                "val_top5": 73.70399995605469
            },
            {
                "epoch": 11,
                "learning_rate": 0.1,
                "model_norm": 159.1351776123047,
                "train_loss": 3.2177236080169678,
                "val_loss": 2.4137271408081054,
                "val_top1": 47.15400007568359,
                "val_top5": 73.220000078125
            },
            {
                "epoch": 12,
                "learning_rate": 0.1,
                "model_norm": 158.1918182373047,
                "train_loss": 3.144787311553955,
                "val_loss": 2.3022963481521606,
                "val_top1": 50.459999982910155,
                "val_top5": 75.87799998535156
            },
            {
                "epoch": 13,
                "learning_rate": 0.1,
                "model_norm": 157.78060913085938,
                "train_loss": 3.0755913257598877,
                "val_loss": 2.3208160746002195,
                "val_top1": 50.17399998291015,
                "val_top5": 75.46400008789062
            },
            {
                "epoch": 14,
                "learning_rate": 0.1,
                "model_norm": 157.7675018310547,
                "train_loss": 3.014570951461792,
                "val_loss": 2.0543198891448973,
                "val_top1": 53.699999970703125,
                "val_top5": 78.60800000732422
            },
            {
                "epoch": 15,
                "learning_rate": 0.1,
                "model_norm": 158.03353881835938,
                "train_loss": 2.9648585319519043,
                "val_loss": 2.0304830174255373,
                "val_top1": 54.72200001708985,
                "val_top5": 79.742000078125
            },
            {
                "epoch": 16,
                "learning_rate": 0.1,
                "model_norm": 158.4871826171875,
                "train_loss": 2.9196999073028564,
                "val_loss": 2.1421127602386476,
                "val_top1": 53.29600000488281,
                "val_top5": 78.20600003662109
            },
            {
                "epoch": 17,
                "learning_rate": 0.1,
                "model_norm": 159.0889129638672,
                "train_loss": 2.880521059036255,
                "val_loss": 2.086871716461182,
                "val_top1": 53.33800005126953,
                "val_top5": 78.18800010498047
            },
            {
                "epoch": 18,
                "learning_rate": 0.1,
                "model_norm": 159.76345825195312,
                "train_loss": 2.8474912643432617,
                "val_loss": 1.95213399269104,
                "val_top1": 57.29200004882812,
                "val_top5": 81.24600006103516
            },
            {
                "epoch": 19,
                "learning_rate": 0.1,
                "model_norm": 160.4902801513672,
                "train_loss": 2.8159334659576416,
                "val_loss": 1.8997103802871704,
                "val_top1": 57.57199991455078,
                "val_top5": 81.84800002441406
            },
            {
                "epoch": 20,
                "learning_rate": 0.1,
                "model_norm": 161.25511169433594,
                "train_loss": 2.7904350757598877,
                "val_loss": 1.9596977264404296,
                "val_top1": 57.456000051269534,
                "val_top5": 81.5139999609375
            },
            {
                "epoch": 21,
                "learning_rate": 0.1,
                "model_norm": 162.03729248046875,
                "train_loss": 2.7655410766601562,
                "val_loss": 1.90145142288208,
                "val_top1": 57.980000068359374,
                "val_top5": 81.55000006591797
            },
            {
                "epoch": 22,
                "learning_rate": 0.1,
                "model_norm": 162.83502197265625,
                "train_loss": 2.7443957328796387,
                "val_loss": 1.923069764328003,
                "val_top1": 58.582000036621096,
                "val_top5": 82.54999999267578
            },
            {
                "epoch": 23,
                "learning_rate": 0.1,
                "model_norm": 163.6575164794922,
                "train_loss": 2.724977493286133,
                "val_loss": 1.877720446395874,
                "val_top1": 58.88000000732422,
                "val_top5": 82.3800000415039
            },
            {
                "epoch": 24,
                "learning_rate": 0.1,
                "model_norm": 164.44772338867188,
                "train_loss": 2.7040841579437256,
                "val_loss": 1.9242216079330445,
                "val_top1": 58.34800005371094,
                "val_top5": 81.89999993408203
            },
            {
                "epoch": 25,
                "learning_rate": 0.1,
                "model_norm": 165.24105834960938,
                "train_loss": 2.6887097358703613,
                "val_loss": 1.9941704154205322,
                "val_top1": 55.039999946289065,
                "val_top5": 79.74799998046875
            },
            {
                "epoch": 26,
                "learning_rate": 0.1,
                "model_norm": 166.03143310546875,
                "train_loss": 2.672274112701416,
                "val_loss": 1.9165070989227295,
                "val_top1": 57.26399998535156,
                "val_top5": 81.38800007080079
            },
            {
                "epoch": 27,
                "learning_rate": 0.1,
                "model_norm": 166.82418823242188,
                "train_loss": 2.6583499908447266,
                "val_loss": 1.7883174380493163,
                "val_top1": 59.27799991699219,
                "val_top5": 82.77400007324219
            },
            {
                "epoch": 28,
                "learning_rate": 0.1,
                "model_norm": 167.60635375976562,
                "train_loss": 2.6452298164367676,
                "val_loss": 1.7666026748657226,
                "val_top1": 60.65000003173828,
                "val_top5": 83.8039999633789
            },
            {
                "epoch": 29,
                "learning_rate": 0.1,
                "model_norm": 168.38092041015625,
                "train_loss": 2.6307523250579834,
                "val_loss": 1.6886762475967407,
                "val_top1": 61.488000017089846,
                "val_top5": 84.42599987792968
            },
            {
                "epoch": 30,
                "learning_rate": 0.1,
                "model_norm": 169.14964294433594,
                "train_loss": 2.6245229244232178,
                "val_loss": 1.7390985217285155,
                "val_top1": 60.68400002441406,
                "val_top5": 84.1140000390625
            },
            {
                "epoch": 31,
                "learning_rate": 0.1,
                "model_norm": 169.8970947265625,
                "train_loss": 2.609096050262451,
                "val_loss": 1.722447206878662,
                "val_top1": 61.03599989746094,
                "val_top5": 83.83599998779297
            },
            {
                "epoch": 32,
                "learning_rate": 0.1,
                "model_norm": 170.63662719726562,
                "train_loss": 2.5969510078430176,
                "val_loss": 1.7524233983993531,
                "val_top1": 60.12200004394531,
                "val_top5": 83.47400008300781
            },
            {
                "epoch": 33,
                "learning_rate": 0.1,
                "model_norm": 171.39306640625,
                "train_loss": 2.587827444076538,
                "val_loss": 1.6899152297210693,
                "val_top1": 60.79599998046875,
                "val_top5": 83.96200006835937
            },
            {
                "epoch": 34,
                "learning_rate": 0.1,
                "model_norm": 172.11456298828125,
                "train_loss": 2.580082416534424,
                "val_loss": 1.823980548171997,
                "val_top1": 58.99000008789063,
                "val_top5": 82.7100000415039
            },
            {
                "epoch": 35,
                "learning_rate": 0.1,
                "model_norm": 172.83067321777344,
                "train_loss": 2.56965708732605,
                "val_loss": 1.8505758908081054,
                "val_top1": 58.880000063476565,
                "val_top5": 82.20799993652344
            },
            {
                "epoch": 36,
                "learning_rate": 0.1,
                "model_norm": 173.52743530273438,
                "train_loss": 2.564136505126953,
                "val_loss": 1.6694233805084229,
                "val_top1": 62.877999995117186,
                "val_top5": 85.55
            },
            {
                "epoch": 37,
                "learning_rate": 0.1,
                "model_norm": 174.2356414794922,
                "train_loss": 2.5562620162963867,
                "val_loss": 1.6649598426818848,
                "val_top1": 61.55800008300781,
                "val_top5": 84.56000005371094
            },
            {
                "epoch": 38,
                "learning_rate": 0.1,
                "model_norm": 174.93887329101562,
                "train_loss": 2.549734115600586,
                "val_loss": 1.6899743044662476,
                "val_top1": 61.709999965820316,
                "val_top5": 84.26399998046875
            },
            {
                "epoch": 39,
                "learning_rate": 0.1,
                "model_norm": 175.60675048828125,
                "train_loss": 2.5422189235687256,
                "val_loss": 1.6853327045440674,
                "val_top1": 61.58999998291016,
                "val_top5": 84.68000001708984
            },
            {
                "epoch": 40,
                "learning_rate": 0.1,
                "model_norm": 176.29617309570312,
                "train_loss": 2.53244948387146,
                "val_loss": 1.6517067432785033,
                "val_top1": 62.99199997558594,
                "val_top5": 85.60599998046875
            },
            {
                "epoch": 41,
                "learning_rate": 0.1,
                "model_norm": 176.9595184326172,
                "train_loss": 2.5271549224853516,
                "val_loss": 1.552846772518158,
                "val_top1": 63.90600017089844,
                "val_top5": 86.30399997558594
            },
            {
                "epoch": 42,
                "learning_rate": 0.1,
                "model_norm": 177.62387084960938,
                "train_loss": 2.5210072994232178,
                "val_loss": 1.6020030973052979,
                "val_top1": 63.758000012207035,
                "val_top5": 85.90400000732421
            },
            {
                "epoch": 43,
                "learning_rate": 0.1,
                "model_norm": 178.30296325683594,
                "train_loss": 2.5142593383789062,
                "val_loss": 1.6035602840805054,
                "val_top1": 63.48200002929688,
                "val_top5": 85.7719998828125
            },
            {
                "epoch": 44,
                "learning_rate": 0.1,
                "model_norm": 178.9702911376953,
                "train_loss": 2.5088050365448,
                "val_loss": 1.5788011303329468,
                "val_top1": 63.99800009521484,
                "val_top5": 85.86399998535157
            },
            {
                "epoch": 45,
                "learning_rate": 0.1,
                "model_norm": 179.61753845214844,
                "train_loss": 2.504795551300049,
                "val_loss": 1.6746082137298584,
                "val_top1": 63.063999995117186,
                "val_top5": 85.1500000390625
            },
            {
                "epoch": 46,
                "learning_rate": 0.1,
                "model_norm": 180.2306671142578,
                "train_loss": 2.4959864616394043,
                "val_loss": 1.6601197396087646,
                "val_top1": 62.852000041503906,
                "val_top5": 85.31600005371094
            },
            {
                "epoch": 47,
                "learning_rate": 0.1,
                "model_norm": 180.8719024658203,
                "train_loss": 2.494062900543213,
                "val_loss": 1.5518183321380614,
                "val_top1": 63.893999978027345,
                "val_top5": 86.01400006835938
            },
            {
                "epoch": 48,
                "learning_rate": 0.1,
                "model_norm": 181.4910430908203,
                "train_loss": 2.4907493591308594,
                "val_loss": 1.5663859522438048,
                "val_top1": 63.721999963378906,
                "val_top5": 86.11400010742187
            },
            {
                "epoch": 49,
                "learning_rate": 0.1,
                "model_norm": 182.11395263671875,
                "train_loss": 2.486036777496338,
                "val_loss": 1.6489248468399047,
                "val_top1": 62.491999997558594,
                "val_top5": 85.22600006103515
            },
            {
                "epoch": 50,
                "learning_rate": 0.1,
                "model_norm": 182.72406005859375,
                "train_loss": 2.4832088947296143,
                "val_loss": 1.7444120399856566,
                "val_top1": 60.94400004882812,
                "val_top5": 83.88000001220703
            },
            {
                "epoch": 51,
                "learning_rate": 0.1,
                "model_norm": 183.32945251464844,
                "train_loss": 2.475288152694702,
                "val_loss": 1.5933555444717407,
                "val_top1": 64.12600009521485,
                "val_top5": 85.93600002929688
            },
            {
                "epoch": 52,
                "learning_rate": 0.1,
                "model_norm": 183.96629333496094,
                "train_loss": 2.4735047817230225,
                "val_loss": 1.6053292904281615,
                "val_top1": 63.800000122070315,
                "val_top5": 85.5199999609375
            },
            {
                "epoch": 53,
                "learning_rate": 0.1,
                "model_norm": 184.5689239501953,
                "train_loss": 2.4689249992370605,
                "val_loss": 1.6892060810470582,
                "val_top1": 61.654,
                "val_top5": 84.53000006347656
            },
            {
                "epoch": 54,
                "learning_rate": 0.1,
                "model_norm": 185.18116760253906,
                "train_loss": 2.4659461975097656,
                "val_loss": 1.6157914437484742,
                "val_top1": 63.532000048828124,
                "val_top5": 85.72800005859375
            },
            {
                "epoch": 55,
                "learning_rate": 0.1,
                "model_norm": 185.77415466308594,
                "train_loss": 2.4612886905670166,
                "val_loss": 1.6135280919265746,
                "val_top1": 63.094000092773435,
                "val_top5": 85.52800003173829
            },
            {
                "epoch": 56,
                "learning_rate": 0.1,
                "model_norm": 186.36260986328125,
                "train_loss": 2.4598348140716553,
                "val_loss": 1.845571295928955,
                "val_top1": 59.24399993652344,
                "val_top5": 82.68799996826172
            },
            {
                "epoch": 57,
                "learning_rate": 0.1,
                "model_norm": 186.94271850585938,
                "train_loss": 2.455186128616333,
                "val_loss": 1.6420598927307128,
                "val_top1": 63.35199990722656,
                "val_top5": 85.39600000976563
            },
            {
                "epoch": 58,
                "learning_rate": 0.1,
                "model_norm": 187.53643798828125,
                "train_loss": 2.453547954559326,
                "val_loss": 1.6182462368774415,
                "val_top1": 62.91400012695313,
                "val_top5": 85.26600002929688
            },
            {
                "epoch": 59,
                "learning_rate": 0.1,
                "model_norm": 188.09034729003906,
                "train_loss": 2.449191093444824,
                "val_loss": 1.6201530445098877,
                "val_top1": 62.811999938964846,
                "val_top5": 85.21999998535156
            },
            {
                "epoch": 60,
                "learning_rate": 0.1,
                "model_norm": 188.6544647216797,
                "train_loss": 2.4459104537963867,
                "val_loss": 1.525393224658966,
                "val_top1": 65.27000003417969,
                "val_top5": 86.90599997558594
            },
            {
                "epoch": 61,
                "learning_rate": 0.1,
                "model_norm": 189.2244873046875,
                "train_loss": 2.444042682647705,
                "val_loss": 1.5919647284317016,
                "val_top1": 64.24400006591797,
                "val_top5": 86.17800002929687
            },
            {
                "epoch": 62,
                "learning_rate": 0.1,
                "model_norm": 189.78659057617188,
                "train_loss": 2.4398856163024902,
                "val_loss": 1.5668714536476136,
                "val_top1": 64.18199992675781,
                "val_top5": 86.18400005126954
            },
            {
                "epoch": 63,
                "learning_rate": 0.1,
                "model_norm": 190.33963012695312,
                "train_loss": 2.437619209289551,
                "val_loss": 1.5999620693206786,
                "val_top1": 63.65600014404297,
                "val_top5": 85.89200008544923
            },
            {
                "epoch": 64,
                "learning_rate": 0.1,
                "model_norm": 190.89051818847656,
                "train_loss": 2.436058759689331,
                "val_loss": 1.5681758528518677,
                "val_top1": 64.44400003173828,
                "val_top5": 86.2440000048828
            },
            {
                "epoch": 65,
                "learning_rate": 0.1,
                "model_norm": 191.4279327392578,
                "train_loss": 2.432429552078247,
                "val_loss": 1.499045653858185,
                "val_top1": 65.54799998291016,
                "val_top5": 87.042000078125
            },
            {
                "epoch": 66,
                "learning_rate": 0.1,
                "model_norm": 191.97708129882812,
                "train_loss": 2.430379867553711,
                "val_loss": 1.5767186936950683,
                "val_top1": 63.83799999023437,
                "val_top5": 85.79599990722656
            },
            {
                "epoch": 67,
                "learning_rate": 0.1,
                "model_norm": 192.537109375,
                "train_loss": 2.4280643463134766,
                "val_loss": 1.5148069911575317,
                "val_top1": 64.61600007080078,
                "val_top5": 86.4440000341797
            },
            {
                "epoch": 68,
                "learning_rate": 0.1,
                "model_norm": 193.06556701660156,
                "train_loss": 2.42409610748291,
                "val_loss": 1.5065558950805664,
                "val_top1": 65.75599998779298,
                "val_top5": 87.16999990234375
            },
            {
                "epoch": 69,
                "learning_rate": 0.1,
                "model_norm": 193.58819580078125,
                "train_loss": 2.423398494720459,
                "val_loss": 1.5775911382675172,
                "val_top1": 64.94800001708984,
                "val_top5": 86.57399998291015
            },
            {
                "epoch": 70,
                "learning_rate": 0.1,
                "model_norm": 194.12779235839844,
                "train_loss": 2.420477867126465,
                "val_loss": 1.5277163606643678,
                "val_top1": 64.7100000366211,
                "val_top5": 86.79200013183593
            },
            {
                "epoch": 71,
                "learning_rate": 0.1,
                "model_norm": 194.68087768554688,
                "train_loss": 2.418841600418091,
                "val_loss": 1.566615869178772,
                "val_top1": 64.32199996826172,
                "val_top5": 86.58600006103515
            },
            {
                "epoch": 72,
                "learning_rate": 0.1,
                "model_norm": 195.19561767578125,
                "train_loss": 2.4153294563293457,
                "val_loss": 1.5019525004577636,
                "val_top1": 64.98199991210937,
                "val_top5": 86.96199993164062
            },
            {
                "epoch": 73,
                "learning_rate": 0.1,
                "model_norm": 195.7260284423828,
                "train_loss": 2.4152870178222656,
                "val_loss": 1.5170014903831481,
                "val_top1": 65.67400008789062,
                "val_top5": 86.97399985351562
            },
            {
                "epoch": 74,
                "learning_rate": 0.1,
                "model_norm": 196.22357177734375,
                "train_loss": 2.4113292694091797,
                "val_loss": 1.7335494764328003,
                "val_top1": 61.75800002441406,
                "val_top5": 84.34600004150391
            },
            {
                "epoch": 75,
                "learning_rate": 0.1,
                "model_norm": 196.7455596923828,
                "train_loss": 2.411254644393921,
                "val_loss": 1.5179397564697266,
                "val_top1": 65.70599998779296,
                "val_top5": 86.94000005859375
            },
            {
                "epoch": 76,
                "learning_rate": 0.1,
                "model_norm": 197.24935913085938,
                "train_loss": 2.406808614730835,
                "val_loss": 1.4774750809860229,
                "val_top1": 66.17800000244141,
                "val_top5": 87.594000078125
            },
            {
                "epoch": 77,
                "learning_rate": 0.1,
                "model_norm": 197.75259399414062,
                "train_loss": 2.404998779296875,
                "val_loss": 1.5418589689064026,
                "val_top1": 64.4600001147461,
                "val_top5": 86.3860000756836
            },
            {
                "epoch": 78,
                "learning_rate": 0.1,
                "model_norm": 198.26902770996094,
                "train_loss": 2.4034624099731445,
                "val_loss": 1.454639071521759,
                "val_top1": 66.28199989990235,
                "val_top5": 87.65000000488281
            },
            {
                "epoch": 79,
                "learning_rate": 0.09523809523809523,
                "model_norm": 198.60411071777344,
                "train_loss": 2.394944190979004,
                "val_loss": 1.5188410880279541,
                "val_top1": 64.86799995361328,
                "val_top5": 86.54600015869141
            },
            {
                "epoch": 80,
                "learning_rate": 0.09047619047619049,
                "model_norm": 198.7395782470703,
                "train_loss": 2.375035524368286,
                "val_loss": 1.4341666639137267,
                "val_top1": 67.19600005371093,
                "val_top5": 88.10800004882813
            },
            {
                "epoch": 81,
                "learning_rate": 0.08571428571428573,
                "model_norm": 198.75369262695312,
                "train_loss": 2.3539466857910156,
                "val_loss": 1.4237082127380372,
                "val_top1": 67.1680000390625,
                "val_top5": 88.23599995605468
            },
            {
                "epoch": 82,
                "learning_rate": 0.08095238095238096,
                "model_norm": 198.69189453125,
                "train_loss": 2.337315797805786,
                "val_loss": 1.5015151200675965,
                "val_top1": 65.73600009277344,
                "val_top5": 87.25000005371093
            },
            {
                "epoch": 83,
                "learning_rate": 0.0761904761904762,
                "model_norm": 198.56057739257812,
                "train_loss": 2.320068359375,
                "val_loss": 1.4858802812385559,
                "val_top1": 65.51199995849609,
                "val_top5": 87.14399998046875
            },
            {
                "epoch": 84,
                "learning_rate": 0.07142857142857144,
                "model_norm": 198.38101196289062,
                "train_loss": 2.299492835998535,
                "val_loss": 1.4575540040969848,
                "val_top1": 66.55799999511719,
                "val_top5": 87.87599994628906
            },
            {
                "epoch": 85,
                "learning_rate": 0.06666666666666668,
                "model_norm": 198.14651489257812,
                "train_loss": 2.2789406776428223,
                "val_loss": 1.3288728892326356,
                "val_top1": 69.26800005859376,
                "val_top5": 89.37800000488281
            },
            {
                "epoch": 86,
                "learning_rate": 0.06190476190476191,
                "model_norm": 197.90469360351562,
                "train_loss": 2.2573463916778564,
                "val_loss": 1.3937888027000427,
                "val_top1": 68.26400002929688,
                "val_top5": 88.576000078125
            },
            {
                "epoch": 87,
                "learning_rate": 0.05714285714285714,
                "model_norm": 197.62509155273438,
                "train_loss": 2.2365405559539795,
                "val_loss": 1.3164979601097107,
                "val_top1": 69.35200005615235,
                "val_top5": 89.54799997070313
            },
            {
                "epoch": 88,
                "learning_rate": 0.05238095238095239,
                "model_norm": 197.29881286621094,
                "train_loss": 2.2119617462158203,
                "val_loss": 1.277969670829773,
                "val_top1": 70.22400005615235,
                "val_top5": 89.95799996826172
            },
            {
                "epoch": 89,
                "learning_rate": 0.047619047619047616,
                "model_norm": 196.9533233642578,
                "train_loss": 2.1885123252868652,
                "val_loss": 1.3390880541801453,
                "val_top1": 69.04199992919922,
                "val_top5": 89.284000078125
            },
            {
                "epoch": 90,
                "learning_rate": 0.042857142857142864,
                "model_norm": 196.57638549804688,
                "train_loss": 2.163466215133667,
                "val_loss": 1.2662589547920227,
                "val_top1": 70.90400004882812,
                "val_top5": 90.23799991455078
            },
            {
                "epoch": 91,
                "learning_rate": 0.0380952380952381,
                "model_norm": 196.17359924316406,
                "train_loss": 2.135336399078369,
                "val_loss": 1.2689277807426453,
                "val_top1": 70.63999994873046,
                "val_top5": 90.06800004638671
            },
            {
                "epoch": 92,
                "learning_rate": 0.03333333333333334,
                "model_norm": 195.7454833984375,
                "train_loss": 2.1073575019836426,
                "val_loss": 1.2104795559310912,
                "val_top1": 71.93400009765625,
                "val_top5": 90.77599989257813
            },
            {
                "epoch": 93,
                "learning_rate": 0.02857142857142857,
                "model_norm": 195.30935668945312,
                "train_loss": 2.078071355819702,
                "val_loss": 1.145735612411499,
                "val_top1": 73.14000009765626,
                "val_top5": 91.57400012207032
            },
            {
                "epoch": 94,
                "learning_rate": 0.023809523809523815,
                "model_norm": 194.86785888671875,
                "train_loss": 2.0416367053985596,
                "val_loss": 1.1647903438186646,
                "val_top1": 72.78399996826172,
                "val_top5": 91.22200004394531
            },
            {
                "epoch": 95,
                "learning_rate": 0.01904761904761905,
                "model_norm": 194.4394073486328,
                "train_loss": 2.0070109367370605,
                "val_loss": 1.1399465549087524,
                "val_top1": 73.65600009765625,
                "val_top5": 91.77399999267578
            },
            {
                "epoch": 96,
                "learning_rate": 0.01428571428571429,
                "model_norm": 194.04518127441406,
                "train_loss": 1.9680558443069458,
                "val_loss": 1.0927033492851257,
                "val_top1": 74.65600001464844,
                "val_top5": 92.26199994140624
            },
            {
                "epoch": 97,
                "learning_rate": 0.009523809523809525,
                "model_norm": 193.709716796875,
                "train_loss": 1.9296784400939941,
                "val_loss": 1.0595953139305114,
                "val_top1": 75.63800006591796,
                "val_top5": 92.68400017089844
            },
            {
                "epoch": 98,
                "learning_rate": 0.0047619047619047675,
                "model_norm": 193.4720916748047,
                "train_loss": 1.8924124240875244,
                "val_loss": 1.0214572270011901,
                "val_top1": 76.2400000366211,
                "val_top5": 93.12600001464844
            },
            {
                "epoch": 99,
                "learning_rate": 0.0,
                "model_norm": 193.3804473876953,
                "train_loss": 1.8558120727539062,
                "val_loss": 1.0053147332382202,
                "val_top1": 76.60399993408203,
                "val_top5": 93.26200004150391
            }
        ],
        "summary": {
            "len_train_loader": 1251,
            "start_time": "2025-03-26 13:29:58.749014"
        }
    },
    {
        "config": {
            "batch_size": 256,
            "dataset": "imagenet1k",
            "gradient_accumulation": 1,
            "max_epoch": 100,
            "model": "resnet50",
            "opt": {
                "lr": 0.2,
                "lr_schedule": "wsd",
                "momentum": 0.9,
                "name": "momentum",
                "weight_decay": 0.0001
            },
            "run_id": 0
        },
        "history": [
            {
                "epoch": 0,
                "learning_rate": 0.04000800000000001,
                "model_norm": 234.07627868652344,
                "train_loss": 6.549493312835693,
                "val_loss": 5.983363056640625,
                "val_top1": 3.4179999990844725,
                "val_top5": 10.61400000427246
            },
            {
                "epoch": 1,
                "learning_rate": 0.08000600000000001,
                "model_norm": 221.8516082763672,
                "train_loss": 5.939591884613037,
                "val_loss": 5.337546290588379,
                "val_top1": 7.26200001159668,
                "val_top5": 19.266000009765627
            },
            {
                "epoch": 2,
                "learning_rate": 0.12000400000000001,
                "model_norm": 205.1299285888672,
                "train_loss": 5.325767517089844,
                "val_loss": 4.638432262573242,
                "val_top1": 13.68399999633789,
                "val_top5": 31.565999989013672
            },
            {
                "epoch": 3,
                "learning_rate": 0.16000200000000003,
                "model_norm": 188.38621520996094,
                "train_loss": 4.682405948638916,
                "val_loss": 4.185813774108887,
                "val_top1": 19.10600004394531,
                "val_top5": 40.43599997314453
            },
            {
                "epoch": 4,
                "learning_rate": 0.2,
                "model_norm": 175.0245819091797,
                "train_loss": 4.207178592681885,
                "val_loss": 3.505176371459961,
                "val_top1": 27.971999965820313,
                "val_top5": 52.87400002929687
            },
            {
                "epoch": 5,
                "learning_rate": 0.2,
                "model_norm": 166.85055541992188,
                "train_loss": 3.8526389598846436,
                "val_loss": 3.0156007857513427,
                "val_top1": 35.984000024414065,
                "val_top5": 62.06799994628906
            },
            {
                "epoch": 6,
                "learning_rate": 0.2,
                "model_norm": 162.94061279296875,
                "train_loss": 3.598957061767578,
                "val_loss": 2.7638863221359253,
                "val_top1": 39.87800002197265,
                "val_top5": 66.87400013671875
            },
            {
                "epoch": 7,
                "learning_rate": 0.2,
                "model_norm": 161.8410186767578,
                "train_loss": 3.4296512603759766,
                "val_loss": 2.5972437021636963,
                "val_top1": 43.61400000854492,
                "val_top5": 70.03600004394531
            },
            {
                "epoch": 8,
                "learning_rate": 0.2,
                "model_norm": 162.3748321533203,
                "train_loss": 3.299379348754883,
                "val_loss": 2.4676838970184325,
                "val_top1": 46.133999965820315,
                "val_top5": 72.52800000732422
            },
            {
                "epoch": 9,
                "learning_rate": 0.2,
                "model_norm": 163.71522521972656,
                "train_loss": 3.2009313106536865,
                "val_loss": 2.430370569343567,
                "val_top1": 46.552000078125,
                "val_top5": 72.40199998046874
            },
            {
                "epoch": 10,
                "learning_rate": 0.2,
                "model_norm": 165.47061157226562,
                "train_loss": 3.1225156784057617,
                "val_loss": 2.2536335610961915,
                "val_top1": 49.44600005371094,
                "val_top5": 75.2780000366211
            },
            {
                "epoch": 11,
                "learning_rate": 0.2,
                "model_norm": 167.40017700195312,
                "train_loss": 3.062495708465576,
                "val_loss": 2.2171226077651975,
                "val_top1": 50.57199998413086,
                "val_top5": 76.25200008789062
            },
            {
                "epoch": 12,
                "learning_rate": 0.2,
                "model_norm": 169.33717346191406,
                "train_loss": 3.0130302906036377,
                "val_loss": 2.1731671018600465,
                "val_top1": 52.84600004638672,
                "val_top5": 77.68600001464844
            },
            {
                "epoch": 13,
                "learning_rate": 0.2,
                "model_norm": 171.2487030029297,
                "train_loss": 2.9707555770874023,
                "val_loss": 2.091900443572998,
                "val_top1": 53.19200008789063,
                "val_top5": 78.13199996582031
            },
            {
                "epoch": 14,
                "learning_rate": 0.2,
                "model_norm": 173.1133575439453,
                "train_loss": 2.935185432434082,
                "val_loss": 2.1559158562088014,
                "val_top1": 52.43399996582031,
                "val_top5": 77.17600011962891
            },
            {
                "epoch": 15,
                "learning_rate": 0.2,
                "model_norm": 174.9276580810547,
                "train_loss": 2.905885696411133,
                "val_loss": 1.9992794338607789,
                "val_top1": 55.94600003173828,
                "val_top5": 80.367999921875
            },
            {
                "epoch": 16,
                "learning_rate": 0.2,
                "model_norm": 176.6630096435547,
                "train_loss": 2.8791961669921875,
                "val_loss": 2.1193941041564943,
                "val_top1": 54.024000021972654,
                "val_top5": 78.64799994628906
            },
            {
                "epoch": 17,
                "learning_rate": 0.2,
                "model_norm": 178.40087890625,
                "train_loss": 2.856117010116577,
                "val_loss": 2.1367988394927977,
                "val_top1": 52.44000000488281,
                "val_top5": 77.46000005859375
            },
            {
                "epoch": 18,
                "learning_rate": 0.2,
                "model_norm": 180.06219482421875,
                "train_loss": 2.837245225906372,
                "val_loss": 1.9582615324401855,
                "val_top1": 56.5680000390625,
                "val_top5": 80.79400002441406
            },
            {
                "epoch": 19,
                "learning_rate": 0.2,
                "model_norm": 181.6410675048828,
                "train_loss": 2.8170809745788574,
                "val_loss": 2.084184027557373,
                "val_top1": 53.694000021972656,
                "val_top5": 79.07800002929687
            },
            {
                "epoch": 20,
                "learning_rate": 0.2,
                "model_norm": 183.2273712158203,
                "train_loss": 2.8006577491760254,
                "val_loss": 1.9702712243652343,
                "val_top1": 56.47600000244141,
                "val_top5": 80.93999993408202
            },
            {
                "epoch": 21,
                "learning_rate": 0.2,
                "model_norm": 184.7715301513672,
                "train_loss": 2.7856316566467285,
                "val_loss": 1.9104658081054688,
                "val_top1": 57.23999994873047,
                "val_top5": 81.45800001220704
            },
            {
                "epoch": 22,
                "learning_rate": 0.2,
                "model_norm": 186.25372314453125,
                "train_loss": 2.7714154720306396,
                "val_loss": 2.001259275856018,
                "val_top1": 56.07800007324219,
                "val_top5": 80.46400007324219
            },
            {
                "epoch": 23,
                "learning_rate": 0.2,
                "model_norm": 187.73834228515625,
                "train_loss": 2.7604856491088867,
                "val_loss": 1.959583966293335,
                "val_top1": 56.86600000976563,
                "val_top5": 80.62800004638672
            },
            {
                "epoch": 24,
                "learning_rate": 0.2,
                "model_norm": 189.16165161132812,
                "train_loss": 2.747570037841797,
                "val_loss": 1.9061025258636475,
                "val_top1": 58.25200003662109,
                "val_top5": 82.13800001953125
            },
            {
                "epoch": 25,
                "learning_rate": 0.2,
                "model_norm": 190.54673767089844,
                "train_loss": 2.7369401454925537,
                "val_loss": 1.8450131855392455,
                "val_top1": 58.12600005371094,
                "val_top5": 82.17600009277344
            },
            {
                "epoch": 26,
                "learning_rate": 0.2,
                "model_norm": 191.9767608642578,
                "train_loss": 2.727971076965332,
                "val_loss": 1.9042239638137817,
                "val_top1": 56.86200002929687,
                "val_top5": 81.27600006835938
            },
            {
                "epoch": 27,
                "learning_rate": 0.2,
                "model_norm": 193.3016815185547,
                "train_loss": 2.7181971073150635,
                "val_loss": 1.9194634755706788,
                "val_top1": 56.7359999609375,
                "val_top5": 80.99599995117188
            },
            {
                "epoch": 28,
                "learning_rate": 0.2,
                "model_norm": 194.61532592773438,
                "train_loss": 2.710857391357422,
                "val_loss": 1.8031581243896484,
                "val_top1": 59.436000078125,
                "val_top5": 83.10800001464844
            },
            {
                "epoch": 29,
                "learning_rate": 0.2,
                "model_norm": 195.9286346435547,
                "train_loss": 2.699801445007324,
                "val_loss": 1.8593839065551758,
                "val_top1": 58.56999987792969,
                "val_top5": 82.52800010009766
            },
            {
                "epoch": 30,
                "learning_rate": 0.2,
                "model_norm": 197.2362518310547,
                "train_loss": 2.697119951248169,
                "val_loss": 1.8137080364608764,
                "val_top1": 58.98800015625,
                "val_top5": 82.83399999267579
            },
            {
                "epoch": 31,
                "learning_rate": 0.2,
                "model_norm": 198.50479125976562,
                "train_loss": 2.688628911972046,
                "val_loss": 1.7347584314727784,
                "val_top1": 61.42600003173828,
                "val_top5": 84.4100000415039
            },
            {
                "epoch": 32,
                "learning_rate": 0.2,
                "model_norm": 199.73851013183594,
                "train_loss": 2.6796724796295166,
                "val_loss": 1.848309346885681,
                "val_top1": 58.60200002197266,
                "val_top5": 82.39200011230469
            },
            {
                "epoch": 33,
                "learning_rate": 0.2,
                "model_norm": 201.01431274414062,
                "train_loss": 2.6737589836120605,
                "val_loss": 1.8312363611221314,
                "val_top1": 58.441999946289066,
                "val_top5": 82.60999998779297
            },
            {
                "epoch": 34,
                "learning_rate": 0.2,
                "model_norm": 202.25979614257812,
                "train_loss": 2.6707615852355957,
                "val_loss": 1.7449026974487305,
                "val_top1": 60.004000007324215,
                "val_top5": 83.74000000976562
            },
            {
                "epoch": 35,
                "learning_rate": 0.2,
                "model_norm": 203.46083068847656,
                "train_loss": 2.6639082431793213,
                "val_loss": 1.7446409647369385,
                "val_top1": 60.00199996582031,
                "val_top5": 83.54200004638672
            },
            {
                "epoch": 36,
                "learning_rate": 0.2,
                "model_norm": 204.66229248046875,
                "train_loss": 2.6607329845428467,
                "val_loss": 1.8885741818237305,
                "val_top1": 57.9280000390625,
                "val_top5": 81.72200004394531
            },
            {
                "epoch": 37,
                "learning_rate": 0.2,
                "model_norm": 205.82485961914062,
                "train_loss": 2.656224012374878,
                "val_loss": 1.8442376838684083,
                "val_top1": 59.28600001953125,
                "val_top5": 82.79600008544922
            },
            {
                "epoch": 38,
                "learning_rate": 0.2,
                "model_norm": 206.9901123046875,
                "train_loss": 2.6522295475006104,
                "val_loss": 1.7304369361114502,
                "val_top1": 61.18000006835938,
                "val_top5": 84.41000005371093
            },
            {
                "epoch": 39,
                "learning_rate": 0.2,
                "model_norm": 208.1067352294922,
                "train_loss": 2.6476564407348633,
                "val_loss": 1.9658098461532594,
                "val_top1": 55.86400000732422,
                "val_top5": 80.13000011230469
            },
            {
                "epoch": 40,
                "learning_rate": 0.2,
                "model_norm": 209.22039794921875,
                "train_loss": 2.6407363414764404,
                "val_loss": 1.739170265045166,
                "val_top1": 60.71799998046875,
                "val_top5": 83.77200011474609
            },
            {
                "epoch": 41,
                "learning_rate": 0.2,
                "model_norm": 210.3412628173828,
                "train_loss": 2.6381635665893555,
                "val_loss": 1.6758636826705933,
                "val_top1": 61.821999929199215,
                "val_top5": 84.53600011962891
            },
            {
                "epoch": 42,
                "learning_rate": 0.2,
                "model_norm": 211.4582977294922,
                "train_loss": 2.6331567764282227,
                "val_loss": 1.74802815284729,
                "val_top1": 60.26399998046875,
                "val_top5": 83.76799993652344
            },
            {
                "epoch": 43,
                "learning_rate": 0.2,
                "model_norm": 212.5340118408203,
                "train_loss": 2.6307971477508545,
                "val_loss": 2.0101676634979246,
                "val_top1": 55.78599999023437,
                "val_top5": 80.11399989257812
            },
            {
                "epoch": 44,
                "learning_rate": 0.2,
                "model_norm": 213.60682678222656,
                "train_loss": 2.626189947128296,
                "val_loss": 1.803284860610962,
                "val_top1": 59.39800001464844,
                "val_top5": 82.9180000805664
            },
            {
                "epoch": 45,
                "learning_rate": 0.2,
                "model_norm": 214.6789093017578,
                "train_loss": 2.6239442825317383,
                "val_loss": 1.8217554685974122,
                "val_top1": 59.79800008789063,
                "val_top5": 82.97599997070313
            },
            {
                "epoch": 46,
                "learning_rate": 0.2,
                "model_norm": 215.7543182373047,
                "train_loss": 2.6191976070404053,
                "val_loss": 1.7692633560180664,
                "val_top1": 59.88999992919922,
                "val_top5": 83.70399988769532
            },
            {
                "epoch": 47,
                "learning_rate": 0.2,
                "model_norm": 216.7634735107422,
                "train_loss": 2.6177074909210205,
                "val_loss": 1.7598739992141723,
                "val_top1": 60.027999997558595,
                "val_top5": 83.4020000830078
            },
            {
                "epoch": 48,
                "learning_rate": 0.2,
                "model_norm": 217.8352508544922,
                "train_loss": 2.6174376010894775,
                "val_loss": 1.9285716877365113,
                "val_top1": 56.65599999023438,
                "val_top5": 80.80200007080079
            },
            {
                "epoch": 49,
                "learning_rate": 0.2,
                "model_norm": 218.81484985351562,
                "train_loss": 2.6118156909942627,
                "val_loss": 1.7304300742340089,
                "val_top1": 60.78199999511719,
                "val_top5": 84.37000003417968
            },
            {
                "epoch": 50,
                "learning_rate": 0.2,
                "model_norm": 219.80844116210938,
                "train_loss": 2.60931396484375,
                "val_loss": 2.018430055465698,
                "val_top1": 55.59800001953125,
                "val_top5": 79.68000015625
            },
            {
                "epoch": 51,
                "learning_rate": 0.2,
                "model_norm": 220.8507843017578,
                "train_loss": 2.6070005893707275,
                "val_loss": 1.7240399168777465,
                "val_top1": 60.88200002197266,
                "val_top5": 83.81000013671876
            },
            {
                "epoch": 52,
                "learning_rate": 0.2,
                "model_norm": 221.85797119140625,
                "train_loss": 2.603861093521118,
                "val_loss": 1.9184724516677856,
                "val_top1": 57.59200009765625,
                "val_top5": 81.58199997314453
            },
            {
                "epoch": 53,
                "learning_rate": 0.2,
                "model_norm": 222.82162475585938,
                "train_loss": 2.601219654083252,
                "val_loss": 1.9907738677978515,
                "val_top1": 55.60599995605469,
                "val_top5": 79.71999997558594
            },
            {
                "epoch": 54,
                "learning_rate": 0.2,
                "model_norm": 223.84617614746094,
                "train_loss": 2.600294828414917,
                "val_loss": 1.831217930908203,
                "val_top1": 58.64799994628906,
                "val_top5": 82.38399994873046
            },
            {
                "epoch": 55,
                "learning_rate": 0.2,
                "model_norm": 224.8268585205078,
                "train_loss": 2.5952866077423096,
                "val_loss": 1.7794215708160401,
                "val_top1": 59.74200000244141,
                "val_top5": 83.28400011230468
            },
            {
                "epoch": 56,
                "learning_rate": 0.2,
                "model_norm": 225.83558654785156,
                "train_loss": 2.5964102745056152,
                "val_loss": 1.8224088666915894,
                "val_top1": 59.36000008300781,
                "val_top5": 83.06999999023438
            },
            {
                "epoch": 57,
                "learning_rate": 0.2,
                "model_norm": 226.8007354736328,
                "train_loss": 2.592921733856201,
                "val_loss": 1.848697537612915,
                "val_top1": 59.23400001953125,
                "val_top5": 82.52400011230469
            },
            {
                "epoch": 58,
                "learning_rate": 0.2,
                "model_norm": 227.76268005371094,
                "train_loss": 2.5922577381134033,
                "val_loss": 1.719049794769287,
                "val_top1": 61.11400008789062,
                "val_top5": 84.26799990722657
            },
            {
                "epoch": 59,
                "learning_rate": 0.2,
                "model_norm": 228.68438720703125,
                "train_loss": 2.588226795196533,
                "val_loss": 1.873350267868042,
                "val_top1": 57.62399998535156,
                "val_top5": 81.75999999511718
            },
            {
                "epoch": 60,
                "learning_rate": 0.2,
                "model_norm": 229.61578369140625,
                "train_loss": 2.585817337036133,
                "val_loss": 1.740829946975708,
                "val_top1": 61.0439999609375,
                "val_top5": 84.01600010742187
            },
            {
                "epoch": 61,
                "learning_rate": 0.2,
                "model_norm": 230.55874633789062,
                "train_loss": 2.5854523181915283,
                "val_loss": 1.8440612495422364,
                "val_top1": 59.02800006103516,
                "val_top5": 82.42799996337891
            },
            {
                "epoch": 62,
                "learning_rate": 0.2,
                "model_norm": 231.4903564453125,
                "train_loss": 2.582792282104492,
                "val_loss": 1.664267219429016,
                "val_top1": 62.25799999511719,
                "val_top5": 85.3239999267578
            },
            {
                "epoch": 63,
                "learning_rate": 0.2,
                "model_norm": 232.40219116210938,
                "train_loss": 2.5808956623077393,
                "val_loss": 1.798499548110962,
                "val_top1": 59.594000034179686,
                "val_top5": 83.22199999023438
            },
            {
                "epoch": 64,
                "learning_rate": 0.2,
                "model_norm": 233.34690856933594,
                "train_loss": 2.579239845275879,
                "val_loss": 1.7282410804748536,
                "val_top1": 60.55000003173828,
                "val_top5": 83.92599998535157
            },
            {
                "epoch": 65,
                "learning_rate": 0.2,
                "model_norm": 234.22857666015625,
                "train_loss": 2.5773420333862305,
                "val_loss": 1.6985526831054687,
                "val_top1": 61.15600002929688,
                "val_top5": 84.27799998291016
            },
            {
                "epoch": 66,
                "learning_rate": 0.2,
                "model_norm": 235.14768981933594,
                "train_loss": 2.5751688480377197,
                "val_loss": 1.9545943701934814,
                "val_top1": 56.38000005126953,
                "val_top5": 80.36400012207031
            },
            {
                "epoch": 67,
                "learning_rate": 0.2,
                "model_norm": 236.04884338378906,
                "train_loss": 2.5737807750701904,
                "val_loss": 1.7455909206771851,
                "val_top1": 60.34800006103516,
                "val_top5": 83.98600000976562
            },
            {
                "epoch": 68,
                "learning_rate": 0.2,
                "model_norm": 236.96377563476562,
                "train_loss": 2.5714476108551025,
                "val_loss": 1.7759518062973023,
                "val_top1": 60.20200014648437,
                "val_top5": 83.23400001220703
            },
            {
                "epoch": 69,
                "learning_rate": 0.2,
                "model_norm": 237.85910034179688,
                "train_loss": 2.5718626976013184,
                "val_loss": 1.6356616764068603,
                "val_top1": 62.72000005126953,
                "val_top5": 85.33999998291016
            },
            {
                "epoch": 70,
                "learning_rate": 0.2,
                "model_norm": 238.75701904296875,
                "train_loss": 2.56949782371521,
                "val_loss": 1.7211857926177978,
                "val_top1": 60.41600007568359,
                "val_top5": 84.05399990722657
            },
            {
                "epoch": 71,
                "learning_rate": 0.2,
                "model_norm": 239.647705078125,
                "train_loss": 2.567617177963257,
                "val_loss": 1.7872507933807373,
                "val_top1": 60.23800004150391,
                "val_top5": 83.94199996826171
            },
            {
                "epoch": 72,
                "learning_rate": 0.2,
                "model_norm": 240.5419464111328,
                "train_loss": 2.565241813659668,
                "val_loss": 1.7368766522979737,
                "val_top1": 60.94600005859375,
                "val_top5": 84.14999991210938
            },
            {
                "epoch": 73,
                "learning_rate": 0.2,
                "model_norm": 241.3980712890625,
                "train_loss": 2.5649962425231934,
                "val_loss": 1.6562714607238769,
                "val_top1": 62.28800006347656,
                "val_top5": 84.91800005859375
            },
            {
                "epoch": 74,
                "learning_rate": 0.2,
                "model_norm": 242.2575225830078,
                "train_loss": 2.5623412132263184,
                "val_loss": 1.6383533654022218,
                "val_top1": 62.372000014648435,
                "val_top5": 85.28600000732422
            },
            {
                "epoch": 75,
                "learning_rate": 0.2,
                "model_norm": 243.13633728027344,
                "train_loss": 2.5641300678253174,
                "val_loss": 1.9066686318206787,
                "val_top1": 57.679999982910154,
                "val_top5": 81.31800010009766
            },
            {
                "epoch": 76,
                "learning_rate": 0.2,
                "model_norm": 243.96865844726562,
                "train_loss": 2.558318614959717,
                "val_loss": 1.7133454402923585,
                "val_top1": 60.94000013183594,
                "val_top5": 84.20200001464843
            },
            {
                "epoch": 77,
                "learning_rate": 0.2,
                "model_norm": 244.8354034423828,
                "train_loss": 2.559037923812866,
                "val_loss": 1.8023907863998414,
                "val_top1": 59.73200008056641,
                "val_top5": 83.27400006347656
            },
            {
                "epoch": 78,
                "learning_rate": 0.2,
                "model_norm": 245.68154907226562,
                "train_loss": 2.5576720237731934,
                "val_loss": 1.805795016708374,
                "val_top1": 59.514000002441406,
                "val_top5": 82.58999993896484
            },
            {
                "epoch": 79,
                "learning_rate": 0.19047619047619047,
                "model_norm": 246.25917053222656,
                "train_loss": 2.5472002029418945,
                "val_loss": 1.7114078470611571,
                "val_top1": 61.52799993164062,
                "val_top5": 84.39000001464844
            },
            {
                "epoch": 80,
                "learning_rate": 0.18095238095238098,
                "model_norm": 246.54132080078125,
                "train_loss": 2.5288772583007812,
                "val_loss": 1.8773546391296387,
                "val_top1": 58.12799993164062,
                "val_top5": 81.43799998535157
            },
            {
                "epoch": 81,
                "learning_rate": 0.17142857142857146,
                "model_norm": 246.71546936035156,
                "train_loss": 2.506192684173584,
                "val_loss": 1.6561030528259277,
                "val_top1": 62.42400005371094,
                "val_top5": 85.19000009277343
            },
            {
                "epoch": 82,
                "learning_rate": 0.1619047619047619,
                "model_norm": 246.79220581054688,
                "train_loss": 2.488222122192383,
                "val_loss": 1.8628745935821533,
                "val_top1": 59.15800001953125,
                "val_top5": 82.18000000488281
            },
            {
                "epoch": 83,
                "learning_rate": 0.1523809523809524,
                "model_norm": 246.81393432617188,
                "train_loss": 2.4698846340179443,
                "val_loss": 1.6391306673812867,
                "val_top1": 62.79200003417969,
                "val_top5": 84.99400008300782
            },
            {
                "epoch": 84,
                "learning_rate": 0.14285714285714288,
                "model_norm": 246.79420471191406,
                "train_loss": 2.4473962783813477,
                "val_loss": 1.7426934924316406,
                "val_top1": 60.94599996337891,
                "val_top5": 83.99800007324218
            },
            {
                "epoch": 85,
                "learning_rate": 0.13333333333333336,
                "model_norm": 246.7149658203125,
                "train_loss": 2.4251155853271484,
                "val_loss": 1.656488985786438,
                "val_top1": 62.666000078125,
                "val_top5": 84.90399990722656
            },
            {
                "epoch": 86,
                "learning_rate": 0.12380952380952381,
                "model_norm": 246.60116577148438,
                "train_loss": 2.401721239089966,
                "val_loss": 1.5490612563323976,
                "val_top1": 65.00000005126954,
                "val_top5": 86.4240000415039
            },
            {
                "epoch": 87,
                "learning_rate": 0.11428571428571428,
                "model_norm": 246.40684509277344,
                "train_loss": 2.3782362937927246,
                "val_loss": 1.4844251766586303,
                "val_top1": 65.74000006591797,
                "val_top5": 87.44600000488282
            },
            {
                "epoch": 88,
                "learning_rate": 0.10476190476190478,
                "model_norm": 246.15884399414062,
                "train_loss": 2.3521029949188232,
                "val_loss": 1.5013557066345216,
                "val_top1": 66.03799994140626,
                "val_top5": 87.31400000732422
            },
            {
                "epoch": 89,
                "learning_rate": 0.09523809523809523,
                "model_norm": 245.85276794433594,
                "train_loss": 2.3242874145507812,
                "val_loss": 1.4383158902168274,
                "val_top1": 67.26199997802735,
                "val_top5": 88.226000078125
            },
            {
                "epoch": 90,
                "learning_rate": 0.08571428571428573,
                "model_norm": 245.47457885742188,
                "train_loss": 2.2962756156921387,
                "val_loss": 1.3948114676475525,
                "val_top1": 67.70400006103516,
                "val_top5": 88.23800005615234
            },
            {
                "epoch": 91,
                "learning_rate": 0.0761904761904762,
                "model_norm": 245.0699462890625,
                "train_loss": 2.264725923538208,
                "val_loss": 1.2950235220718385,
                "val_top1": 69.72800002197266,
                "val_top5": 89.63800002197266
            },
            {
                "epoch": 92,
                "learning_rate": 0.06666666666666668,
                "model_norm": 244.6036376953125,
                "train_loss": 2.231703758239746,
                "val_loss": 1.2979973962593079,
                "val_top1": 70.04000000488281,
                "val_top5": 89.73200007324219
            },
            {
                "epoch": 93,
                "learning_rate": 0.05714285714285714,
                "model_norm": 244.1006622314453,
                "train_loss": 2.1972689628601074,
                "val_loss": 1.2697980024147033,
                "val_top1": 70.64999998291016,
                "val_top5": 90.09599994628907
            },
            {
                "epoch": 94,
                "learning_rate": 0.04761904761904763,
                "model_norm": 243.5619354248047,
                "train_loss": 2.155897855758667,
                "val_loss": 1.2223224430465698,
                "val_top1": 71.45800010009765,
                "val_top5": 90.6119999975586
            },
            {
                "epoch": 95,
                "learning_rate": 0.0380952380952381,
                "model_norm": 243.00283813476562,
                "train_loss": 2.111678123474121,
                "val_loss": 1.1512293218421936,
                "val_top1": 73.19399999511718,
                "val_top5": 91.59000001953125
            },
            {
                "epoch": 96,
                "learning_rate": 0.02857142857142858,
                "model_norm": 242.45309448242188,
                "train_loss": 2.0623109340667725,
                "val_loss": 1.1713517433929443,
                "val_top1": 73.07199996826172,
                "val_top5": 91.40199994628907
            },
            {
                "epoch": 97,
                "learning_rate": 0.01904761904761905,
                "model_norm": 241.95582580566406,
                "train_loss": 2.0111935138702393,
                "val_loss": 1.0919122960090637,
                "val_top1": 74.67600001953124,
                "val_top5": 92.3639999633789
            },
            {
                "epoch": 98,
                "learning_rate": 0.009523809523809535,
                "model_norm": 241.58059692382812,
                "train_loss": 1.9590145349502563,
                "val_loss": 1.0316731986999512,
                "val_top1": 75.7659999609375,
                "val_top5": 92.98000001464844
            },
            {
                "epoch": 99,
                "learning_rate": 0.0,
                "model_norm": 241.4282989501953,
                "train_loss": 1.9066615104675293,
                "val_loss": 0.995554522781372,
                "val_top1": 76.64600001220703,
                "val_top5": 93.3880000415039
            }
        ],
        "summary": {
            "len_train_loader": 1251,
            "start_time": "2025-03-26 15:44:34.918211"
        }
    },
    {
        "config": {
            "batch_size": 256,
            "dataset": "imagenet1k",
            "gradient_accumulation": 1,
            "max_epoch": 100,
            "model": "resnet50",
            "opt": {
                "lr": 0.4,
                "lr_schedule": "cosine",
                "momentum": 0.9,
                "name": "momentum",
                "weight_decay": 0.0001
            },
            "run_id": 0
        },
        "history": [
            {
                "epoch": 0,
                "learning_rate": 0.080008,
                "model_norm": 229.7904510498047,
                "train_grad_norm": 0.963539867442051,
                "train_loss": 6.44606876373291,
                "val_loss": 5.729341376495361,
                "val_top1": 4.60400000579834,
                "val_top5": 13.221999965820313
            },
            {
                "epoch": 1,
                "learning_rate": 0.160006,
                "model_norm": 207.937744140625,
                "train_grad_norm": 1.050059203075297,
                "train_loss": 5.660904407501221,
                "val_loss": 5.277152816009521,
                "val_top1": 7.972000010986328,
                "val_top5": 20.6860000390625
            },
            {
                "epoch": 2,
                "learning_rate": 0.240004,
                "model_norm": 184.6366424560547,
                "train_grad_norm": 1.0409470648018018,
                "train_loss": 4.84236478805542,
                "val_loss": 4.189275117797852,
                "val_top1": 17.96400006347656,
                "val_top5": 39.56600002075195
            },
            {
                "epoch": 3,
                "learning_rate": 0.320002,
                "model_norm": 169.51324462890625,
                "train_grad_norm": 0.9683234767936364,
                "train_loss": 4.233952045440674,
                "val_loss": 3.510338759460449,
                "val_top1": 27.94200003173828,
                "val_top5": 52.718000029296874
            },
            {
                "epoch": 4,
                "learning_rate": 0.3975376681190276,
                "model_norm": 165.76654052734375,
                "train_grad_norm": 0.9206262139459696,
                "train_loss": 3.864772319793701,
                "val_loss": 3.1973481115722655,
                "val_top1": 33.99200005126953,
                "val_top5": 59.739999982910156
            },
            {
                "epoch": 5,
                "learning_rate": 0.3964574501457378,
                "model_norm": 168.22581481933594,
                "train_grad_norm": 0.8945055859906816,
                "train_loss": 3.6110823154449463,
                "val_loss": 2.9475522035217283,
                "val_top1": 37.97000004272461,
                "val_top5": 64.33800001953125
            },
            {
                "epoch": 6,
                "learning_rate": 0.3951833523877495,
                "model_norm": 172.39051818847656,
                "train_grad_norm": 0.9022049617503836,
                "train_loss": 3.433262825012207,
                "val_loss": 2.867694624404907,
                "val_top1": 39.10199998046875,
                "val_top5": 65.51600001953125
            },
            {
                "epoch": 7,
                "learning_rate": 0.3937166322257262,
                "model_norm": 176.9035186767578,
                "train_grad_norm": 0.9129878900419207,
                "train_loss": 3.319180488586426,
                "val_loss": 2.6161027392578124,
                "val_top1": 43.43199992431641,
                "val_top5": 70.2459999633789
            },
            {
                "epoch": 8,
                "learning_rate": 0.39205873713538864,
                "model_norm": 181.1772918701172,
                "train_grad_norm": 0.9209590473771372,
                "train_loss": 3.2374026775360107,
                "val_loss": 2.560034604110718,
                "val_top1": 45.05400002075195,
                "val_top5": 71.38799998535156
            },
            {
                "epoch": 9,
                "learning_rate": 0.39021130325903075,
                "model_norm": 185.09674072265625,
                "train_grad_norm": 0.9281395171861878,
                "train_loss": 3.1760735511779785,
                "val_loss": 2.64051282333374,
                "val_top1": 42.67799997070313,
                "val_top5": 69.36400008544922
            },
            {
                "epoch": 10,
                "learning_rate": 0.38817615379084514,
                "model_norm": 188.80377197265625,
                "train_grad_norm": 0.9352480021167553,
                "train_loss": 3.125735282897949,
                "val_loss": 2.2336228086853027,
                "val_top1": 49.31000001464844,
                "val_top5": 75.32200000732422
            },
            {
                "epoch": 11,
                "learning_rate": 0.3859552971776503,
                "model_norm": 192.2559814453125,
                "train_grad_norm": 0.9420461649373316,
                "train_loss": 3.0866599082946777,
                "val_loss": 2.2177385592651366,
                "val_top1": 50.14199998291016,
                "val_top5": 76.60800007324218
            },
            {
                "epoch": 12,
                "learning_rate": 0.38355092513679623,
                "model_norm": 195.5028533935547,
                "train_grad_norm": 0.9481157694125496,
                "train_loss": 3.0545594692230225,
                "val_loss": 2.7427916046142577,
                "val_top1": 41.69800001220703,
                "val_top5": 67.23599999023438
            },
            {
                "epoch": 13,
                "learning_rate": 0.3809654104932039,
                "model_norm": 198.60018920898438,
                "train_grad_norm": 0.9535767147158462,
                "train_loss": 3.0269408226013184,
                "val_loss": 2.165420773162842,
                "val_top1": 51.82799998291016,
                "val_top5": 77.62000000488281
            },
            {
                "epoch": 14,
                "learning_rate": 0.37820130483767356,
                "model_norm": 201.42095947265625,
                "train_grad_norm": 0.9580132264512543,
                "train_loss": 3.0001277923583984,
                "val_loss": 2.2021405626678465,
                "val_top1": 51.25000003173828,
                "val_top5": 76.63600005615234
            },
            {
                "epoch": 15,
                "learning_rate": 0.3752613360087727,
                "model_norm": 204.16351318359375,
                "train_grad_norm": 0.9640452007333421,
                "train_loss": 2.979318618774414,
                "val_loss": 2.221370612754822,
                "val_top1": 51.46199998046875,
                "val_top5": 76.92200006347656
            },
            {
                "epoch": 16,
                "learning_rate": 0.37214840540078875,
                "model_norm": 206.8380126953125,
                "train_grad_norm": 0.9684081292271717,
                "train_loss": 2.961049795150757,
                "val_loss": 2.209597103881836,
                "val_top1": 51.73200014160156,
                "val_top5": 76.90199990478516
            },
            {
                "epoch": 17,
                "learning_rate": 0.368865585100403,
                "model_norm": 209.34324645996094,
                "train_grad_norm": 0.9741155945486226,
                "train_loss": 2.9413247108459473,
                "val_loss": 2.14464037940979,
                "val_top1": 52.454000053710935,
                "val_top5": 77.87600002441407
            },
            {
                "epoch": 18,
                "learning_rate": 0.3654161148549124,
                "model_norm": 211.77491760253906,
                "train_grad_norm": 0.9790360199390058,
                "train_loss": 2.9254486560821533,
                "val_loss": 2.085109735450745,
                "val_top1": 53.89999989257812,
                "val_top5": 79.09800000244141
            },
            {
                "epoch": 19,
                "learning_rate": 0.3618033988749895,
                "model_norm": 214.0426025390625,
                "train_grad_norm": 0.9827488907160885,
                "train_loss": 2.909431219100952,
                "val_loss": 2.1382619801712037,
                "val_top1": 53.168000034179684,
                "val_top5": 78.36600008300782
            },
            {
                "epoch": 20,
                "learning_rate": 0.3580310024751381,
                "model_norm": 216.29800415039062,
                "train_grad_norm": 0.9889974937554082,
                "train_loss": 2.8971590995788574,
                "val_loss": 2.1552807530212403,
                "val_top1": 52.656000036621094,
                "val_top5": 77.75799999267578
            },
            {
                "epoch": 21,
                "learning_rate": 0.3541026485551579,
                "model_norm": 218.4312744140625,
                "train_grad_norm": 0.993406406224227,
                "train_loss": 2.8843982219696045,
                "val_loss": 2.0073155738449096,
                "val_top1": 54.519999970703125,
                "val_top5": 79.79400006347656
            },
            {
                "epoch": 22,
                "learning_rate": 0.35002221392609195,
                "model_norm": 220.41790771484375,
                "train_grad_norm": 0.9970192446075057,
                "train_loss": 2.870375633239746,
                "val_loss": 2.144714526672363,
                "val_top1": 52.86600011230469,
                "val_top5": 77.97999998291016
            },
            {
                "epoch": 23,
                "learning_rate": 0.34579372548428233,
                "model_norm": 222.3969268798828,
                "train_grad_norm": 1.0025071913762817,
                "train_loss": 2.8596997261047363,
                "val_loss": 2.1016562912750243,
                "val_top1": 54.543999968261716,
                "val_top5": 79.04400000488282
            },
            {
                "epoch": 24,
                "learning_rate": 0.3414213562373095,
                "model_norm": 224.25514221191406,
                "train_grad_norm": 1.0064239500079288,
                "train_loss": 2.8450353145599365,
                "val_loss": 2.039875336380005,
                "val_top1": 54.300000068359374,
                "val_top5": 79.44200002929688
            },
            {
                "epoch": 25,
                "learning_rate": 0.33690942118573775,
                "model_norm": 226.0140380859375,
                "train_grad_norm": 1.0105077345230429,
                "train_loss": 2.8346471786499023,
                "val_loss": 2.019029041976929,
                "val_top1": 55.29399998046875,
                "val_top5": 80.15199994140625
            },
            {
                "epoch": 26,
                "learning_rate": 0.3322623730647304,
                "model_norm": 227.77101135253906,
                "train_grad_norm": 1.0166441677838756,
                "train_loss": 2.823245048522949,
                "val_loss": 2.0294341304397583,
                "val_top1": 53.9859999609375,
                "val_top5": 78.86999999267579
            },
            {
                "epoch": 27,
                "learning_rate": 0.32748479794973795,
                "model_norm": 229.39845275878906,
                "train_grad_norm": 1.0208932433719164,
                "train_loss": 2.811809778213501,
                "val_loss": 1.937589896774292,
                "val_top1": 56.534000048828126,
                "val_top5": 80.90400001708984
            },
            {
                "epoch": 28,
                "learning_rate": 0.3225814107305953,
                "model_norm": 230.97744750976562,
                "train_grad_norm": 1.026404005954407,
                "train_loss": 2.8015007972717285,
                "val_loss": 1.9444912308502198,
                "val_top1": 56.64199994628906,
                "val_top5": 81.02400002441406
            },
            {
                "epoch": 29,
                "learning_rate": 0.31755705045849464,
                "model_norm": 232.51242065429688,
                "train_grad_norm": 1.0313629060021996,
                "train_loss": 2.7892367839813232,
                "val_loss": 1.9901762260055542,
                "val_top1": 55.43000004150391,
                "val_top5": 79.91600010009766
            },
            {
                "epoch": 30,
                "learning_rate": 0.3124166755704262,
                "model_norm": 234.01690673828125,
                "train_grad_norm": 1.0378726081005833,
                "train_loss": 2.782928943634033,
                "val_loss": 2.104039707107544,
                "val_top1": 53.16199990966797,
                "val_top5": 78.10000010742188
            },
            {
                "epoch": 31,
                "learning_rate": 0.30716535899579933,
                "model_norm": 235.450927734375,
                "train_grad_norm": 1.042852489603355,
                "train_loss": 2.770730972290039,
                "val_loss": 2.0367562280273437,
                "val_top1": 54.69800002929688,
                "val_top5": 79.47000005615234
            },
            {
                "epoch": 32,
                "learning_rate": 0.3018082831500743,
                "model_norm": 236.79739379882812,
                "train_grad_norm": 1.048473400534592,
                "train_loss": 2.757343292236328,
                "val_loss": 2.156636581878662,
                "val_top1": 52.42000008789063,
                "val_top5": 77.44000013183594
            },
            {
                "epoch": 33,
                "learning_rate": 0.2963507348203431,
                "model_norm": 238.13290405273438,
                "train_grad_norm": 1.0550710180365788,
                "train_loss": 2.7469983100891113,
                "val_loss": 1.830037467651367,
                "val_top1": 58.052000053710934,
                "val_top5": 82.50200001708984
            },
            {
                "epoch": 34,
                "learning_rate": 0.29079809994790934,
                "model_norm": 239.345947265625,
                "train_grad_norm": 1.0604504098761434,
                "train_loss": 2.736457586288452,
                "val_loss": 2.0538019643783567,
                "val_top1": 54.598000087890625,
                "val_top5": 79.38200004882812
            },
            {
                "epoch": 35,
                "learning_rate": 0.28515585831301454,
                "model_norm": 240.53955078125,
                "train_grad_norm": 1.0669408613122482,
                "train_loss": 2.726266860961914,
                "val_loss": 1.8989781255722047,
                "val_top1": 57.50200006835937,
                "val_top5": 81.48800007324219
            },
            {
                "epoch": 36,
                "learning_rate": 0.2794295781269562,
                "model_norm": 241.70541381835938,
                "train_grad_norm": 1.0745469878441518,
                "train_loss": 2.718958616256714,
                "val_loss": 1.8496457996749878,
                "val_top1": 58.44399995361328,
                "val_top5": 82.6979999584961
            },
            {
                "epoch": 37,
                "learning_rate": 0.2736249105369356,
                "model_norm": 242.81495666503906,
                "train_grad_norm": 1.0815892291177622,
                "train_loss": 2.707080841064453,
                "val_loss": 1.9358515086746215,
                "val_top1": 57.724000078125,
                "val_top5": 81.49600003417969
            },
            {
                "epoch": 38,
                "learning_rate": 0.26774758404905835,
                "model_norm": 243.88671875,
                "train_grad_norm": 1.0891533644196658,
                "train_loss": 2.695417642593384,
                "val_loss": 1.9826720526504518,
                "val_top1": 55.99600001708984,
                "val_top5": 80.46400005371093
            },
            {
                "epoch": 39,
                "learning_rate": 0.2618033988749895,
                "model_norm": 244.85325622558594,
                "train_grad_norm": 1.094973143953867,
                "train_loss": 2.686275005340576,
                "val_loss": 1.7646489507293701,
                "val_top1": 59.758000102539064,
                "val_top5": 83.63199996582031
            },
            {
                "epoch": 40,
                "learning_rate": 0.2557982212078459,
                "model_norm": 245.84683227539062,
                "train_grad_norm": 1.1040531519320638,
                "train_loss": 2.6730904579162598,
                "val_loss": 1.8344843357086182,
                "val_top1": 58.71199999511719,
                "val_top5": 82.88800004638672
            },
            {
                "epoch": 41,
                "learning_rate": 0.24973797743297102,
                "model_norm": 246.72633361816406,
                "train_grad_norm": 1.111104942656255,
                "train_loss": 2.6638801097869873,
                "val_loss": 1.8295687934875489,
                "val_top1": 58.92799994140625,
                "val_top5": 82.35800014892578
            },
            {
                "epoch": 42,
                "learning_rate": 0.24362864827930852,
                "model_norm": 247.5966339111328,
                "train_grad_norm": 1.1188544654389372,
                "train_loss": 2.65183687210083,
                "val_loss": 1.8416485478973388,
                "val_top1": 58.3620000805664,
                "val_top5": 82.1100000439453
            },
            {
                "epoch": 43,
                "learning_rate": 0.23747626291714496,
                "model_norm": 248.40676879882812,
                "train_grad_norm": 1.1273020876389033,
                "train_loss": 2.6407673358917236,
                "val_loss": 1.7449501600646973,
                "val_top1": 60.53800000244141,
                "val_top5": 83.93600008544922
            },
            {
                "epoch": 44,
                "learning_rate": 0.2312868930080462,
                "model_norm": 249.20921325683594,
                "train_grad_norm": 1.1369023427081189,
                "train_loss": 2.629460334777832,
                "val_loss": 1.6833249407958983,
                "val_top1": 61.752000078125,
                "val_top5": 84.6980000415039
            },
            {
                "epoch": 45,
                "learning_rate": 0.22506664671286086,
                "model_norm": 249.96005249023438,
                "train_grad_norm": 1.1461885290317773,
                "train_loss": 2.618565797805786,
                "val_loss": 1.8886838534545898,
                "val_top1": 58.7139999609375,
                "val_top5": 82.59200001953126
            },
            {
                "epoch": 46,
                "learning_rate": 0.21882166266370287,
                "model_norm": 250.6778564453125,
                "train_grad_norm": 1.1556474371304175,
                "train_loss": 2.604840040206909,
                "val_loss": 1.7953687397003173,
                "val_top1": 59.64799996582031,
                "val_top5": 83.13999991699218
            },
            {
                "epoch": 47,
                "learning_rate": 0.21255810390586272,
                "model_norm": 251.30299377441406,
                "train_grad_norm": 1.1654459637495072,
                "train_loss": 2.5949654579162598,
                "val_loss": 1.6457969927978515,
                "val_top1": 61.96200005859375,
                "val_top5": 84.74000001953125
            },
            {
                "epoch": 48,
                "learning_rate": 0.20628215181562562,
                "model_norm": 251.92213439941406,
                "train_grad_norm": 1.1763432318831273,
                "train_loss": 2.584303379058838,
                "val_loss": 1.5853211898803712,
                "val_top1": 63.6140000390625,
                "val_top5": 85.9719999243164
            },
            {
                "epoch": 49,
                "learning_rate": 0.2,
                "model_norm": 252.4493865966797,
                "train_grad_norm": 1.1846640759048457,
                "train_loss": 2.5707509517669678,
                "val_loss": 1.6791338767242432,
                "val_top1": 61.784,
                "val_top5": 84.96800000732422
            },
            {
                "epoch": 50,
                "learning_rate": 0.1937178481843744,
                "model_norm": 252.9768524169922,
                "train_grad_norm": 1.196958814997689,
                "train_loss": 2.560372829437256,
                "val_loss": 1.6101436939239502,
                "val_top1": 63.36800006591797,
                "val_top5": 85.69600000976563
            },
            {
                "epoch": 51,
                "learning_rate": 0.18744189609413733,
                "model_norm": 253.48887634277344,
                "train_grad_norm": 1.209294336506542,
                "train_loss": 2.5462663173675537,
                "val_loss": 1.6585637225341796,
                "val_top1": 62.115999926757816,
                "val_top5": 84.80400018554687
            },
            {
                "epoch": 52,
                "learning_rate": 0.18117833733629718,
                "model_norm": 253.95555114746094,
                "train_grad_norm": 1.2212892336078116,
                "train_loss": 2.534407138824463,
                "val_loss": 1.6766024119186402,
                "val_top1": 62.20599997802734,
                "val_top5": 84.80200004394531
            },
            {
                "epoch": 53,
                "learning_rate": 0.1749333532871392,
                "model_norm": 254.35987854003906,
                "train_grad_norm": 1.232553078686746,
                "train_loss": 2.52071475982666,
                "val_loss": 1.8086301837158203,
                "val_top1": 59.37000002441406,
                "val_top5": 83.01799999755859
            },
            {
                "epoch": 54,
                "learning_rate": 0.16871310699195385,
                "model_norm": 254.75167846679688,
                "train_grad_norm": 1.245730368935107,
                "train_loss": 2.5079832077026367,
                "val_loss": 1.5843178961563111,
                "val_top1": 63.49200010742187,
                "val_top5": 85.93999999023437
            },
            {
                "epoch": 55,
                "learning_rate": 0.16252373708285509,
                "model_norm": 255.08938598632812,
                "train_grad_norm": 1.2580222057726205,
                "train_loss": 2.4951395988464355,
                "val_loss": 1.7646569288635254,
                "val_top1": 60.138,
                "val_top5": 83.31000001464844
            },
            {
                "epoch": 56,
                "learning_rate": 0.1563713517206915,
                "model_norm": 255.41917419433594,
                "train_grad_norm": 1.2731632952753245,
                "train_loss": 2.481872081756592,
                "val_loss": 1.8439511381530762,
                "val_top1": 59.184000068359374,
                "val_top5": 82.51999994628906
            },
            {
                "epoch": 57,
                "learning_rate": 0.15026202256702909,
                "model_norm": 255.7183837890625,
                "train_grad_norm": 1.2877088417771825,
                "train_loss": 2.4683690071105957,
                "val_loss": 1.7103652236557008,
                "val_top1": 62.5180000390625,
                "val_top5": 85.12399995605469
            },
            {
                "epoch": 58,
                "learning_rate": 0.14420177879215418,
                "model_norm": 255.9702606201172,
                "train_grad_norm": 1.3019618982981023,
                "train_loss": 2.4552550315856934,
                "val_loss": 1.6535662495803833,
                "val_top1": 62.65400004638672,
                "val_top5": 85.15000000488281
            },
            {
                "epoch": 59,
                "learning_rate": 0.13819660112501053,
                "model_norm": 256.1656494140625,
                "train_grad_norm": 1.3161765081185832,
                "train_loss": 2.439274549484253,
                "val_loss": 1.6059593180084228,
                "val_top1": 62.96399990966797,
                "val_top5": 85.42199990234376
            },
            {
                "epoch": 60,
                "learning_rate": 0.13225241595094173,
                "model_norm": 256.34210205078125,
                "train_grad_norm": 1.3318322485576184,
                "train_loss": 2.4256062507629395,
                "val_loss": 1.5183623988151551,
                "val_top1": 65.69399999023437,
                "val_top5": 87.07800002929687
            },
            {
                "epoch": 61,
                "learning_rate": 0.12637508946306447,
                "model_norm": 256.4876708984375,
                "train_grad_norm": 1.3473887925945098,
                "train_loss": 2.41109561920166,
                "val_loss": 1.5336085967063904,
                "val_top1": 64.8599999609375,
                "val_top5": 86.61799997558593
            },
            {
                "epoch": 62,
                "learning_rate": 0.12057042187304386,
                "model_norm": 256.6116027832031,
                "train_grad_norm": 1.3655103120866277,
                "train_loss": 2.3948564529418945,
                "val_loss": 1.5199030154037476,
                "val_top1": 65.00399998535157,
                "val_top5": 86.97600005371093
            },
            {
                "epoch": 63,
                "learning_rate": 0.11484414168698548,
                "model_norm": 256.70263671875,
                "train_grad_norm": 1.383276609445628,
                "train_loss": 2.3811843395233154,
                "val_loss": 1.4712485673522948,
                "val_top1": 66.55800006835938,
                "val_top5": 87.68600005859375
            },
            {
                "epoch": 64,
                "learning_rate": 0.10920190005209066,
                "model_norm": 256.7651062011719,
                "train_grad_norm": 1.4013527206901315,
                "train_loss": 2.365708112716675,
                "val_loss": 1.4505159874343871,
                "val_top1": 66.56400001220703,
                "val_top5": 87.94400008544922
            },
            {
                "epoch": 65,
                "learning_rate": 0.10364926517965692,
                "model_norm": 256.8067626953125,
                "train_grad_norm": 1.4212809250217875,
                "train_loss": 2.349930763244629,
                "val_loss": 1.4185243522834778,
                "val_top1": 67.32599987792969,
                "val_top5": 88.24800004638672
            },
            {
                "epoch": 66,
                "learning_rate": 0.09819171684992574,
                "model_norm": 256.82586669921875,
                "train_grad_norm": 1.4418684131680308,
                "train_loss": 2.3338212966918945,
                "val_loss": 1.3592339761924743,
                "val_top1": 68.33600006103515,
                "val_top5": 88.99200013183594
            },
            {
                "epoch": 67,
                "learning_rate": 0.09283464100420072,
                "model_norm": 256.8187255859375,
                "train_grad_norm": 1.4624482413369821,
                "train_loss": 2.316807746887207,
                "val_loss": 1.470538074874878,
                "val_top1": 65.65199998291016,
                "val_top5": 87.4959999975586
            },
            {
                "epoch": 68,
                "learning_rate": 0.08758332442957394,
                "model_norm": 256.78546142578125,
                "train_grad_norm": 1.4837477958317837,
                "train_loss": 2.298624038696289,
                "val_loss": 1.3461848258590698,
                "val_top1": 69.08200000488281,
                "val_top5": 89.23599994628906
            },
            {
                "epoch": 69,
                "learning_rate": 0.0824429495415054,
                "model_norm": 256.73333740234375,
                "train_grad_norm": 1.506592158691779,
                "train_loss": 2.283306837081909,
                "val_loss": 1.4084063862609864,
                "val_top1": 67.53999999267577,
                "val_top5": 88.64199997558593
            },
            {
                "epoch": 70,
                "learning_rate": 0.07741858926940469,
                "model_norm": 256.656494140625,
                "train_grad_norm": 1.5287132324303045,
                "train_loss": 2.265617847442627,
                "val_loss": 1.3956751424407958,
                "val_top1": 67.78799996826172,
                "val_top5": 88.63600002441406
            },
            {
                "epoch": 71,
                "learning_rate": 0.07251520205026206,
                "model_norm": 256.5638427734375,
                "train_grad_norm": 1.5547912122947647,
                "train_loss": 2.2473998069763184,
                "val_loss": 1.3471044309043885,
                "val_top1": 68.87200003173828,
                "val_top5": 89.30199995117188
            },
            {
                "epoch": 72,
                "learning_rate": 0.06773762693526966,
                "model_norm": 256.4478454589844,
                "train_grad_norm": 1.580519604971106,
                "train_loss": 2.229149103164673,
                "val_loss": 1.2906374249076844,
                "val_top1": 69.7180000024414,
                "val_top5": 89.742
            },
            {
                "epoch": 73,
                "learning_rate": 0.06309057881426232,
                "model_norm": 256.309326171875,
                "train_grad_norm": 1.6040689844920841,
                "train_loss": 2.210948944091797,
                "val_loss": 1.310674301109314,
                "val_top1": 69.81000002685546,
                "val_top5": 89.46399997314452
            },
            {
                "epoch": 74,
                "learning_rate": 0.058578643762690445,
                "model_norm": 256.1606140136719,
                "train_grad_norm": 1.633673964123771,
                "train_loss": 2.1923668384552,
                "val_loss": 1.2728051955795288,
                "val_top1": 70.60799995117188,
                "val_top5": 90.08799999511719
            },
            {
                "epoch": 75,
                "learning_rate": 0.05420627451571767,
                "model_norm": 255.99365234375,
                "train_grad_norm": 1.6601505974799418,
                "train_loss": 2.173983097076416,
                "val_loss": 1.2937410064888,
                "val_top1": 69.89799989746093,
                "val_top5": 89.90999991943359
            },
            {
                "epoch": 76,
                "learning_rate": 0.049977786073908084,
                "model_norm": 255.80685424804688,
                "train_grad_norm": 1.6869932092819437,
                "train_loss": 2.1523420810699463,
                "val_loss": 1.2831847932052611,
                "val_top1": 70.34800002685547,
                "val_top5": 90.1179999194336
            },
            {
                "epoch": 77,
                "learning_rate": 0.04589735144484217,
                "model_norm": 255.60958862304688,
                "train_grad_norm": 1.7174572372642483,
                "train_loss": 2.13185715675354,
                "val_loss": 1.2353510525131226,
                "val_top1": 71.12000009765624,
                "val_top5": 90.57199996826172
            },
            {
                "epoch": 78,
                "learning_rate": 0.04196899752486197,
                "model_norm": 255.4047393798828,
                "train_grad_norm": 1.749290106839193,
                "train_loss": 2.11312198638916,
                "val_loss": 1.2522060454177857,
                "val_top1": 71.2020000756836,
                "val_top5": 90.41399994628907
            },
            {
                "epoch": 79,
                "learning_rate": 0.03819660112501053,
                "model_norm": 255.1906280517578,
                "train_grad_norm": 1.7805402582254877,
                "train_loss": 2.0922768115997314,
                "val_loss": 1.2054942406272888,
                "val_top1": 71.85600002197266,
                "val_top5": 90.95200004882813
            },
            {
                "epoch": 80,
                "learning_rate": 0.03458388514508761,
                "model_norm": 254.97483825683594,
                "train_grad_norm": 1.8158542869127974,
                "train_loss": 2.071855306625366,
                "val_loss": 1.1695269520950318,
                "val_top1": 72.78400001708984,
                "val_top5": 91.2240000390625
            },
            {
                "epoch": 81,
                "learning_rate": 0.031134414899596986,
                "model_norm": 254.75308227539062,
                "train_grad_norm": 1.8483509821963027,
                "train_loss": 2.0480756759643555,
                "val_loss": 1.177937402973175,
                "val_top1": 72.63399994140624,
                "val_top5": 91.2660001513672
            },
            {
                "epoch": 82,
                "learning_rate": 0.027851594599211296,
                "model_norm": 254.5272216796875,
                "train_grad_norm": 1.8820415529196688,
                "train_loss": 2.027878761291504,
                "val_loss": 1.1286161779785155,
                "val_top1": 73.55000001220704,
                "val_top5": 91.93600001464844
            },
            {
                "epoch": 83,
                "learning_rate": 0.02473866399122733,
                "model_norm": 254.3037872314453,
                "train_grad_norm": 1.91901700058942,
                "train_loss": 2.0080530643463135,
                "val_loss": 1.1259454420280457,
                "val_top1": 73.78799996582032,
                "val_top5": 91.77600001708984
            },
            {
                "epoch": 84,
                "learning_rate": 0.021798695162326444,
                "model_norm": 254.08140563964844,
                "train_grad_norm": 1.949943092349552,
                "train_loss": 1.9847638607025146,
                "val_loss": 1.118032236213684,
                "val_top1": 73.97000004394532,
                "val_top5": 92.09800006835937
            },
            {
                "epoch": 85,
                "learning_rate": 0.019034589506796085,
                "model_norm": 253.86386108398438,
                "train_grad_norm": 1.984257404824889,
                "train_loss": 1.9642367362976074,
                "val_loss": 1.0790100056648255,
                "val_top1": 75.00199999023438,
                "val_top5": 92.45800006835937
            },
            {
                "epoch": 86,
                "learning_rate": 0.016449074863203773,
                "model_norm": 253.65621948242188,
                "train_grad_norm": 2.0183667712044717,
                "train_loss": 1.9397609233856201,
                "val_loss": 1.0745663145446778,
                "val_top1": 75.36200009277344,
                "val_top5": 92.58399999023437
            },
            {
                "epoch": 87,
                "learning_rate": 0.014044702822349731,
                "model_norm": 253.4591522216797,
                "train_grad_norm": 2.0484158782480146,
                "train_loss": 1.9196877479553223,
                "val_loss": 1.0517737560844422,
                "val_top1": 75.53200001220704,
                "val_top5": 92.8640000390625
            },
            {
                "epoch": 88,
                "learning_rate": 0.01182384620915491,
                "model_norm": 253.27586364746094,
                "train_grad_norm": 2.0789104111581307,
                "train_loss": 1.8970894813537598,
                "val_loss": 1.0200172888183594,
                "val_top1": 76.19000004150391,
                "val_top5": 93.11600014160156
            },
            {
                "epoch": 89,
                "learning_rate": 0.009788696740969294,
                "model_norm": 253.109375,
                "train_grad_norm": 2.110874399545941,
                "train_loss": 1.8775221109390259,
                "val_loss": 1.0248330810546875,
                "val_top1": 76.44000006347656,
                "val_top5": 93.11799998779297
            },
            {
                "epoch": 90,
                "learning_rate": 0.00794126286461141,
                "model_norm": 252.96102905273438,
                "train_grad_norm": 2.1361645297433993,
                "train_loss": 1.8590476512908936,
                "val_loss": 1.0220047914505004,
                "val_top1": 76.53600003662109,
                "val_top5": 93.2080001147461
            },
            {
                "epoch": 91,
                "learning_rate": 0.0062833677742737855,
                "model_norm": 252.8329620361328,
                "train_grad_norm": 2.1599094565380637,
                "train_loss": 1.8398445844650269,
                "val_loss": 1.0104525424575805,
                "val_top1": 76.52800001708984,
                "val_top5": 93.21999993652344
            },
            {
                "epoch": 92,
                "learning_rate": 0.004816647612250535,
                "model_norm": 252.7255096435547,
                "train_grad_norm": 2.181535641359402,
                "train_loss": 1.8244967460632324,
                "val_loss": 1.0057205820465087,
                "val_top1": 76.89800009033203,
                "val_top5": 93.39999993408203
            },
            {
                "epoch": 93,
                "learning_rate": 0.003542549854262256,
                "model_norm": 252.64010620117188,
                "train_grad_norm": 2.198791031650729,
                "train_loss": 1.811537265777588,
                "val_loss": 0.9927536464309692,
                "val_top1": 77.00400009033203,
                "val_top5": 93.50600008789063
            },
            {
                "epoch": 94,
                "learning_rate": 0.0024623318809724685,
                "model_norm": 252.5753936767578,
                "train_grad_norm": 2.203561914723378,
                "train_loss": 1.797890305519104,
                "val_loss": 0.9842381191825866,
                "val_top1": 77.18999995849609,
                "val_top5": 93.5399999609375
            },
            {
                "epoch": 95,
                "learning_rate": 0.0015770597371044472,
                "model_norm": 252.52992248535156,
                "train_grad_norm": 2.212908279671095,
                "train_loss": 1.786906361579895,
                "val_loss": 0.9836688971710205,
                "val_top1": 77.29400006347656,
                "val_top5": 93.56000006347656
            },
            {
                "epoch": 96,
                "learning_rate": 0.0008876070793840008,
                "model_norm": 252.5014190673828,
                "train_grad_norm": 2.214097410164139,
                "train_loss": 1.7772572040557861,
                "val_loss": 0.9791730240249634,
                "val_top1": 77.35800003662109,
                "val_top5": 93.64000011474609
            },
            {
                "epoch": 97,
                "learning_rate": 0.00039465431434568824,
                "model_norm": 252.48635864257812,
                "train_grad_norm": 2.2153519009515237,
                "train_loss": 1.7729535102844238,
                "val_loss": 0.9757770546722412,
                "val_top1": 77.3559998828125,
                "val_top5": 93.61999993408203
            },
            {
                "epoch": 98,
                "learning_rate": 9.868792685368e-05,
                "model_norm": 252.48074340820312,
                "train_grad_norm": 2.212385256567594,
                "train_loss": 1.7704020738601685,
                "val_loss": 0.9847097683906555,
                "val_top1": 77.4040000390625,
                "val_top5": 93.6260000366211
            },
            {
                "epoch": 99,
                "learning_rate": 0.0,
                "model_norm": 252.47988891601562,
                "train_grad_norm": 2.2110518094036142,
                "train_loss": 1.7673463821411133,
                "val_loss": 0.9737415019989014,
                "val_top1": 77.42400001220703,
                "val_top5": 93.63200011474609
            }
        ],
        "summary": {
            "len_train_loader": 1251,
            "start_time": "2025-03-27 06:23:51.031891"
        }
    },
    {
        "config": {
            "batch_size": 256,
            "dataset": "imagenet1k",
            "gradient_accumulation": 1,
            "max_epoch": 100,
            "model": "resnet50",
            "opt": {
                "lr": 0.4,
                "lr_schedule": "linear-decay",
                "momentum": 0.9,
                "name": "momentum",
                "weight_decay": 0.0001
            },
            "run_id": 0
        },
        "history": [
            {
                "epoch": 0,
                "learning_rate": 0.080008,
                "model_norm": 229.7855224609375,
                "train_grad_norm": 0.9639270922261696,
                "train_loss": 6.447768688201904,
                "val_loss": 5.755281113891601,
                "val_top1": 4.447999989013672,
                "val_top5": 12.980000013427734
            },
            {
                "epoch": 1,
                "learning_rate": 0.160006,
                "model_norm": 207.9287109375,
                "train_grad_norm": 1.0493056674381571,
                "train_loss": 5.662769317626953,
                "val_loss": 4.866955654602051,
                "val_top1": 11.30199998046875,
                "val_top5": 27.33400005004883
            },
            {
                "epoch": 2,
                "learning_rate": 0.240004,
                "model_norm": 184.6352996826172,
                "train_grad_norm": 1.0434426229399028,
                "train_loss": 4.845889568328857,
                "val_loss": 4.375285541381836,
                "val_top1": 16.44200001464844,
                "val_top5": 36.568000068359375
            },
            {
                "epoch": 3,
                "learning_rate": 0.320002,
                "model_norm": 169.49801635742188,
                "train_grad_norm": 0.9681497438158121,
                "train_loss": 4.240854740142822,
                "val_loss": 3.7242241425323486,
                "val_top1": 24.75200001098633,
                "val_top5": 48.46600003173828
            },
            {
                "epoch": 4,
                "learning_rate": 0.39583333333333337,
                "model_norm": 165.7278289794922,
                "train_grad_norm": 0.9207491647897825,
                "train_loss": 3.8718624114990234,
                "val_loss": 3.354064582977295,
                "val_top1": 31.568000051269532,
                "val_top5": 57.24599998535156
            },
            {
                "epoch": 5,
                "learning_rate": 0.39166666666666666,
                "model_norm": 168.04647827148438,
                "train_grad_norm": 0.8962217481404829,
                "train_loss": 3.6137771606445312,
                "val_loss": 2.981079534988403,
                "val_top1": 37.116000040283204,
                "val_top5": 63.60599998535156
            },
            {
                "epoch": 6,
                "learning_rate": 0.3875,
                "model_norm": 172.132568359375,
                "train_grad_norm": 0.908851729399213,
                "train_loss": 3.4314346313476562,
                "val_loss": 2.617006452407837,
                "val_top1": 42.78800001098633,
                "val_top5": 69.2100000390625
            },
            {
                "epoch": 7,
                "learning_rate": 0.38333333333333336,
                "model_norm": 176.4782257080078,
                "train_grad_norm": 0.9195961825218074,
                "train_loss": 3.316382646560669,
                "val_loss": 2.519472624282837,
                "val_top1": 45.575999995117186,
                "val_top5": 72.1679999975586
            },
            {
                "epoch": 8,
                "learning_rate": 0.37916666666666665,
                "model_norm": 180.51025390625,
                "train_grad_norm": 0.9287942847294696,
                "train_loss": 3.231309413909912,
                "val_loss": 2.7823695704650877,
                "val_top1": 41.551999975585936,
                "val_top5": 67.98400002685547
            },
            {
                "epoch": 9,
                "learning_rate": 0.375,
                "model_norm": 184.17640686035156,
                "train_grad_norm": 0.9374127511486652,
                "train_loss": 3.167036533355713,
                "val_loss": 2.3759972496032713,
                "val_top1": 47.897999916992184,
                "val_top5": 73.68599995117188
            },
            {
                "epoch": 10,
                "learning_rate": 0.37083333333333335,
                "model_norm": 187.64599609375,
                "train_grad_norm": 0.9477599174363047,
                "train_loss": 3.114743709564209,
                "val_loss": 2.375247562522888,
                "val_top1": 47.29799999023437,
                "val_top5": 73.29600001464844
            },
            {
                "epoch": 11,
                "learning_rate": 0.3666666666666667,
                "model_norm": 190.90380859375,
                "train_grad_norm": 0.955621484158328,
                "train_loss": 3.0734481811523438,
                "val_loss": 2.1791143769836427,
                "val_top1": 51.354000036621095,
                "val_top5": 77.29800013183593
            },
            {
                "epoch": 12,
                "learning_rate": 0.36250000000000004,
                "model_norm": 193.9164581298828,
                "train_grad_norm": 0.9633470852370274,
                "train_loss": 3.0383808612823486,
                "val_loss": 2.1911355988311767,
                "val_top1": 51.145999982910155,
                "val_top5": 76.85199998779296
            },
            {
                "epoch": 13,
                "learning_rate": 0.3583333333333334,
                "model_norm": 196.77774047851562,
                "train_grad_norm": 0.9709906052830507,
                "train_loss": 3.0090413093566895,
                "val_loss": 2.392801946411133,
                "val_top1": 48.42200004272461,
                "val_top5": 74.1899999609375
            },
            {
                "epoch": 14,
                "learning_rate": 0.3541666666666667,
                "model_norm": 199.3389892578125,
                "train_grad_norm": 0.9759248440880262,
                "train_loss": 2.979933261871338,
                "val_loss": 2.078142295150757,
                "val_top1": 53.66200000244141,
                "val_top5": 78.68599998046875
            },
            {
                "epoch": 15,
                "learning_rate": 0.35000000000000003,
                "model_norm": 201.84535217285156,
                "train_grad_norm": 0.9833953371525297,
                "train_loss": 2.957620620727539,
                "val_loss": 1.9572018490219116,
                "val_top1": 56.259999978027345,
                "val_top5": 80.89399994384766
            },
            {
                "epoch": 16,
                "learning_rate": 0.3458333333333334,
                "model_norm": 204.270751953125,
                "train_grad_norm": 0.9896737177589148,
                "train_loss": 2.9374914169311523,
                "val_loss": 2.0627996143341063,
                "val_top1": 53.801999946289065,
                "val_top5": 78.92000008056641
            },
            {
                "epoch": 17,
                "learning_rate": 0.3416666666666667,
                "model_norm": 206.5963592529297,
                "train_grad_norm": 0.9968443179164184,
                "train_loss": 2.9174070358276367,
                "val_loss": 1.9848956448745727,
                "val_top1": 55.2440000024414,
                "val_top5": 79.92200001708984
            },
            {
                "epoch": 18,
                "learning_rate": 0.3375,
                "model_norm": 208.81790161132812,
                "train_grad_norm": 1.0031402758376053,
                "train_loss": 2.9005138874053955,
                "val_loss": 2.0778221783447264,
                "val_top1": 53.85000004638672,
                "val_top5": 79.14199995605469
            },
            {
                "epoch": 19,
                "learning_rate": 0.33333333333333337,
                "model_norm": 210.9107666015625,
                "train_grad_norm": 1.0081409445505276,
                "train_loss": 2.8836429119110107,
                "val_loss": 1.9970932899475098,
                "val_top1": 55.406000014648434,
                "val_top5": 80.37199983398438
            },
            {
                "epoch": 20,
                "learning_rate": 0.32916666666666666,
                "model_norm": 212.93206787109375,
                "train_grad_norm": 1.0140771798442092,
                "train_loss": 2.8703436851501465,
                "val_loss": 2.0960743482208253,
                "val_top1": 53.46200001953125,
                "val_top5": 78.67400001953125
            },
            {
                "epoch": 21,
                "learning_rate": 0.325,
                "model_norm": 214.8730010986328,
                "train_grad_norm": 1.0196429269856624,
                "train_loss": 2.8548660278320312,
                "val_loss": 1.9308313695526123,
                "val_top1": 56.27399989746094,
                "val_top5": 80.66999996337891
            },
            {
                "epoch": 22,
                "learning_rate": 0.32083333333333336,
                "model_norm": 216.727783203125,
                "train_grad_norm": 1.0255160353044876,
                "train_loss": 2.842146873474121,
                "val_loss": 1.982156629486084,
                "val_top1": 55.92800004150391,
                "val_top5": 80.58199994140625
            },
            {
                "epoch": 23,
                "learning_rate": 0.31666666666666665,
                "model_norm": 218.52178955078125,
                "train_grad_norm": 1.0306696862490636,
                "train_loss": 2.8295211791992188,
                "val_loss": 1.8983890711975098,
                "val_top1": 57.594000073242185,
                "val_top5": 81.76200004150391
            },
            {
                "epoch": 24,
                "learning_rate": 0.3125,
                "model_norm": 220.2506866455078,
                "train_grad_norm": 1.0361603128039885,
                "train_loss": 2.818330764770508,
                "val_loss": 2.3820118154144287,
                "val_top1": 48.93400001708984,
                "val_top5": 74.34400000976562
            },
            {
                "epoch": 25,
                "learning_rate": 0.30833333333333335,
                "model_norm": 221.8715362548828,
                "train_grad_norm": 1.039790234768001,
                "train_loss": 2.806000232696533,
                "val_loss": 1.9186035299301147,
                "val_top1": 56.690000029296876,
                "val_top5": 81.08600004150391
            },
            {
                "epoch": 26,
                "learning_rate": 0.3041666666666667,
                "model_norm": 223.47451782226562,
                "train_grad_norm": 1.0456942764447856,
                "train_loss": 2.794865846633911,
                "val_loss": 2.0111959842681886,
                "val_top1": 54.71200009277344,
                "val_top5": 79.57000005371094
            },
            {
                "epoch": 27,
                "learning_rate": 0.30000000000000004,
                "model_norm": 224.96092224121094,
                "train_grad_norm": 1.0504864694797749,
                "train_loss": 2.7835474014282227,
                "val_loss": 2.029634709854126,
                "val_top1": 54.88400000976562,
                "val_top5": 79.40400010986328
            },
            {
                "epoch": 28,
                "learning_rate": 0.29583333333333334,
                "model_norm": 226.42938232421875,
                "train_grad_norm": 1.0561738360996016,
                "train_loss": 2.7745420932769775,
                "val_loss": 1.8363193227386474,
                "val_top1": 58.72600000488281,
                "val_top5": 82.49599998535156
            },
            {
                "epoch": 29,
                "learning_rate": 0.2916666666666667,
                "model_norm": 227.90806579589844,
                "train_grad_norm": 1.0619320858029586,
                "train_loss": 2.76228404045105,
                "val_loss": 1.8165242156982422,
                "val_top1": 58.693999912109376,
                "val_top5": 82.70200006835937
            },
            {
                "epoch": 30,
                "learning_rate": 0.28750000000000003,
                "model_norm": 229.2695770263672,
                "train_grad_norm": 1.0658932742274467,
                "train_loss": 2.7559449672698975,
                "val_loss": 2.0966494302749634,
                "val_top1": 54.07599989990234,
                "val_top5": 78.58599998046876
            },
            {
                "epoch": 31,
                "learning_rate": 0.2833333333333333,
                "model_norm": 230.6744842529297,
                "train_grad_norm": 1.0726920311998236,
                "train_loss": 2.743859052658081,
                "val_loss": 2.0217382402801514,
                "val_top1": 54.95799997070313,
                "val_top5": 79.84199994628906
            },
            {
                "epoch": 32,
                "learning_rate": 0.27916666666666673,
                "model_norm": 231.94459533691406,
                "train_grad_norm": 1.0765044753917474,
                "train_loss": 2.733203172683716,
                "val_loss": 1.7805144067382812,
                "val_top1": 59.24599996826172,
                "val_top5": 83.40400002929688
            },
            {
                "epoch": 33,
                "learning_rate": 0.275,
                "model_norm": 233.20233154296875,
                "train_grad_norm": 1.083108044831864,
                "train_loss": 2.7230987548828125,
                "val_loss": 1.811568164138794,
                "val_top1": 58.97600005371094,
                "val_top5": 82.94400003662109
            },
            {
                "epoch": 34,
                "learning_rate": 0.2708333333333333,
                "model_norm": 234.4385528564453,
                "train_grad_norm": 1.0893344391112771,
                "train_loss": 2.714951992034912,
                "val_loss": 1.8535743754959106,
                "val_top1": 58.24400008300781,
                "val_top5": 82.50800009277344
            },
            {
                "epoch": 35,
                "learning_rate": 0.2666666666666667,
                "model_norm": 235.5953826904297,
                "train_grad_norm": 1.0936571367055683,
                "train_loss": 2.7059473991394043,
                "val_loss": 2.0575873862457277,
                "val_top1": 54.320000002441404,
                "val_top5": 78.86399997558594
            },
            {
                "epoch": 36,
                "learning_rate": 0.2625,
                "model_norm": 236.72523498535156,
                "train_grad_norm": 1.0998742239658557,
                "train_loss": 2.6999082565307617,
                "val_loss": 1.8128926948165893,
                "val_top1": 59.69399998046875,
                "val_top5": 83.29799999023437
            },
            {
                "epoch": 37,
                "learning_rate": 0.2583333333333333,
                "model_norm": 237.84658813476562,
                "train_grad_norm": 1.10602919646673,
                "train_loss": 2.6897318363189697,
                "val_loss": 1.7636208859252929,
                "val_top1": 60.386000043945316,
                "val_top5": 83.6980000366211
            },
            {
                "epoch": 38,
                "learning_rate": 0.2541666666666667,
                "model_norm": 238.92752075195312,
                "train_grad_norm": 1.1120607445752662,
                "train_loss": 2.680802822113037,
                "val_loss": 1.8621764200592041,
                "val_top1": 58.496000024414066,
                "val_top5": 82.39400003417968
            },
            {
                "epoch": 39,
                "learning_rate": 0.25,
                "model_norm": 239.9320526123047,
                "train_grad_norm": 1.1168891552532851,
                "train_loss": 2.672889232635498,
                "val_loss": 1.8804245404052735,
                "val_top1": 57.0400000390625,
                "val_top5": 81.37999994140625
            },
            {
                "epoch": 40,
                "learning_rate": 0.24583333333333332,
                "model_norm": 240.92185974121094,
                "train_grad_norm": 1.1224626621816431,
                "train_loss": 2.661640167236328,
                "val_loss": 1.753810793685913,
                "val_top1": 59.9500000390625,
                "val_top5": 83.64800009277344
            },
            {
                "epoch": 41,
                "learning_rate": 0.2416666666666667,
                "model_norm": 241.888916015625,
                "train_grad_norm": 1.1296678268087585,
                "train_loss": 2.655052423477173,
                "val_loss": 1.7539851763534546,
                "val_top1": 59.98800001220703,
                "val_top5": 83.61399993652344
            },
            {
                "epoch": 42,
                "learning_rate": 0.23750000000000002,
                "model_norm": 242.86497497558594,
                "train_grad_norm": 1.1366197312458513,
                "train_loss": 2.6456050872802734,
                "val_loss": 1.7127033430480958,
                "val_top1": 61.076000014648436,
                "val_top5": 84.2819998828125
            },
            {
                "epoch": 43,
                "learning_rate": 0.2333333333333333,
                "model_norm": 243.7711639404297,
                "train_grad_norm": 1.1420513860499277,
                "train_loss": 2.6377387046813965,
                "val_loss": 1.873260845527649,
                "val_top1": 58.24199998535156,
                "val_top5": 82.04199998535157
            },
            {
                "epoch": 44,
                "learning_rate": 0.2291666666666667,
                "model_norm": 244.6331787109375,
                "train_grad_norm": 1.1480406279225368,
                "train_loss": 2.6287262439727783,
                "val_loss": 1.7094085404968262,
                "val_top1": 61.39400010253906,
                "val_top5": 84.38400008789063
            },
            {
                "epoch": 45,
                "learning_rate": 0.225,
                "model_norm": 245.4578399658203,
                "train_grad_norm": 1.1546192210714792,
                "train_loss": 2.6201019287109375,
                "val_loss": 1.769392986907959,
                "val_top1": 60.91000002441406,
                "val_top5": 84.33599998535156
            },
            {
                "epoch": 46,
                "learning_rate": 0.22083333333333333,
                "model_norm": 246.26573181152344,
                "train_grad_norm": 1.1619688293555535,
                "train_loss": 2.6100406646728516,
                "val_loss": 1.7516663805007935,
                "val_top1": 60.35999995117187,
                "val_top5": 83.4440000390625
            },
            {
                "epoch": 47,
                "learning_rate": 0.2166666666666667,
                "model_norm": 247.03578186035156,
                "train_grad_norm": 1.1686499279898017,
                "train_loss": 2.603688955307007,
                "val_loss": 1.8161191310119629,
                "val_top1": 58.58599998779297,
                "val_top5": 82.39600001708985
            },
            {
                "epoch": 48,
                "learning_rate": 0.21250000000000002,
                "model_norm": 247.78623962402344,
                "train_grad_norm": 1.1752438413928752,
                "train_loss": 2.5961384773254395,
                "val_loss": 1.7273650007629395,
                "val_top1": 60.98999991699219,
                "val_top5": 83.83199993164062
            },
            {
                "epoch": 49,
                "learning_rate": 0.20833333333333331,
                "model_norm": 248.51773071289062,
                "train_grad_norm": 1.182827339612517,
                "train_loss": 2.5886192321777344,
                "val_loss": 1.7421793461990356,
                "val_top1": 60.52200009765625,
                "val_top5": 84.18800013671876
            },
            {
                "epoch": 50,
                "learning_rate": 0.20416666666666672,
                "model_norm": 249.19912719726562,
                "train_grad_norm": 1.1890491432567787,
                "train_loss": 2.5789432525634766,
                "val_loss": 1.7021644666671754,
                "val_top1": 61.20000010498047,
                "val_top5": 84.44800016601563
            },
            {
                "epoch": 51,
                "learning_rate": 0.2,
                "model_norm": 249.87806701660156,
                "train_grad_norm": 1.1981790355968283,
                "train_loss": 2.569399118423462,
                "val_loss": 1.8996222082901002,
                "val_top1": 57.51800001220703,
                "val_top5": 81.21599998535156
            },
            {
                "epoch": 52,
                "learning_rate": 0.19583333333333336,
                "model_norm": 250.5220184326172,
                "train_grad_norm": 1.2058023849249577,
                "train_loss": 2.561030864715576,
                "val_loss": 1.66258128616333,
                "val_top1": 62.548000041503904,
                "val_top5": 85.322000078125
            },
            {
                "epoch": 53,
                "learning_rate": 0.19166666666666665,
                "model_norm": 251.1457977294922,
                "train_grad_norm": 1.213558291544878,
                "train_loss": 2.5513150691986084,
                "val_loss": 1.702169055366516,
                "val_top1": 60.974000102539065,
                "val_top5": 84.09999993408204
            },
            {
                "epoch": 54,
                "learning_rate": 0.1875,
                "model_norm": 251.74862670898438,
                "train_grad_norm": 1.222209771988122,
                "train_loss": 2.5422189235687256,
                "val_loss": 1.5836385264205932,
                "val_top1": 63.39599999267578,
                "val_top5": 85.83800008300781
            },
            {
                "epoch": 55,
                "learning_rate": 0.18333333333333335,
                "model_norm": 252.30477905273438,
                "train_grad_norm": 1.2299436127944567,
                "train_loss": 2.533295154571533,
                "val_loss": 1.7462878410339355,
                "val_top1": 60.87000012451172,
                "val_top5": 84.1019998828125
            },
            {
                "epoch": 56,
                "learning_rate": 0.17916666666666667,
                "model_norm": 252.84678649902344,
                "train_grad_norm": 1.2379094113931155,
                "train_loss": 2.5265090465545654,
                "val_loss": 1.6581331370925902,
                "val_top1": 62.493999963378904,
                "val_top5": 85.55800004882812
            },
            {
                "epoch": 57,
                "learning_rate": 0.17500000000000002,
                "model_norm": 253.39158630371094,
                "train_grad_norm": 1.2489618712332726,
                "train_loss": 2.517481803894043,
                "val_loss": 1.7634065646362305,
                "val_top1": 61.240000102539064,
                "val_top5": 84.19999993164062
            },
            {
                "epoch": 58,
                "learning_rate": 0.17083333333333336,
                "model_norm": 253.88186645507812,
                "train_grad_norm": 1.2563376123376695,
                "train_loss": 2.508310556411743,
                "val_loss": 1.7605775662612915,
                "val_top1": 60.41200000976563,
                "val_top5": 83.83800001464844
            },
            {
                "epoch": 59,
                "learning_rate": 0.16666666666666666,
                "model_norm": 254.31556701660156,
                "train_grad_norm": 1.2639503257012823,
                "train_loss": 2.4974966049194336,
                "val_loss": 1.6278362427139281,
                "val_top1": 62.42000004882812,
                "val_top5": 85.06800004394532
            },
            {
                "epoch": 60,
                "learning_rate": 0.1625,
                "model_norm": 254.7434844970703,
                "train_grad_norm": 1.2735588667599758,
                "train_loss": 2.4889233112335205,
                "val_loss": 1.5578224971389771,
                "val_top1": 64.25600007080078,
                "val_top5": 86.2920000341797
            },
            {
                "epoch": 61,
                "learning_rate": 0.15833333333333335,
                "model_norm": 255.16856384277344,
                "train_grad_norm": 1.2839631367230402,
                "train_loss": 2.48047137260437,
                "val_loss": 1.7117398552703857,
                "val_top1": 61.67999998779297,
                "val_top5": 84.23200000732422
            },
            {
                "epoch": 62,
                "learning_rate": 0.15416666666666667,
                "model_norm": 255.5667266845703,
                "train_grad_norm": 1.2937165010158473,
                "train_loss": 2.470041513442993,
                "val_loss": 1.5355929949569702,
                "val_top1": 64.92200003417969,
                "val_top5": 86.61000005615234
            },
            {
                "epoch": 63,
                "learning_rate": 0.15000000000000002,
                "model_norm": 255.9273681640625,
                "train_grad_norm": 1.3042407935311489,
                "train_loss": 2.4605698585510254,
                "val_loss": 1.7680099186706544,
                "val_top1": 60.13799996337891,
                "val_top5": 83.67000007568359
            },
            {
                "epoch": 64,
                "learning_rate": 0.14583333333333334,
                "model_norm": 256.27349853515625,
                "train_grad_norm": 1.3148308702396574,
                "train_loss": 2.450993537902832,
                "val_loss": 1.6092381358337402,
                "val_top1": 63.65400004394531,
                "val_top5": 86.04399997802734
            },
            {
                "epoch": 65,
                "learning_rate": 0.14166666666666666,
                "model_norm": 256.5895080566406,
                "train_grad_norm": 1.3253153973240241,
                "train_loss": 2.441084861755371,
                "val_loss": 1.506731612148285,
                "val_top1": 65.26400004882812,
                "val_top5": 87.1600000805664
            },
            {
                "epoch": 66,
                "learning_rate": 0.1375,
                "model_norm": 256.90594482421875,
                "train_grad_norm": 1.3381256569984061,
                "train_loss": 2.4311330318450928,
                "val_loss": 1.5047303534317016,
                "val_top1": 65.47000001953126,
                "val_top5": 87.08600000732422
            },
            {
                "epoch": 67,
                "learning_rate": 0.13333333333333336,
                "model_norm": 257.1825866699219,
                "train_grad_norm": 1.349506989666886,
                "train_loss": 2.41990327835083,
                "val_loss": 1.5923514701843262,
                "val_top1": 63.278,
                "val_top5": 85.6340000390625
            },
            {
                "epoch": 68,
                "learning_rate": 0.12916666666666665,
                "model_norm": 257.4515686035156,
                "train_grad_norm": 1.3622637721600321,
                "train_loss": 2.408116579055786,
                "val_loss": 1.5616175062942506,
                "val_top1": 64.8359999658203,
                "val_top5": 86.48200003173828
            },
            {
                "epoch": 69,
                "learning_rate": 0.125,
                "model_norm": 257.6809997558594,
                "train_grad_norm": 1.373807352898681,
                "train_loss": 2.3979272842407227,
                "val_loss": 1.552302098083496,
                "val_top1": 64.63400007324219,
                "val_top5": 86.72399998046875
            },
            {
                "epoch": 70,
                "learning_rate": 0.12083333333333335,
                "model_norm": 257.9052734375,
                "train_grad_norm": 1.387063424607454,
                "train_loss": 2.3880515098571777,
                "val_loss": 1.55068022813797,
                "val_top1": 64.0699999633789,
                "val_top5": 86.44800005371094
            },
            {
                "epoch": 71,
                "learning_rate": 0.11666666666666665,
                "model_norm": 258.0928649902344,
                "train_grad_norm": 1.4007825625614347,
                "train_loss": 2.3764755725860596,
                "val_loss": 1.613435218963623,
                "val_top1": 63.8600000024414,
                "val_top5": 86.01999996582032
            },
            {
                "epoch": 72,
                "learning_rate": 0.1125,
                "model_norm": 258.2420349121094,
                "train_grad_norm": 1.4125729602572499,
                "train_loss": 2.363098621368408,
                "val_loss": 1.4787997054672242,
                "val_top1": 65.98200001708985,
                "val_top5": 87.58200000488281
            },
            {
                "epoch": 73,
                "learning_rate": 0.10833333333333335,
                "model_norm": 258.38555908203125,
                "train_grad_norm": 1.427777903665133,
                "train_loss": 2.352909564971924,
                "val_loss": 1.4928258415603637,
                "val_top1": 65.85599998291016,
                "val_top5": 87.3740000024414
            },
            {
                "epoch": 74,
                "learning_rate": 0.10416666666666666,
                "model_norm": 258.5093688964844,
                "train_grad_norm": 1.4433316448127098,
                "train_loss": 2.340919017791748,
                "val_loss": 1.4739837672805787,
                "val_top1": 66.81200001953125,
                "val_top5": 87.96000011230468
            },
            {
                "epoch": 75,
                "learning_rate": 0.1,
                "model_norm": 258.6031799316406,
                "train_grad_norm": 1.4584676257461044,
                "train_loss": 2.3289289474487305,
                "val_loss": 1.4200649530410767,
                "val_top1": 67.2160000390625,
                "val_top5": 88.34199992431641
            },
            {
                "epoch": 76,
                "learning_rate": 0.09583333333333335,
                "model_norm": 258.6734619140625,
                "train_grad_norm": 1.4736818499862816,
                "train_loss": 2.3149170875549316,
                "val_loss": 1.4432242579650878,
                "val_top1": 66.41799992675782,
                "val_top5": 87.92599997070313
            },
            {
                "epoch": 77,
                "learning_rate": 0.09166666666666666,
                "model_norm": 258.7197570800781,
                "train_grad_norm": 1.4917051256944522,
                "train_loss": 2.3011977672576904,
                "val_loss": 1.440665942802429,
                "val_top1": 66.95600001953125,
                "val_top5": 87.98800002197265
            },
            {
                "epoch": 78,
                "learning_rate": 0.08750000000000001,
                "model_norm": 258.7497863769531,
                "train_grad_norm": 1.5092713561284175,
                "train_loss": 2.2887699604034424,
                "val_loss": 1.4955053533935547,
                "val_top1": 66.05800000732422,
                "val_top5": 87.29200010498047
            },
            {
                "epoch": 79,
                "learning_rate": 0.08333333333333336,
                "model_norm": 258.75872802734375,
                "train_grad_norm": 1.5279087738238488,
                "train_loss": 2.275289297103882,
                "val_loss": 1.3446102014160157,
                "val_top1": 68.490000078125,
                "val_top5": 89.116
            },
            {
                "epoch": 80,
                "learning_rate": 0.07916666666666666,
                "model_norm": 258.75372314453125,
                "train_grad_norm": 1.5488360246555781,
                "train_loss": 2.261349678039551,
                "val_loss": 1.4722450748443603,
                "val_top1": 66.60599999023438,
                "val_top5": 87.61599992431641
            },
            {
                "epoch": 81,
                "learning_rate": 0.07500000000000001,
                "model_norm": 258.72198486328125,
                "train_grad_norm": 1.5684093200075129,
                "train_loss": 2.2445766925811768,
                "val_loss": 1.4044351908874513,
                "val_top1": 68.11000009277343,
                "val_top5": 88.49000003417969
            },
            {
                "epoch": 82,
                "learning_rate": 0.07083333333333335,
                "model_norm": 258.65252685546875,
                "train_grad_norm": 1.586169002862443,
                "train_loss": 2.230325222015381,
                "val_loss": 1.3193974855232238,
                "val_top1": 69.53200010498047,
                "val_top5": 89.65799991943359
            },
            {
                "epoch": 83,
                "learning_rate": 0.06666666666666665,
                "model_norm": 258.5726013183594,
                "train_grad_norm": 1.6116721329631607,
                "train_loss": 2.2153337001800537,
                "val_loss": 1.3469040661239624,
                "val_top1": 68.79200002685546,
                "val_top5": 88.98399997558593
            },
            {
                "epoch": 84,
                "learning_rate": 0.0625,
                "model_norm": 258.46942138671875,
                "train_grad_norm": 1.6345740109205298,
                "train_loss": 2.198560953140259,
                "val_loss": 1.4235534710693358,
                "val_top1": 67.78999998779297,
                "val_top5": 88.27999997802735
            },
            {
                "epoch": 85,
                "learning_rate": 0.05833333333333335,
                "model_norm": 258.3374938964844,
                "train_grad_norm": 1.65725127594057,
                "train_loss": 2.1806564331054688,
                "val_loss": 1.2714337269592284,
                "val_top1": 70.924,
                "val_top5": 90.25000004882813
            },
            {
                "epoch": 86,
                "learning_rate": 0.054166666666666655,
                "model_norm": 258.1915283203125,
                "train_grad_norm": 1.6843365808507516,
                "train_loss": 2.1613731384277344,
                "val_loss": 1.2527211791419983,
                "val_top1": 71.45200007080078,
                "val_top5": 90.62399994384765
            },
            {
                "epoch": 87,
                "learning_rate": 0.05,
                "model_norm": 258.0218811035156,
                "train_grad_norm": 1.710188364102206,
                "train_loss": 2.143021583557129,
                "val_loss": 1.2465287998199464,
                "val_top1": 71.34200007324219,
                "val_top5": 90.7499999951172
            },
            {
                "epoch": 88,
                "learning_rate": 0.04583333333333335,
                "model_norm": 257.833251953125,
                "train_grad_norm": 1.7390653059993408,
                "train_loss": 2.12150239944458,
                "val_loss": 1.1789743746185302,
                "val_top1": 72.45599999511718,
                "val_top5": 91.2000000732422
            },
            {
                "epoch": 89,
                "learning_rate": 0.04166666666666666,
                "model_norm": 257.6170959472656,
                "train_grad_norm": 1.7664903270686378,
                "train_loss": 2.099228858947754,
                "val_loss": 1.1922826647567748,
                "val_top1": 72.11400004394531,
                "val_top5": 91.09200006835937
            },
            {
                "epoch": 90,
                "learning_rate": 0.037500000000000006,
                "model_norm": 257.38653564453125,
                "train_grad_norm": 1.798223118999476,
                "train_loss": 2.078458309173584,
                "val_loss": 1.1734767657661438,
                "val_top1": 72.75599997070313,
                "val_top5": 91.43400004394532
            },
            {
                "epoch": 91,
                "learning_rate": 0.03333333333333335,
                "model_norm": 257.1405029296875,
                "train_grad_norm": 1.8285658813716392,
                "train_loss": 2.053467035293579,
                "val_loss": 1.1515379235458374,
                "val_top1": 73.17799999023437,
                "val_top5": 91.58199999511719
            },
            {
                "epoch": 92,
                "learning_rate": 0.029166666666666653,
                "model_norm": 256.88092041015625,
                "train_grad_norm": 1.8578843865146215,
                "train_loss": 2.028797149658203,
                "val_loss": 1.1553349071502685,
                "val_top1": 73.37799991210937,
                "val_top5": 91.62400001464843
            },
            {
                "epoch": 93,
                "learning_rate": 0.025,
                "model_norm": 256.613525390625,
                "train_grad_norm": 1.892372265572267,
                "train_loss": 2.0036325454711914,
                "val_loss": 1.0942809301757812,
                "val_top1": 74.44800001220703,
                "val_top5": 92.32400004150391
            },
            {
                "epoch": 94,
                "learning_rate": 0.02083333333333335,
                "model_norm": 256.3475341796875,
                "train_grad_norm": 1.9233733493850564,
                "train_loss": 1.973601222038269,
                "val_loss": 1.0742818885803223,
                "val_top1": 74.93800001464844,
                "val_top5": 92.45200001708984
            },
            {
                "epoch": 95,
                "learning_rate": 0.016666666666666653,
                "model_norm": 256.0868835449219,
                "train_grad_norm": 1.9537282201661403,
                "train_loss": 1.942369818687439,
                "val_loss": 1.0664758535575867,
                "val_top1": 75.06800006103515,
                "val_top5": 92.59799991455078
            },
            {
                "epoch": 96,
                "learning_rate": 0.0125,
                "model_norm": 255.8485107421875,
                "train_grad_norm": 1.9806511911691171,
                "train_loss": 1.909501552581787,
                "val_loss": 1.030705492286682,
                "val_top1": 76.01400001220703,
                "val_top5": 92.95800001464843
            },
            {
                "epoch": 97,
                "learning_rate": 0.008333333333333349,
                "model_norm": 255.647705078125,
                "train_grad_norm": 2.001424061041856,
                "train_loss": 1.8769768476486206,
                "val_loss": 1.0216724802589416,
                "val_top1": 76.38200000732422,
                "val_top5": 93.15800001464844
            },
            {
                "epoch": 98,
                "learning_rate": 0.004166666666666652,
                "model_norm": 255.50624084472656,
                "train_grad_norm": 2.0101759249327187,
                "train_loss": 1.8474119901657104,
                "val_loss": 0.9929428809738159,
                "val_top1": 76.93799993164062,
                "val_top5": 93.49000001464844
            },
            {
                "epoch": 99,
                "learning_rate": 0.0,
                "model_norm": 255.4520721435547,
                "train_grad_norm": 1.9998057575674641,
                "train_loss": 1.8171467781066895,
                "val_loss": 0.9743368803405762,
                "val_top1": 77.36799998291016,
                "val_top5": 93.67599998779296
            }
        ],
        "summary": {
            "len_train_loader": 1251,
            "start_time": "2025-03-28 04:55:46.898636"
        }
    }
]